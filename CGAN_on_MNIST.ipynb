{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN on MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgl1/W93qQ910snrOYKbzQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohit501/CGAN-on-MNIST/blob/main/CGAN_on_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-LY68OHHwjb"
      },
      "source": [
        "## Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F84DifVSHHUI"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "from keras.layers import Activation,Dense,Input,Conv2D,Flatten,Reshape,Conv2DTranspose,LeakyReLU,BatchNormalization,concatenate\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from keras.models import Model,load_model\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.utils import to_categorical,plot_model\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import math\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import argparse"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd72Qgq7njZo"
      },
      "source": [
        "## Building Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YB2KTpPJzBV"
      },
      "source": [
        "def build_generator(inputs,labels,image_size):\r\n",
        "  image_resize = image_size//4\r\n",
        "  kernel_size = 5\r\n",
        "  layer_filter =  [128,64,32,1]\r\n",
        "  x = concatenate([inputs,labels],axis = 1)\r\n",
        "  x = Dense(image_resize*image_resize*layer_filter[0])(x)\r\n",
        "  x = Reshape((image_resize,image_resize,layer_filter[0]))(x)\r\n",
        "  for filter in layer_filter:\r\n",
        "      if filter > layer_filter[-2]:\r\n",
        "        strides = 2\r\n",
        "      else:\r\n",
        "        strides = 1\r\n",
        "      x = BatchNormalization()(x)\r\n",
        "      x = Activation('relu')(x)\r\n",
        "      x = Conv2DTranspose(filters=  filter,kernel_size=kernel_size,strides=strides,padding = 'same')(x)\r\n",
        "\r\n",
        "  x = Activation('sigmoid')(x)\r\n",
        "  generator  = Model([inputs,labels],x,name = 'generator')\r\n",
        "  return generator"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL-OOm29noaE"
      },
      "source": [
        "# Building Discriminator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPtnoVf8nnkP"
      },
      "source": [
        "def build_discriminator(inputs, labels, image_size):  \r\n",
        "    kernel_size = 5\r\n",
        "    layer_filters = [32, 64, 128, 256]\r\n",
        "    x = inputs\r\n",
        "    y = Dense(image_size * image_size)(labels)\r\n",
        "    y = Reshape((image_size, image_size, 1))(y)\r\n",
        "    x = concatenate([x, y])\r\n",
        "    for filters in layer_filters:\r\n",
        "        if filters == layer_filters[-1]:\r\n",
        "            strides = 1\r\n",
        "        else:\r\n",
        "            strides = 2\r\n",
        "        x = LeakyReLU(alpha=0.2)(x)\r\n",
        "        x = Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(x)\r\n",
        "    x = Flatten()(x)\r\n",
        "    x = Dense(1)(x)\r\n",
        "    x = Activation('sigmoid')(x)\r\n",
        "    discriminator = Model([inputs, labels], x, name='discriminator')\r\n",
        "    return discriminator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPuGl8EPp_Y9"
      },
      "source": [
        "# Building a trian function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2S-VM_Zp7pZ"
      },
      "source": [
        " def train(models,data,params):\r\n",
        "    generator, discriminator, adversarial = models\r\n",
        "    x_train, y_train = data\r\n",
        "    batch_size, latent_size, train_steps, num_labels, model_name = params\r\n",
        "    save_interval = 1000\r\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\r\n",
        "    noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels]\r\n",
        "    train_size = x_train.shape[0]\r\n",
        "    print(model_name,\"Labels for generated images: \", np.argmax(noise_class, axis=1))\r\n",
        "    for i in range(train_steps):\r\n",
        "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\r\n",
        "        real_images = x_train[rand_indexes]\r\n",
        "        real_labels = y_train[rand_indexes]\r\n",
        "       \r\n",
        "        noise = np.random.uniform(-1.0,1.0,size=[batch_size, latent_size])\r\n",
        "        \r\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\r\n",
        "        fake_images = generator.predict([noise, fake_labels])\r\n",
        "        x = np.concatenate((real_images, fake_images))\r\n",
        "        labels = np.concatenate((real_labels, fake_labels))\r\n",
        "        y = np.ones([2 * batch_size, 1])\r\n",
        "        y[batch_size:, :] = 0.0\r\n",
        "        loss, acc = discriminator.train_on_batch([x, labels], y)\r\n",
        "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\r\n",
        "        noise = np.random.uniform(-1.0,1.0,size=[batch_size, latent_size])\r\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,batch_size)]\r\n",
        "        y = np.ones([batch_size, 1])\r\n",
        "        loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\r\n",
        "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\r\n",
        "        print(log)\r\n",
        "        if (i + 1) % save_interval == 0:\r\n",
        "            plot_images(generator,noise_input=noise_input,noise_class=noise_class,show=False,step=(i + 1),model_name=model_name)\r\n",
        "    \r\n",
        "  \r\n",
        "    generator.save(model_name + \".h5\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h30i4cQuoX_"
      },
      "source": [
        "## Creating a Plot Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADlw5KQuulkt"
      },
      "source": [
        "def plot_images(generator,noise_input,noise_class,show=False,step=0,model_name=\"gan\"):\r\n",
        "    os.makedirs(model_name, exist_ok=True)\r\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\r\n",
        "    images = generator.predict([noise_input, noise_class])\r\n",
        "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\r\n",
        "    plt.figure(figsize=(3,3))\r\n",
        "    num_images = images.shape[0]\r\n",
        "    image_size = images.shape[1]\r\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\r\n",
        "    for i in range(num_images):\r\n",
        "        plt.subplot(rows, rows, i + 1)\r\n",
        "        image = np.reshape(images[i], [image_size, image_size])\r\n",
        "        plt.imshow(image, cmap='gray')\r\n",
        "        plt.axis('off')\r\n",
        "    plt.savefig(filename)\r\n",
        "    if show:\r\n",
        "        plt.show()\r\n",
        "    else:\r\n",
        "        plt.close('all')\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv0-le4evR43"
      },
      "source": [
        "# Build and Train Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtaG5NsCvPkm"
      },
      "source": [
        "\r\n",
        "def build_and_train_models():\r\n",
        "    (x_train, y_train), (_, _) = mnist.load_data()\r\n",
        "    image_size = x_train.shape[1]\r\n",
        "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\r\n",
        "    x_train = x_train.astype('float32') / 255\r\n",
        "\r\n",
        "    num_labels = np.amax(y_train) + 1\r\n",
        "    y_train = to_categorical(y_train)\r\n",
        "\r\n",
        "    model_name = \"cgan_mnist\"\r\n",
        "    latent_size = 100\r\n",
        "    batch_size = 64\r\n",
        "    train_steps = 40000\r\n",
        "    lr = 2e-4\r\n",
        "    decay = 6e-8\r\n",
        "    input_shape = (image_size, image_size, 1)\r\n",
        "    label_shape = (num_labels, )\r\n",
        "\r\n",
        "    \r\n",
        "    inputs = Input(shape=input_shape, name='discriminator_input')\r\n",
        "    labels = Input(shape=label_shape, name='class_labels')\r\n",
        "\r\n",
        "    discriminator = build_discriminator(inputs, labels, image_size)\r\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\r\n",
        "    discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\r\n",
        "    discriminator.summary()\r\n",
        "    input_shape = (latent_size, )\r\n",
        "    inputs = Input(shape=input_shape, name='z_input')\r\n",
        "    generator = build_generator(inputs, labels, image_size)\r\n",
        "    generator.summary()\r\n",
        "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\r\n",
        "    \r\n",
        "    discriminator.trainable = False\r\n",
        "    outputs = discriminator([generator([inputs, labels]), labels])\r\n",
        "    adversarial = Model([inputs, labels],\r\n",
        "                        outputs,\r\n",
        "                        name=model_name)\r\n",
        "    adversarial.compile(loss='binary_crossentropy',\r\n",
        "                        optimizer=optimizer,\r\n",
        "                        metrics=['accuracy'])\r\n",
        "    adversarial.summary()\r\n",
        "    models = (generator, discriminator, adversarial)\r\n",
        "    data = (x_train, y_train)\r\n",
        "    params = (batch_size, latent_size, train_steps, num_labels, model_name)\r\n",
        "    train(models, data, params)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_gzIXfM_N03"
      },
      "source": [
        "def test_generator(generator, class_label=None):\r\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\r\n",
        "    step = 0\r\n",
        "    if class_label is None:\r\n",
        "        num_labels = 10\r\n",
        "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\r\n",
        "    else:\r\n",
        "        noise_class = np.zeros((16, 10))\r\n",
        "        noise_class[:,class_label] = 1\r\n",
        "        step = class_label\r\n",
        "\r\n",
        "    plot_images(generator,\r\n",
        "                noise_input=noise_input,\r\n",
        "                noise_class=noise_class,\r\n",
        "                show=True,\r\n",
        "                step=step,\r\n",
        "                model_name=\"test_outputs\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhbsKE-Ozs_F",
        "outputId": "2112f91f-3b97-4067-fa63-de7294f740d0"
      },
      "source": [
        "build_and_train_models()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "35005: [discriminator loss: 0.617507, acc: 0.632812] [adversarial loss: 1.129732, acc: 0.187500]\n",
            "35006: [discriminator loss: 0.568334, acc: 0.718750] [adversarial loss: 0.861671, acc: 0.421875]\n",
            "35007: [discriminator loss: 0.544283, acc: 0.710938] [adversarial loss: 1.230737, acc: 0.171875]\n",
            "35008: [discriminator loss: 0.560755, acc: 0.703125] [adversarial loss: 0.980587, acc: 0.312500]\n",
            "35009: [discriminator loss: 0.588732, acc: 0.671875] [adversarial loss: 1.139206, acc: 0.187500]\n",
            "35010: [discriminator loss: 0.632845, acc: 0.601562] [adversarial loss: 0.909235, acc: 0.406250]\n",
            "35011: [discriminator loss: 0.604311, acc: 0.664062] [adversarial loss: 1.333366, acc: 0.093750]\n",
            "35012: [discriminator loss: 0.606215, acc: 0.656250] [adversarial loss: 1.003124, acc: 0.343750]\n",
            "35013: [discriminator loss: 0.624749, acc: 0.687500] [adversarial loss: 1.113688, acc: 0.234375]\n",
            "35014: [discriminator loss: 0.607759, acc: 0.648438] [adversarial loss: 0.798950, acc: 0.468750]\n",
            "35015: [discriminator loss: 0.611081, acc: 0.664062] [adversarial loss: 1.030304, acc: 0.296875]\n",
            "35016: [discriminator loss: 0.650983, acc: 0.625000] [adversarial loss: 0.934437, acc: 0.250000]\n",
            "35017: [discriminator loss: 0.639411, acc: 0.585938] [adversarial loss: 1.118132, acc: 0.203125]\n",
            "35018: [discriminator loss: 0.585816, acc: 0.718750] [adversarial loss: 1.099745, acc: 0.203125]\n",
            "35019: [discriminator loss: 0.578901, acc: 0.695312] [adversarial loss: 1.125862, acc: 0.218750]\n",
            "35020: [discriminator loss: 0.577030, acc: 0.664062] [adversarial loss: 1.069011, acc: 0.343750]\n",
            "35021: [discriminator loss: 0.576992, acc: 0.687500] [adversarial loss: 1.226951, acc: 0.234375]\n",
            "35022: [discriminator loss: 0.622360, acc: 0.609375] [adversarial loss: 1.061599, acc: 0.312500]\n",
            "35023: [discriminator loss: 0.606866, acc: 0.671875] [adversarial loss: 0.802977, acc: 0.453125]\n",
            "35024: [discriminator loss: 0.684593, acc: 0.593750] [adversarial loss: 1.267939, acc: 0.125000]\n",
            "35025: [discriminator loss: 0.572955, acc: 0.648438] [adversarial loss: 0.825663, acc: 0.453125]\n",
            "35026: [discriminator loss: 0.653044, acc: 0.656250] [adversarial loss: 1.295296, acc: 0.125000]\n",
            "35027: [discriminator loss: 0.616058, acc: 0.648438] [adversarial loss: 0.922811, acc: 0.453125]\n",
            "35028: [discriminator loss: 0.600880, acc: 0.648438] [adversarial loss: 0.897068, acc: 0.390625]\n",
            "35029: [discriminator loss: 0.573246, acc: 0.679688] [adversarial loss: 1.095718, acc: 0.187500]\n",
            "35030: [discriminator loss: 0.551797, acc: 0.750000] [adversarial loss: 0.892763, acc: 0.359375]\n",
            "35031: [discriminator loss: 0.568226, acc: 0.742188] [adversarial loss: 1.261229, acc: 0.203125]\n",
            "35032: [discriminator loss: 0.577438, acc: 0.703125] [adversarial loss: 0.821952, acc: 0.421875]\n",
            "35033: [discriminator loss: 0.602038, acc: 0.609375] [adversarial loss: 1.051299, acc: 0.265625]\n",
            "35034: [discriminator loss: 0.618375, acc: 0.601562] [adversarial loss: 1.016258, acc: 0.359375]\n",
            "35035: [discriminator loss: 0.638721, acc: 0.625000] [adversarial loss: 1.010147, acc: 0.218750]\n",
            "35036: [discriminator loss: 0.601843, acc: 0.632812] [adversarial loss: 0.813696, acc: 0.468750]\n",
            "35037: [discriminator loss: 0.545054, acc: 0.734375] [adversarial loss: 1.158878, acc: 0.203125]\n",
            "35038: [discriminator loss: 0.572201, acc: 0.687500] [adversarial loss: 0.881261, acc: 0.359375]\n",
            "35039: [discriminator loss: 0.551292, acc: 0.734375] [adversarial loss: 1.242921, acc: 0.187500]\n",
            "35040: [discriminator loss: 0.660632, acc: 0.679688] [adversarial loss: 0.884008, acc: 0.375000]\n",
            "35041: [discriminator loss: 0.713452, acc: 0.601562] [adversarial loss: 1.088517, acc: 0.218750]\n",
            "35042: [discriminator loss: 0.584553, acc: 0.703125] [adversarial loss: 0.959215, acc: 0.296875]\n",
            "35043: [discriminator loss: 0.619213, acc: 0.671875] [adversarial loss: 0.788769, acc: 0.421875]\n",
            "35044: [discriminator loss: 0.592338, acc: 0.679688] [adversarial loss: 1.046208, acc: 0.265625]\n",
            "35045: [discriminator loss: 0.594157, acc: 0.679688] [adversarial loss: 0.942461, acc: 0.312500]\n",
            "35046: [discriminator loss: 0.587348, acc: 0.625000] [adversarial loss: 0.990936, acc: 0.406250]\n",
            "35047: [discriminator loss: 0.588678, acc: 0.671875] [adversarial loss: 0.928329, acc: 0.390625]\n",
            "35048: [discriminator loss: 0.590037, acc: 0.695312] [adversarial loss: 1.129049, acc: 0.250000]\n",
            "35049: [discriminator loss: 0.557897, acc: 0.726562] [adversarial loss: 0.800950, acc: 0.390625]\n",
            "35050: [discriminator loss: 0.592365, acc: 0.703125] [adversarial loss: 1.140209, acc: 0.203125]\n",
            "35051: [discriminator loss: 0.639538, acc: 0.671875] [adversarial loss: 0.765775, acc: 0.546875]\n",
            "35052: [discriminator loss: 0.600569, acc: 0.617188] [adversarial loss: 1.061999, acc: 0.234375]\n",
            "35053: [discriminator loss: 0.603374, acc: 0.679688] [adversarial loss: 1.033012, acc: 0.312500]\n",
            "35054: [discriminator loss: 0.509497, acc: 0.742188] [adversarial loss: 0.983028, acc: 0.375000]\n",
            "35055: [discriminator loss: 0.563971, acc: 0.742188] [adversarial loss: 1.192559, acc: 0.156250]\n",
            "35056: [discriminator loss: 0.607878, acc: 0.664062] [adversarial loss: 0.868566, acc: 0.421875]\n",
            "35057: [discriminator loss: 0.591070, acc: 0.687500] [adversarial loss: 1.079100, acc: 0.187500]\n",
            "35058: [discriminator loss: 0.606836, acc: 0.695312] [adversarial loss: 0.864130, acc: 0.453125]\n",
            "35059: [discriminator loss: 0.605293, acc: 0.671875] [adversarial loss: 1.020671, acc: 0.296875]\n",
            "35060: [discriminator loss: 0.586743, acc: 0.679688] [adversarial loss: 0.853927, acc: 0.515625]\n",
            "35061: [discriminator loss: 0.575170, acc: 0.718750] [adversarial loss: 1.099643, acc: 0.171875]\n",
            "35062: [discriminator loss: 0.646586, acc: 0.601562] [adversarial loss: 0.782318, acc: 0.453125]\n",
            "35063: [discriminator loss: 0.686084, acc: 0.609375] [adversarial loss: 1.463724, acc: 0.125000]\n",
            "35064: [discriminator loss: 0.591747, acc: 0.617188] [adversarial loss: 0.901225, acc: 0.390625]\n",
            "35065: [discriminator loss: 0.552428, acc: 0.687500] [adversarial loss: 1.138855, acc: 0.250000]\n",
            "35066: [discriminator loss: 0.615278, acc: 0.695312] [adversarial loss: 0.988930, acc: 0.343750]\n",
            "35067: [discriminator loss: 0.580459, acc: 0.757812] [adversarial loss: 1.097462, acc: 0.328125]\n",
            "35068: [discriminator loss: 0.645845, acc: 0.656250] [adversarial loss: 0.919959, acc: 0.375000]\n",
            "35069: [discriminator loss: 0.598190, acc: 0.625000] [adversarial loss: 1.018195, acc: 0.343750]\n",
            "35070: [discriminator loss: 0.627438, acc: 0.617188] [adversarial loss: 1.075487, acc: 0.281250]\n",
            "35071: [discriminator loss: 0.550443, acc: 0.671875] [adversarial loss: 0.860794, acc: 0.453125]\n",
            "35072: [discriminator loss: 0.567509, acc: 0.671875] [adversarial loss: 1.074320, acc: 0.296875]\n",
            "35073: [discriminator loss: 0.644466, acc: 0.648438] [adversarial loss: 0.991528, acc: 0.312500]\n",
            "35074: [discriminator loss: 0.635617, acc: 0.578125] [adversarial loss: 1.034134, acc: 0.296875]\n",
            "35075: [discriminator loss: 0.566743, acc: 0.718750] [adversarial loss: 1.047730, acc: 0.250000]\n",
            "35076: [discriminator loss: 0.577142, acc: 0.687500] [adversarial loss: 1.198642, acc: 0.218750]\n",
            "35077: [discriminator loss: 0.586241, acc: 0.648438] [adversarial loss: 0.913105, acc: 0.390625]\n",
            "35078: [discriminator loss: 0.609569, acc: 0.625000] [adversarial loss: 1.233871, acc: 0.109375]\n",
            "35079: [discriminator loss: 0.690153, acc: 0.585938] [adversarial loss: 0.696121, acc: 0.609375]\n",
            "35080: [discriminator loss: 0.666160, acc: 0.617188] [adversarial loss: 1.150209, acc: 0.171875]\n",
            "35081: [discriminator loss: 0.546998, acc: 0.726562] [adversarial loss: 0.820467, acc: 0.515625]\n",
            "35082: [discriminator loss: 0.597066, acc: 0.640625] [adversarial loss: 1.291893, acc: 0.140625]\n",
            "35083: [discriminator loss: 0.584193, acc: 0.703125] [adversarial loss: 0.970852, acc: 0.390625]\n",
            "35084: [discriminator loss: 0.565244, acc: 0.718750] [adversarial loss: 1.129744, acc: 0.296875]\n",
            "35085: [discriminator loss: 0.547970, acc: 0.718750] [adversarial loss: 1.026578, acc: 0.359375]\n",
            "35086: [discriminator loss: 0.563838, acc: 0.734375] [adversarial loss: 1.140049, acc: 0.281250]\n",
            "35087: [discriminator loss: 0.575648, acc: 0.750000] [adversarial loss: 0.911767, acc: 0.421875]\n",
            "35088: [discriminator loss: 0.548775, acc: 0.726562] [adversarial loss: 1.088598, acc: 0.328125]\n",
            "35089: [discriminator loss: 0.597222, acc: 0.640625] [adversarial loss: 0.988462, acc: 0.359375]\n",
            "35090: [discriminator loss: 0.548319, acc: 0.710938] [adversarial loss: 1.148434, acc: 0.234375]\n",
            "35091: [discriminator loss: 0.598162, acc: 0.656250] [adversarial loss: 1.169175, acc: 0.312500]\n",
            "35092: [discriminator loss: 0.595636, acc: 0.703125] [adversarial loss: 1.065715, acc: 0.296875]\n",
            "35093: [discriminator loss: 0.585353, acc: 0.703125] [adversarial loss: 1.215343, acc: 0.171875]\n",
            "35094: [discriminator loss: 0.544452, acc: 0.750000] [adversarial loss: 0.905184, acc: 0.390625]\n",
            "35095: [discriminator loss: 0.570566, acc: 0.687500] [adversarial loss: 1.250393, acc: 0.109375]\n",
            "35096: [discriminator loss: 0.615796, acc: 0.617188] [adversarial loss: 0.805943, acc: 0.453125]\n",
            "35097: [discriminator loss: 0.607210, acc: 0.640625] [adversarial loss: 1.067832, acc: 0.187500]\n",
            "35098: [discriminator loss: 0.581792, acc: 0.687500] [adversarial loss: 0.993958, acc: 0.250000]\n",
            "35099: [discriminator loss: 0.648995, acc: 0.578125] [adversarial loss: 1.254195, acc: 0.156250]\n",
            "35100: [discriminator loss: 0.628368, acc: 0.664062] [adversarial loss: 0.961495, acc: 0.343750]\n",
            "35101: [discriminator loss: 0.619821, acc: 0.664062] [adversarial loss: 0.983235, acc: 0.343750]\n",
            "35102: [discriminator loss: 0.585943, acc: 0.703125] [adversarial loss: 1.023443, acc: 0.390625]\n",
            "35103: [discriminator loss: 0.548353, acc: 0.687500] [adversarial loss: 0.915585, acc: 0.437500]\n",
            "35104: [discriminator loss: 0.680307, acc: 0.585938] [adversarial loss: 1.314404, acc: 0.140625]\n",
            "35105: [discriminator loss: 0.626986, acc: 0.632812] [adversarial loss: 0.901047, acc: 0.421875]\n",
            "35106: [discriminator loss: 0.664830, acc: 0.585938] [adversarial loss: 1.214255, acc: 0.171875]\n",
            "35107: [discriminator loss: 0.617606, acc: 0.609375] [adversarial loss: 0.827331, acc: 0.500000]\n",
            "35108: [discriminator loss: 0.586278, acc: 0.679688] [adversarial loss: 1.238583, acc: 0.156250]\n",
            "35109: [discriminator loss: 0.579333, acc: 0.718750] [adversarial loss: 0.986274, acc: 0.281250]\n",
            "35110: [discriminator loss: 0.603795, acc: 0.640625] [adversarial loss: 1.114143, acc: 0.218750]\n",
            "35111: [discriminator loss: 0.616453, acc: 0.640625] [adversarial loss: 1.021864, acc: 0.312500]\n",
            "35112: [discriminator loss: 0.647170, acc: 0.648438] [adversarial loss: 1.214309, acc: 0.156250]\n",
            "35113: [discriminator loss: 0.641322, acc: 0.609375] [adversarial loss: 0.801722, acc: 0.531250]\n",
            "35114: [discriminator loss: 0.584172, acc: 0.695312] [adversarial loss: 1.182269, acc: 0.234375]\n",
            "35115: [discriminator loss: 0.576378, acc: 0.656250] [adversarial loss: 0.972129, acc: 0.375000]\n",
            "35116: [discriminator loss: 0.614828, acc: 0.640625] [adversarial loss: 1.046476, acc: 0.250000]\n",
            "35117: [discriminator loss: 0.649291, acc: 0.648438] [adversarial loss: 1.287766, acc: 0.125000]\n",
            "35118: [discriminator loss: 0.619509, acc: 0.625000] [adversarial loss: 0.917222, acc: 0.328125]\n",
            "35119: [discriminator loss: 0.584752, acc: 0.671875] [adversarial loss: 0.970027, acc: 0.296875]\n",
            "35120: [discriminator loss: 0.531995, acc: 0.710938] [adversarial loss: 0.927402, acc: 0.359375]\n",
            "35121: [discriminator loss: 0.589544, acc: 0.710938] [adversarial loss: 1.123401, acc: 0.250000]\n",
            "35122: [discriminator loss: 0.627922, acc: 0.640625] [adversarial loss: 0.902563, acc: 0.375000]\n",
            "35123: [discriminator loss: 0.556500, acc: 0.734375] [adversarial loss: 1.092710, acc: 0.296875]\n",
            "35124: [discriminator loss: 0.559730, acc: 0.671875] [adversarial loss: 0.837475, acc: 0.437500]\n",
            "35125: [discriminator loss: 0.580552, acc: 0.726562] [adversarial loss: 1.429197, acc: 0.140625]\n",
            "35126: [discriminator loss: 0.597351, acc: 0.710938] [adversarial loss: 0.823846, acc: 0.437500]\n",
            "35127: [discriminator loss: 0.592721, acc: 0.695312] [adversarial loss: 1.157350, acc: 0.234375]\n",
            "35128: [discriminator loss: 0.581126, acc: 0.695312] [adversarial loss: 0.981612, acc: 0.359375]\n",
            "35129: [discriminator loss: 0.549082, acc: 0.726562] [adversarial loss: 0.886751, acc: 0.359375]\n",
            "35130: [discriminator loss: 0.540434, acc: 0.710938] [adversarial loss: 1.140977, acc: 0.218750]\n",
            "35131: [discriminator loss: 0.606103, acc: 0.679688] [adversarial loss: 0.826401, acc: 0.515625]\n",
            "35132: [discriminator loss: 0.568323, acc: 0.734375] [adversarial loss: 1.257126, acc: 0.250000]\n",
            "35133: [discriminator loss: 0.574641, acc: 0.687500] [adversarial loss: 0.877987, acc: 0.406250]\n",
            "35134: [discriminator loss: 0.630112, acc: 0.617188] [adversarial loss: 1.058680, acc: 0.281250]\n",
            "35135: [discriminator loss: 0.541183, acc: 0.734375] [adversarial loss: 0.970822, acc: 0.265625]\n",
            "35136: [discriminator loss: 0.634559, acc: 0.625000] [adversarial loss: 1.102607, acc: 0.296875]\n",
            "35137: [discriminator loss: 0.593087, acc: 0.695312] [adversarial loss: 1.069904, acc: 0.234375]\n",
            "35138: [discriminator loss: 0.558658, acc: 0.742188] [adversarial loss: 0.996702, acc: 0.328125]\n",
            "35139: [discriminator loss: 0.634665, acc: 0.625000] [adversarial loss: 1.065776, acc: 0.296875]\n",
            "35140: [discriminator loss: 0.683874, acc: 0.617188] [adversarial loss: 1.071902, acc: 0.312500]\n",
            "35141: [discriminator loss: 0.664553, acc: 0.617188] [adversarial loss: 1.055902, acc: 0.203125]\n",
            "35142: [discriminator loss: 0.557696, acc: 0.742188] [adversarial loss: 1.021118, acc: 0.265625]\n",
            "35143: [discriminator loss: 0.518960, acc: 0.757812] [adversarial loss: 1.053950, acc: 0.250000]\n",
            "35144: [discriminator loss: 0.645220, acc: 0.625000] [adversarial loss: 1.021682, acc: 0.390625]\n",
            "35145: [discriminator loss: 0.655270, acc: 0.648438] [adversarial loss: 1.097280, acc: 0.296875]\n",
            "35146: [discriminator loss: 0.587015, acc: 0.718750] [adversarial loss: 0.810434, acc: 0.468750]\n",
            "35147: [discriminator loss: 0.622617, acc: 0.687500] [adversarial loss: 0.898813, acc: 0.375000]\n",
            "35148: [discriminator loss: 0.601382, acc: 0.687500] [adversarial loss: 1.202024, acc: 0.187500]\n",
            "35149: [discriminator loss: 0.611396, acc: 0.640625] [adversarial loss: 0.822947, acc: 0.468750]\n",
            "35150: [discriminator loss: 0.622241, acc: 0.687500] [adversarial loss: 1.238336, acc: 0.171875]\n",
            "35151: [discriminator loss: 0.617512, acc: 0.648438] [adversarial loss: 0.810328, acc: 0.484375]\n",
            "35152: [discriminator loss: 0.616331, acc: 0.718750] [adversarial loss: 1.265584, acc: 0.125000]\n",
            "35153: [discriminator loss: 0.580154, acc: 0.695312] [adversarial loss: 0.736618, acc: 0.515625]\n",
            "35154: [discriminator loss: 0.637618, acc: 0.656250] [adversarial loss: 1.176254, acc: 0.203125]\n",
            "35155: [discriminator loss: 0.569690, acc: 0.687500] [adversarial loss: 0.689446, acc: 0.593750]\n",
            "35156: [discriminator loss: 0.594752, acc: 0.710938] [adversarial loss: 1.086138, acc: 0.265625]\n",
            "35157: [discriminator loss: 0.565629, acc: 0.718750] [adversarial loss: 0.858078, acc: 0.437500]\n",
            "35158: [discriminator loss: 0.618883, acc: 0.648438] [adversarial loss: 1.113800, acc: 0.265625]\n",
            "35159: [discriminator loss: 0.617296, acc: 0.593750] [adversarial loss: 0.939919, acc: 0.312500]\n",
            "35160: [discriminator loss: 0.567202, acc: 0.687500] [adversarial loss: 1.067516, acc: 0.265625]\n",
            "35161: [discriminator loss: 0.574348, acc: 0.671875] [adversarial loss: 0.988765, acc: 0.312500]\n",
            "35162: [discriminator loss: 0.565118, acc: 0.734375] [adversarial loss: 0.886796, acc: 0.359375]\n",
            "35163: [discriminator loss: 0.568834, acc: 0.640625] [adversarial loss: 1.023990, acc: 0.250000]\n",
            "35164: [discriminator loss: 0.596841, acc: 0.671875] [adversarial loss: 1.097739, acc: 0.265625]\n",
            "35165: [discriminator loss: 0.573017, acc: 0.679688] [adversarial loss: 1.066838, acc: 0.218750]\n",
            "35166: [discriminator loss: 0.627327, acc: 0.640625] [adversarial loss: 0.840925, acc: 0.437500]\n",
            "35167: [discriminator loss: 0.583878, acc: 0.679688] [adversarial loss: 1.194911, acc: 0.250000]\n",
            "35168: [discriminator loss: 0.618328, acc: 0.648438] [adversarial loss: 0.803949, acc: 0.515625]\n",
            "35169: [discriminator loss: 0.610177, acc: 0.695312] [adversarial loss: 1.162909, acc: 0.187500]\n",
            "35170: [discriminator loss: 0.580280, acc: 0.687500] [adversarial loss: 0.869285, acc: 0.406250]\n",
            "35171: [discriminator loss: 0.596418, acc: 0.679688] [adversarial loss: 1.069111, acc: 0.218750]\n",
            "35172: [discriminator loss: 0.653858, acc: 0.632812] [adversarial loss: 0.791088, acc: 0.500000]\n",
            "35173: [discriminator loss: 0.602909, acc: 0.695312] [adversarial loss: 1.120467, acc: 0.234375]\n",
            "35174: [discriminator loss: 0.567087, acc: 0.695312] [adversarial loss: 1.040710, acc: 0.218750]\n",
            "35175: [discriminator loss: 0.570906, acc: 0.703125] [adversarial loss: 1.253228, acc: 0.171875]\n",
            "35176: [discriminator loss: 0.592042, acc: 0.687500] [adversarial loss: 1.064244, acc: 0.296875]\n",
            "35177: [discriminator loss: 0.542951, acc: 0.726562] [adversarial loss: 1.140456, acc: 0.187500]\n",
            "35178: [discriminator loss: 0.590259, acc: 0.687500] [adversarial loss: 1.037115, acc: 0.296875]\n",
            "35179: [discriminator loss: 0.581681, acc: 0.687500] [adversarial loss: 1.288432, acc: 0.109375]\n",
            "35180: [discriminator loss: 0.581377, acc: 0.679688] [adversarial loss: 0.802633, acc: 0.421875]\n",
            "35181: [discriminator loss: 0.585660, acc: 0.671875] [adversarial loss: 1.139055, acc: 0.312500]\n",
            "35182: [discriminator loss: 0.631748, acc: 0.625000] [adversarial loss: 0.930786, acc: 0.375000]\n",
            "35183: [discriminator loss: 0.593217, acc: 0.640625] [adversarial loss: 1.109541, acc: 0.250000]\n",
            "35184: [discriminator loss: 0.579343, acc: 0.718750] [adversarial loss: 1.045721, acc: 0.265625]\n",
            "35185: [discriminator loss: 0.621588, acc: 0.601562] [adversarial loss: 0.934477, acc: 0.390625]\n",
            "35186: [discriminator loss: 0.555714, acc: 0.710938] [adversarial loss: 1.096196, acc: 0.250000]\n",
            "35187: [discriminator loss: 0.598758, acc: 0.679688] [adversarial loss: 1.171042, acc: 0.203125]\n",
            "35188: [discriminator loss: 0.616267, acc: 0.656250] [adversarial loss: 0.896789, acc: 0.406250]\n",
            "35189: [discriminator loss: 0.605504, acc: 0.679688] [adversarial loss: 1.309248, acc: 0.140625]\n",
            "35190: [discriminator loss: 0.597754, acc: 0.664062] [adversarial loss: 0.798773, acc: 0.484375]\n",
            "35191: [discriminator loss: 0.605630, acc: 0.664062] [adversarial loss: 1.076459, acc: 0.296875]\n",
            "35192: [discriminator loss: 0.583226, acc: 0.632812] [adversarial loss: 0.862293, acc: 0.437500]\n",
            "35193: [discriminator loss: 0.571502, acc: 0.687500] [adversarial loss: 1.136001, acc: 0.171875]\n",
            "35194: [discriminator loss: 0.632255, acc: 0.640625] [adversarial loss: 0.931021, acc: 0.406250]\n",
            "35195: [discriminator loss: 0.592570, acc: 0.664062] [adversarial loss: 1.261494, acc: 0.203125]\n",
            "35196: [discriminator loss: 0.577591, acc: 0.687500] [adversarial loss: 0.814091, acc: 0.390625]\n",
            "35197: [discriminator loss: 0.618790, acc: 0.640625] [adversarial loss: 1.370905, acc: 0.140625]\n",
            "35198: [discriminator loss: 0.600031, acc: 0.617188] [adversarial loss: 0.921959, acc: 0.390625]\n",
            "35199: [discriminator loss: 0.581359, acc: 0.664062] [adversarial loss: 1.259518, acc: 0.234375]\n",
            "35200: [discriminator loss: 0.548614, acc: 0.695312] [adversarial loss: 1.099605, acc: 0.281250]\n",
            "35201: [discriminator loss: 0.571752, acc: 0.703125] [adversarial loss: 1.070827, acc: 0.375000]\n",
            "35202: [discriminator loss: 0.659300, acc: 0.664062] [adversarial loss: 1.196804, acc: 0.265625]\n",
            "35203: [discriminator loss: 0.614086, acc: 0.718750] [adversarial loss: 0.998452, acc: 0.343750]\n",
            "35204: [discriminator loss: 0.625206, acc: 0.664062] [adversarial loss: 1.061683, acc: 0.281250]\n",
            "35205: [discriminator loss: 0.569078, acc: 0.671875] [adversarial loss: 1.063507, acc: 0.375000]\n",
            "35206: [discriminator loss: 0.509607, acc: 0.742188] [adversarial loss: 0.901266, acc: 0.468750]\n",
            "35207: [discriminator loss: 0.563840, acc: 0.695312] [adversarial loss: 1.285610, acc: 0.218750]\n",
            "35208: [discriminator loss: 0.551836, acc: 0.695312] [adversarial loss: 0.830808, acc: 0.484375]\n",
            "35209: [discriminator loss: 0.625239, acc: 0.640625] [adversarial loss: 1.412416, acc: 0.187500]\n",
            "35210: [discriminator loss: 0.653291, acc: 0.625000] [adversarial loss: 0.857502, acc: 0.421875]\n",
            "35211: [discriminator loss: 0.556654, acc: 0.726562] [adversarial loss: 1.417760, acc: 0.140625]\n",
            "35212: [discriminator loss: 0.584932, acc: 0.695312] [adversarial loss: 0.819224, acc: 0.437500]\n",
            "35213: [discriminator loss: 0.597615, acc: 0.656250] [adversarial loss: 1.104859, acc: 0.171875]\n",
            "35214: [discriminator loss: 0.595028, acc: 0.718750] [adversarial loss: 0.887336, acc: 0.359375]\n",
            "35215: [discriminator loss: 0.590111, acc: 0.640625] [adversarial loss: 1.187861, acc: 0.218750]\n",
            "35216: [discriminator loss: 0.568902, acc: 0.679688] [adversarial loss: 0.825530, acc: 0.421875]\n",
            "35217: [discriminator loss: 0.573693, acc: 0.703125] [adversarial loss: 1.089697, acc: 0.234375]\n",
            "35218: [discriminator loss: 0.540497, acc: 0.726562] [adversarial loss: 0.839745, acc: 0.468750]\n",
            "35219: [discriminator loss: 0.603049, acc: 0.703125] [adversarial loss: 1.095299, acc: 0.281250]\n",
            "35220: [discriminator loss: 0.645094, acc: 0.593750] [adversarial loss: 0.770588, acc: 0.515625]\n",
            "35221: [discriminator loss: 0.642092, acc: 0.632812] [adversarial loss: 1.172142, acc: 0.203125]\n",
            "35222: [discriminator loss: 0.581824, acc: 0.664062] [adversarial loss: 0.828419, acc: 0.453125]\n",
            "35223: [discriminator loss: 0.626542, acc: 0.625000] [adversarial loss: 1.072976, acc: 0.281250]\n",
            "35224: [discriminator loss: 0.553638, acc: 0.734375] [adversarial loss: 0.955722, acc: 0.359375]\n",
            "35225: [discriminator loss: 0.628429, acc: 0.625000] [adversarial loss: 1.181766, acc: 0.234375]\n",
            "35226: [discriminator loss: 0.621191, acc: 0.648438] [adversarial loss: 1.019441, acc: 0.343750]\n",
            "35227: [discriminator loss: 0.639568, acc: 0.687500] [adversarial loss: 1.091439, acc: 0.250000]\n",
            "35228: [discriminator loss: 0.583752, acc: 0.679688] [adversarial loss: 1.013507, acc: 0.296875]\n",
            "35229: [discriminator loss: 0.614179, acc: 0.664062] [adversarial loss: 0.891367, acc: 0.375000]\n",
            "35230: [discriminator loss: 0.633178, acc: 0.679688] [adversarial loss: 1.010677, acc: 0.265625]\n",
            "35231: [discriminator loss: 0.568331, acc: 0.726562] [adversarial loss: 1.260212, acc: 0.218750]\n",
            "35232: [discriminator loss: 0.671673, acc: 0.601562] [adversarial loss: 0.977348, acc: 0.359375]\n",
            "35233: [discriminator loss: 0.565537, acc: 0.742188] [adversarial loss: 1.431809, acc: 0.125000]\n",
            "35234: [discriminator loss: 0.591381, acc: 0.695312] [adversarial loss: 0.925036, acc: 0.406250]\n",
            "35235: [discriminator loss: 0.591959, acc: 0.679688] [adversarial loss: 0.860278, acc: 0.390625]\n",
            "35236: [discriminator loss: 0.567646, acc: 0.679688] [adversarial loss: 0.969956, acc: 0.359375]\n",
            "35237: [discriminator loss: 0.561384, acc: 0.718750] [adversarial loss: 0.995996, acc: 0.296875]\n",
            "35238: [discriminator loss: 0.557953, acc: 0.710938] [adversarial loss: 0.794763, acc: 0.515625]\n",
            "35239: [discriminator loss: 0.668186, acc: 0.585938] [adversarial loss: 1.114545, acc: 0.234375]\n",
            "35240: [discriminator loss: 0.607861, acc: 0.671875] [adversarial loss: 0.960108, acc: 0.328125]\n",
            "35241: [discriminator loss: 0.604063, acc: 0.679688] [adversarial loss: 1.101333, acc: 0.234375]\n",
            "35242: [discriminator loss: 0.590434, acc: 0.703125] [adversarial loss: 1.043087, acc: 0.328125]\n",
            "35243: [discriminator loss: 0.535180, acc: 0.726562] [adversarial loss: 0.983682, acc: 0.328125]\n",
            "35244: [discriminator loss: 0.625939, acc: 0.664062] [adversarial loss: 1.170056, acc: 0.203125]\n",
            "35245: [discriminator loss: 0.635775, acc: 0.632812] [adversarial loss: 0.848599, acc: 0.453125]\n",
            "35246: [discriminator loss: 0.614957, acc: 0.656250] [adversarial loss: 1.044199, acc: 0.250000]\n",
            "35247: [discriminator loss: 0.600703, acc: 0.656250] [adversarial loss: 1.016479, acc: 0.359375]\n",
            "35248: [discriminator loss: 0.563140, acc: 0.679688] [adversarial loss: 1.070490, acc: 0.281250]\n",
            "35249: [discriminator loss: 0.595714, acc: 0.679688] [adversarial loss: 0.868330, acc: 0.468750]\n",
            "35250: [discriminator loss: 0.607865, acc: 0.687500] [adversarial loss: 1.391165, acc: 0.046875]\n",
            "35251: [discriminator loss: 0.627429, acc: 0.640625] [adversarial loss: 0.860338, acc: 0.437500]\n",
            "35252: [discriminator loss: 0.612135, acc: 0.656250] [adversarial loss: 1.103451, acc: 0.281250]\n",
            "35253: [discriminator loss: 0.582772, acc: 0.710938] [adversarial loss: 1.025519, acc: 0.281250]\n",
            "35254: [discriminator loss: 0.595182, acc: 0.664062] [adversarial loss: 0.961180, acc: 0.359375]\n",
            "35255: [discriminator loss: 0.587300, acc: 0.687500] [adversarial loss: 1.158123, acc: 0.171875]\n",
            "35256: [discriminator loss: 0.628632, acc: 0.601562] [adversarial loss: 0.898544, acc: 0.468750]\n",
            "35257: [discriminator loss: 0.687436, acc: 0.640625] [adversarial loss: 1.316554, acc: 0.203125]\n",
            "35258: [discriminator loss: 0.595140, acc: 0.648438] [adversarial loss: 0.685494, acc: 0.625000]\n",
            "35259: [discriminator loss: 0.583467, acc: 0.703125] [adversarial loss: 1.250440, acc: 0.109375]\n",
            "35260: [discriminator loss: 0.637350, acc: 0.648438] [adversarial loss: 0.804469, acc: 0.468750]\n",
            "35261: [discriminator loss: 0.567485, acc: 0.726562] [adversarial loss: 1.101916, acc: 0.203125]\n",
            "35262: [discriminator loss: 0.568914, acc: 0.640625] [adversarial loss: 1.004589, acc: 0.250000]\n",
            "35263: [discriminator loss: 0.585533, acc: 0.695312] [adversarial loss: 1.182651, acc: 0.250000]\n",
            "35264: [discriminator loss: 0.572019, acc: 0.671875] [adversarial loss: 1.143661, acc: 0.250000]\n",
            "35265: [discriminator loss: 0.555056, acc: 0.750000] [adversarial loss: 1.152793, acc: 0.218750]\n",
            "35266: [discriminator loss: 0.684978, acc: 0.601562] [adversarial loss: 1.001130, acc: 0.406250]\n",
            "35267: [discriminator loss: 0.651177, acc: 0.625000] [adversarial loss: 0.972251, acc: 0.359375]\n",
            "35268: [discriminator loss: 0.542648, acc: 0.695312] [adversarial loss: 1.100654, acc: 0.265625]\n",
            "35269: [discriminator loss: 0.540269, acc: 0.726562] [adversarial loss: 1.040732, acc: 0.218750]\n",
            "35270: [discriminator loss: 0.586082, acc: 0.718750] [adversarial loss: 0.968022, acc: 0.312500]\n",
            "35271: [discriminator loss: 0.632286, acc: 0.625000] [adversarial loss: 1.085765, acc: 0.203125]\n",
            "35272: [discriminator loss: 0.561959, acc: 0.710938] [adversarial loss: 1.031181, acc: 0.250000]\n",
            "35273: [discriminator loss: 0.600275, acc: 0.656250] [adversarial loss: 1.250775, acc: 0.125000]\n",
            "35274: [discriminator loss: 0.580962, acc: 0.648438] [adversarial loss: 0.731162, acc: 0.640625]\n",
            "35275: [discriminator loss: 0.627437, acc: 0.648438] [adversarial loss: 1.306995, acc: 0.109375]\n",
            "35276: [discriminator loss: 0.569091, acc: 0.757812] [adversarial loss: 0.814893, acc: 0.453125]\n",
            "35277: [discriminator loss: 0.550864, acc: 0.718750] [adversarial loss: 1.304116, acc: 0.203125]\n",
            "35278: [discriminator loss: 0.651679, acc: 0.703125] [adversarial loss: 1.234694, acc: 0.203125]\n",
            "35279: [discriminator loss: 0.639178, acc: 0.609375] [adversarial loss: 0.847886, acc: 0.421875]\n",
            "35280: [discriminator loss: 0.612939, acc: 0.687500] [adversarial loss: 1.368399, acc: 0.140625]\n",
            "35281: [discriminator loss: 0.625005, acc: 0.632812] [adversarial loss: 0.913282, acc: 0.421875]\n",
            "35282: [discriminator loss: 0.620651, acc: 0.671875] [adversarial loss: 1.298958, acc: 0.109375]\n",
            "35283: [discriminator loss: 0.594890, acc: 0.679688] [adversarial loss: 0.954720, acc: 0.375000]\n",
            "35284: [discriminator loss: 0.612306, acc: 0.617188] [adversarial loss: 0.873118, acc: 0.468750]\n",
            "35285: [discriminator loss: 0.535068, acc: 0.757812] [adversarial loss: 0.986195, acc: 0.265625]\n",
            "35286: [discriminator loss: 0.584990, acc: 0.687500] [adversarial loss: 0.979488, acc: 0.328125]\n",
            "35287: [discriminator loss: 0.591248, acc: 0.671875] [adversarial loss: 1.176857, acc: 0.265625]\n",
            "35288: [discriminator loss: 0.582914, acc: 0.687500] [adversarial loss: 0.965460, acc: 0.296875]\n",
            "35289: [discriminator loss: 0.644852, acc: 0.656250] [adversarial loss: 0.944634, acc: 0.296875]\n",
            "35290: [discriminator loss: 0.581147, acc: 0.703125] [adversarial loss: 1.067011, acc: 0.265625]\n",
            "35291: [discriminator loss: 0.614786, acc: 0.632812] [adversarial loss: 0.968122, acc: 0.312500]\n",
            "35292: [discriminator loss: 0.597955, acc: 0.671875] [adversarial loss: 0.927330, acc: 0.406250]\n",
            "35293: [discriminator loss: 0.592351, acc: 0.656250] [adversarial loss: 1.048676, acc: 0.250000]\n",
            "35294: [discriminator loss: 0.597790, acc: 0.679688] [adversarial loss: 1.058708, acc: 0.281250]\n",
            "35295: [discriminator loss: 0.533625, acc: 0.742188] [adversarial loss: 1.038226, acc: 0.312500]\n",
            "35296: [discriminator loss: 0.559264, acc: 0.679688] [adversarial loss: 1.007085, acc: 0.296875]\n",
            "35297: [discriminator loss: 0.567333, acc: 0.687500] [adversarial loss: 1.235720, acc: 0.140625]\n",
            "35298: [discriminator loss: 0.623584, acc: 0.648438] [adversarial loss: 0.806220, acc: 0.468750]\n",
            "35299: [discriminator loss: 0.688688, acc: 0.609375] [adversarial loss: 1.438504, acc: 0.078125]\n",
            "35300: [discriminator loss: 0.616669, acc: 0.648438] [adversarial loss: 0.838765, acc: 0.468750]\n",
            "35301: [discriminator loss: 0.576324, acc: 0.687500] [adversarial loss: 1.243873, acc: 0.171875]\n",
            "35302: [discriminator loss: 0.581919, acc: 0.687500] [adversarial loss: 0.856948, acc: 0.453125]\n",
            "35303: [discriminator loss: 0.624006, acc: 0.593750] [adversarial loss: 1.196858, acc: 0.234375]\n",
            "35304: [discriminator loss: 0.653509, acc: 0.593750] [adversarial loss: 0.788046, acc: 0.562500]\n",
            "35305: [discriminator loss: 0.694135, acc: 0.593750] [adversarial loss: 1.378786, acc: 0.156250]\n",
            "35306: [discriminator loss: 0.626179, acc: 0.625000] [adversarial loss: 1.067841, acc: 0.296875]\n",
            "35307: [discriminator loss: 0.577499, acc: 0.640625] [adversarial loss: 0.969900, acc: 0.343750]\n",
            "35308: [discriminator loss: 0.587443, acc: 0.664062] [adversarial loss: 1.040515, acc: 0.281250]\n",
            "35309: [discriminator loss: 0.584613, acc: 0.703125] [adversarial loss: 0.935499, acc: 0.328125]\n",
            "35310: [discriminator loss: 0.616434, acc: 0.664062] [adversarial loss: 1.169369, acc: 0.203125]\n",
            "35311: [discriminator loss: 0.609692, acc: 0.617188] [adversarial loss: 0.872720, acc: 0.406250]\n",
            "35312: [discriminator loss: 0.615988, acc: 0.640625] [adversarial loss: 0.939508, acc: 0.312500]\n",
            "35313: [discriminator loss: 0.594523, acc: 0.656250] [adversarial loss: 1.094534, acc: 0.171875]\n",
            "35314: [discriminator loss: 0.562365, acc: 0.695312] [adversarial loss: 1.137137, acc: 0.250000]\n",
            "35315: [discriminator loss: 0.553176, acc: 0.718750] [adversarial loss: 0.835019, acc: 0.406250]\n",
            "35316: [discriminator loss: 0.563967, acc: 0.695312] [adversarial loss: 1.002389, acc: 0.312500]\n",
            "35317: [discriminator loss: 0.580626, acc: 0.671875] [adversarial loss: 0.860026, acc: 0.359375]\n",
            "35318: [discriminator loss: 0.513008, acc: 0.742188] [adversarial loss: 1.070257, acc: 0.328125]\n",
            "35319: [discriminator loss: 0.526104, acc: 0.710938] [adversarial loss: 0.864661, acc: 0.468750]\n",
            "35320: [discriminator loss: 0.594026, acc: 0.687500] [adversarial loss: 1.430336, acc: 0.156250]\n",
            "35321: [discriminator loss: 0.600611, acc: 0.679688] [adversarial loss: 0.755005, acc: 0.546875]\n",
            "35322: [discriminator loss: 0.568245, acc: 0.679688] [adversarial loss: 1.226795, acc: 0.218750]\n",
            "35323: [discriminator loss: 0.631546, acc: 0.648438] [adversarial loss: 0.856110, acc: 0.421875]\n",
            "35324: [discriminator loss: 0.651085, acc: 0.640625] [adversarial loss: 1.144303, acc: 0.250000]\n",
            "35325: [discriminator loss: 0.549300, acc: 0.742188] [adversarial loss: 0.957898, acc: 0.390625]\n",
            "35326: [discriminator loss: 0.586896, acc: 0.679688] [adversarial loss: 1.053720, acc: 0.312500]\n",
            "35327: [discriminator loss: 0.615146, acc: 0.679688] [adversarial loss: 1.000669, acc: 0.390625]\n",
            "35328: [discriminator loss: 0.568755, acc: 0.679688] [adversarial loss: 1.026333, acc: 0.312500]\n",
            "35329: [discriminator loss: 0.603496, acc: 0.640625] [adversarial loss: 0.941698, acc: 0.359375]\n",
            "35330: [discriminator loss: 0.588525, acc: 0.671875] [adversarial loss: 0.924319, acc: 0.406250]\n",
            "35331: [discriminator loss: 0.540019, acc: 0.687500] [adversarial loss: 1.052968, acc: 0.281250]\n",
            "35332: [discriminator loss: 0.575479, acc: 0.695312] [adversarial loss: 1.069281, acc: 0.218750]\n",
            "35333: [discriminator loss: 0.578651, acc: 0.710938] [adversarial loss: 1.098106, acc: 0.250000]\n",
            "35334: [discriminator loss: 0.507153, acc: 0.757812] [adversarial loss: 0.983539, acc: 0.359375]\n",
            "35335: [discriminator loss: 0.557085, acc: 0.734375] [adversarial loss: 1.133430, acc: 0.265625]\n",
            "35336: [discriminator loss: 0.579928, acc: 0.695312] [adversarial loss: 0.947888, acc: 0.421875]\n",
            "35337: [discriminator loss: 0.635014, acc: 0.671875] [adversarial loss: 1.197537, acc: 0.203125]\n",
            "35338: [discriminator loss: 0.532466, acc: 0.718750] [adversarial loss: 1.051273, acc: 0.250000]\n",
            "35339: [discriminator loss: 0.613295, acc: 0.625000] [adversarial loss: 1.084062, acc: 0.296875]\n",
            "35340: [discriminator loss: 0.670918, acc: 0.640625] [adversarial loss: 0.952110, acc: 0.359375]\n",
            "35341: [discriminator loss: 0.581774, acc: 0.671875] [adversarial loss: 1.000172, acc: 0.390625]\n",
            "35342: [discriminator loss: 0.588433, acc: 0.656250] [adversarial loss: 0.869529, acc: 0.375000]\n",
            "35343: [discriminator loss: 0.611874, acc: 0.687500] [adversarial loss: 1.326674, acc: 0.187500]\n",
            "35344: [discriminator loss: 0.549933, acc: 0.718750] [adversarial loss: 0.659156, acc: 0.578125]\n",
            "35345: [discriminator loss: 0.531881, acc: 0.734375] [adversarial loss: 1.201011, acc: 0.203125]\n",
            "35346: [discriminator loss: 0.591748, acc: 0.671875] [adversarial loss: 1.120018, acc: 0.312500]\n",
            "35347: [discriminator loss: 0.592863, acc: 0.664062] [adversarial loss: 0.909896, acc: 0.406250]\n",
            "35348: [discriminator loss: 0.556357, acc: 0.710938] [adversarial loss: 1.116336, acc: 0.171875]\n",
            "35349: [discriminator loss: 0.576714, acc: 0.695312] [adversarial loss: 0.769522, acc: 0.531250]\n",
            "35350: [discriminator loss: 0.554362, acc: 0.750000] [adversarial loss: 1.110396, acc: 0.328125]\n",
            "35351: [discriminator loss: 0.552298, acc: 0.742188] [adversarial loss: 1.022946, acc: 0.250000]\n",
            "35352: [discriminator loss: 0.544865, acc: 0.671875] [adversarial loss: 0.926164, acc: 0.437500]\n",
            "35353: [discriminator loss: 0.609551, acc: 0.671875] [adversarial loss: 1.112961, acc: 0.187500]\n",
            "35354: [discriminator loss: 0.614725, acc: 0.679688] [adversarial loss: 1.071068, acc: 0.250000]\n",
            "35355: [discriminator loss: 0.575691, acc: 0.664062] [adversarial loss: 0.822293, acc: 0.468750]\n",
            "35356: [discriminator loss: 0.642303, acc: 0.640625] [adversarial loss: 1.395821, acc: 0.125000]\n",
            "35357: [discriminator loss: 0.605346, acc: 0.695312] [adversarial loss: 0.767521, acc: 0.500000]\n",
            "35358: [discriminator loss: 0.577190, acc: 0.695312] [adversarial loss: 1.099089, acc: 0.312500]\n",
            "35359: [discriminator loss: 0.604846, acc: 0.601562] [adversarial loss: 1.039705, acc: 0.281250]\n",
            "35360: [discriminator loss: 0.519204, acc: 0.765625] [adversarial loss: 1.193345, acc: 0.250000]\n",
            "35361: [discriminator loss: 0.617930, acc: 0.710938] [adversarial loss: 0.992952, acc: 0.281250]\n",
            "35362: [discriminator loss: 0.621653, acc: 0.648438] [adversarial loss: 1.308948, acc: 0.140625]\n",
            "35363: [discriminator loss: 0.555836, acc: 0.664062] [adversarial loss: 0.863913, acc: 0.515625]\n",
            "35364: [discriminator loss: 0.618378, acc: 0.625000] [adversarial loss: 1.066372, acc: 0.328125]\n",
            "35365: [discriminator loss: 0.561718, acc: 0.726562] [adversarial loss: 0.991369, acc: 0.296875]\n",
            "35366: [discriminator loss: 0.609603, acc: 0.609375] [adversarial loss: 1.229816, acc: 0.265625]\n",
            "35367: [discriminator loss: 0.551533, acc: 0.710938] [adversarial loss: 1.048298, acc: 0.390625]\n",
            "35368: [discriminator loss: 0.692366, acc: 0.609375] [adversarial loss: 1.066175, acc: 0.218750]\n",
            "35369: [discriminator loss: 0.575011, acc: 0.703125] [adversarial loss: 0.961073, acc: 0.328125]\n",
            "35370: [discriminator loss: 0.593144, acc: 0.648438] [adversarial loss: 1.508457, acc: 0.093750]\n",
            "35371: [discriminator loss: 0.630846, acc: 0.648438] [adversarial loss: 0.912570, acc: 0.390625]\n",
            "35372: [discriminator loss: 0.651063, acc: 0.664062] [adversarial loss: 1.293439, acc: 0.125000]\n",
            "35373: [discriminator loss: 0.579863, acc: 0.656250] [adversarial loss: 0.914471, acc: 0.281250]\n",
            "35374: [discriminator loss: 0.609375, acc: 0.632812] [adversarial loss: 1.353363, acc: 0.093750]\n",
            "35375: [discriminator loss: 0.644514, acc: 0.656250] [adversarial loss: 0.989226, acc: 0.328125]\n",
            "35376: [discriminator loss: 0.606587, acc: 0.703125] [adversarial loss: 1.044520, acc: 0.250000]\n",
            "35377: [discriminator loss: 0.570497, acc: 0.742188] [adversarial loss: 1.138821, acc: 0.281250]\n",
            "35378: [discriminator loss: 0.591872, acc: 0.671875] [adversarial loss: 0.882035, acc: 0.468750]\n",
            "35379: [discriminator loss: 0.572927, acc: 0.695312] [adversarial loss: 1.042760, acc: 0.359375]\n",
            "35380: [discriminator loss: 0.579437, acc: 0.671875] [adversarial loss: 1.033176, acc: 0.265625]\n",
            "35381: [discriminator loss: 0.531127, acc: 0.734375] [adversarial loss: 1.095614, acc: 0.187500]\n",
            "35382: [discriminator loss: 0.641969, acc: 0.578125] [adversarial loss: 0.820583, acc: 0.484375]\n",
            "35383: [discriminator loss: 0.650819, acc: 0.640625] [adversarial loss: 1.377698, acc: 0.125000]\n",
            "35384: [discriminator loss: 0.611492, acc: 0.625000] [adversarial loss: 0.705342, acc: 0.546875]\n",
            "35385: [discriminator loss: 0.686142, acc: 0.617188] [adversarial loss: 1.309870, acc: 0.125000]\n",
            "35386: [discriminator loss: 0.533606, acc: 0.742188] [adversarial loss: 0.739111, acc: 0.546875]\n",
            "35387: [discriminator loss: 0.550862, acc: 0.757812] [adversarial loss: 1.077975, acc: 0.281250]\n",
            "35388: [discriminator loss: 0.601017, acc: 0.648438] [adversarial loss: 0.907929, acc: 0.421875]\n",
            "35389: [discriminator loss: 0.643131, acc: 0.609375] [adversarial loss: 1.130989, acc: 0.187500]\n",
            "35390: [discriminator loss: 0.551454, acc: 0.742188] [adversarial loss: 0.836870, acc: 0.421875]\n",
            "35391: [discriminator loss: 0.571580, acc: 0.710938] [adversarial loss: 1.099888, acc: 0.281250]\n",
            "35392: [discriminator loss: 0.571919, acc: 0.703125] [adversarial loss: 1.025930, acc: 0.281250]\n",
            "35393: [discriminator loss: 0.628304, acc: 0.656250] [adversarial loss: 1.049187, acc: 0.343750]\n",
            "35394: [discriminator loss: 0.582928, acc: 0.687500] [adversarial loss: 1.074474, acc: 0.281250]\n",
            "35395: [discriminator loss: 0.535886, acc: 0.718750] [adversarial loss: 0.780978, acc: 0.500000]\n",
            "35396: [discriminator loss: 0.673676, acc: 0.679688] [adversarial loss: 1.207597, acc: 0.125000]\n",
            "35397: [discriminator loss: 0.594861, acc: 0.648438] [adversarial loss: 0.806652, acc: 0.515625]\n",
            "35398: [discriminator loss: 0.576795, acc: 0.664062] [adversarial loss: 1.141793, acc: 0.265625]\n",
            "35399: [discriminator loss: 0.620218, acc: 0.648438] [adversarial loss: 0.983305, acc: 0.343750]\n",
            "35400: [discriminator loss: 0.565499, acc: 0.664062] [adversarial loss: 0.917688, acc: 0.312500]\n",
            "35401: [discriminator loss: 0.630426, acc: 0.648438] [adversarial loss: 1.079962, acc: 0.281250]\n",
            "35402: [discriminator loss: 0.611773, acc: 0.656250] [adversarial loss: 1.036304, acc: 0.171875]\n",
            "35403: [discriminator loss: 0.604399, acc: 0.671875] [adversarial loss: 1.028593, acc: 0.281250]\n",
            "35404: [discriminator loss: 0.564627, acc: 0.726562] [adversarial loss: 1.084753, acc: 0.296875]\n",
            "35405: [discriminator loss: 0.582402, acc: 0.679688] [adversarial loss: 1.044183, acc: 0.250000]\n",
            "35406: [discriminator loss: 0.595902, acc: 0.664062] [adversarial loss: 0.889021, acc: 0.328125]\n",
            "35407: [discriminator loss: 0.597523, acc: 0.664062] [adversarial loss: 1.147643, acc: 0.218750]\n",
            "35408: [discriminator loss: 0.571102, acc: 0.687500] [adversarial loss: 0.873386, acc: 0.343750]\n",
            "35409: [discriminator loss: 0.550237, acc: 0.726562] [adversarial loss: 0.978963, acc: 0.296875]\n",
            "35410: [discriminator loss: 0.602268, acc: 0.718750] [adversarial loss: 1.250947, acc: 0.125000]\n",
            "35411: [discriminator loss: 0.595717, acc: 0.671875] [adversarial loss: 1.163957, acc: 0.171875]\n",
            "35412: [discriminator loss: 0.596117, acc: 0.687500] [adversarial loss: 1.017706, acc: 0.312500]\n",
            "35413: [discriminator loss: 0.611346, acc: 0.671875] [adversarial loss: 0.995734, acc: 0.281250]\n",
            "35414: [discriminator loss: 0.611373, acc: 0.664062] [adversarial loss: 0.894907, acc: 0.375000]\n",
            "35415: [discriminator loss: 0.513056, acc: 0.703125] [adversarial loss: 1.082517, acc: 0.265625]\n",
            "35416: [discriminator loss: 0.561021, acc: 0.726562] [adversarial loss: 1.009550, acc: 0.343750]\n",
            "35417: [discriminator loss: 0.536778, acc: 0.703125] [adversarial loss: 0.965242, acc: 0.421875]\n",
            "35418: [discriminator loss: 0.592402, acc: 0.648438] [adversarial loss: 1.116374, acc: 0.281250]\n",
            "35419: [discriminator loss: 0.628531, acc: 0.632812] [adversarial loss: 0.772362, acc: 0.578125]\n",
            "35420: [discriminator loss: 0.553992, acc: 0.742188] [adversarial loss: 0.946658, acc: 0.421875]\n",
            "35421: [discriminator loss: 0.565780, acc: 0.695312] [adversarial loss: 1.396600, acc: 0.156250]\n",
            "35422: [discriminator loss: 0.701175, acc: 0.554688] [adversarial loss: 0.701183, acc: 0.515625]\n",
            "35423: [discriminator loss: 0.636131, acc: 0.609375] [adversarial loss: 1.197308, acc: 0.265625]\n",
            "35424: [discriminator loss: 0.582413, acc: 0.664062] [adversarial loss: 0.802563, acc: 0.546875]\n",
            "35425: [discriminator loss: 0.566634, acc: 0.664062] [adversarial loss: 1.059894, acc: 0.296875]\n",
            "35426: [discriminator loss: 0.577177, acc: 0.695312] [adversarial loss: 0.854251, acc: 0.390625]\n",
            "35427: [discriminator loss: 0.518293, acc: 0.742188] [adversarial loss: 0.866235, acc: 0.437500]\n",
            "35428: [discriminator loss: 0.611728, acc: 0.640625] [adversarial loss: 1.226877, acc: 0.203125]\n",
            "35429: [discriminator loss: 0.579389, acc: 0.695312] [adversarial loss: 0.912473, acc: 0.375000]\n",
            "35430: [discriminator loss: 0.594035, acc: 0.632812] [adversarial loss: 1.248841, acc: 0.156250]\n",
            "35431: [discriminator loss: 0.686532, acc: 0.562500] [adversarial loss: 1.020971, acc: 0.312500]\n",
            "35432: [discriminator loss: 0.533250, acc: 0.765625] [adversarial loss: 0.959314, acc: 0.375000]\n",
            "35433: [discriminator loss: 0.609216, acc: 0.703125] [adversarial loss: 1.412333, acc: 0.109375]\n",
            "35434: [discriminator loss: 0.621731, acc: 0.671875] [adversarial loss: 0.792566, acc: 0.500000]\n",
            "35435: [discriminator loss: 0.601612, acc: 0.632812] [adversarial loss: 1.432729, acc: 0.125000]\n",
            "35436: [discriminator loss: 0.625298, acc: 0.648438] [adversarial loss: 0.915142, acc: 0.406250]\n",
            "35437: [discriminator loss: 0.601267, acc: 0.609375] [adversarial loss: 1.358229, acc: 0.109375]\n",
            "35438: [discriminator loss: 0.566810, acc: 0.687500] [adversarial loss: 1.219241, acc: 0.171875]\n",
            "35439: [discriminator loss: 0.636840, acc: 0.671875] [adversarial loss: 1.133278, acc: 0.218750]\n",
            "35440: [discriminator loss: 0.523024, acc: 0.726562] [adversarial loss: 1.134023, acc: 0.234375]\n",
            "35441: [discriminator loss: 0.550562, acc: 0.664062] [adversarial loss: 0.955722, acc: 0.437500]\n",
            "35442: [discriminator loss: 0.622450, acc: 0.625000] [adversarial loss: 1.132821, acc: 0.234375]\n",
            "35443: [discriminator loss: 0.555227, acc: 0.718750] [adversarial loss: 0.918530, acc: 0.375000]\n",
            "35444: [discriminator loss: 0.604663, acc: 0.671875] [adversarial loss: 0.945834, acc: 0.359375]\n",
            "35445: [discriminator loss: 0.596481, acc: 0.664062] [adversarial loss: 0.996996, acc: 0.328125]\n",
            "35446: [discriminator loss: 0.609531, acc: 0.632812] [adversarial loss: 0.845055, acc: 0.453125]\n",
            "35447: [discriminator loss: 0.549772, acc: 0.703125] [adversarial loss: 1.013222, acc: 0.375000]\n",
            "35448: [discriminator loss: 0.587251, acc: 0.687500] [adversarial loss: 1.284178, acc: 0.187500]\n",
            "35449: [discriminator loss: 0.565863, acc: 0.687500] [adversarial loss: 0.846956, acc: 0.421875]\n",
            "35450: [discriminator loss: 0.547859, acc: 0.687500] [adversarial loss: 1.127643, acc: 0.171875]\n",
            "35451: [discriminator loss: 0.650121, acc: 0.625000] [adversarial loss: 0.929293, acc: 0.375000]\n",
            "35452: [discriminator loss: 0.568744, acc: 0.656250] [adversarial loss: 1.065989, acc: 0.281250]\n",
            "35453: [discriminator loss: 0.613808, acc: 0.664062] [adversarial loss: 1.036632, acc: 0.218750]\n",
            "35454: [discriminator loss: 0.574649, acc: 0.703125] [adversarial loss: 0.943738, acc: 0.328125]\n",
            "35455: [discriminator loss: 0.613726, acc: 0.640625] [adversarial loss: 1.044948, acc: 0.296875]\n",
            "35456: [discriminator loss: 0.579795, acc: 0.710938] [adversarial loss: 0.997177, acc: 0.375000]\n",
            "35457: [discriminator loss: 0.535442, acc: 0.765625] [adversarial loss: 1.048520, acc: 0.328125]\n",
            "35458: [discriminator loss: 0.465549, acc: 0.804688] [adversarial loss: 0.980767, acc: 0.406250]\n",
            "35459: [discriminator loss: 0.556234, acc: 0.710938] [adversarial loss: 0.999016, acc: 0.390625]\n",
            "35460: [discriminator loss: 0.654014, acc: 0.625000] [adversarial loss: 1.015278, acc: 0.343750]\n",
            "35461: [discriminator loss: 0.595312, acc: 0.687500] [adversarial loss: 0.825448, acc: 0.484375]\n",
            "35462: [discriminator loss: 0.617576, acc: 0.687500] [adversarial loss: 1.278221, acc: 0.140625]\n",
            "35463: [discriminator loss: 0.574723, acc: 0.695312] [adversarial loss: 1.044554, acc: 0.390625]\n",
            "35464: [discriminator loss: 0.629164, acc: 0.640625] [adversarial loss: 1.213938, acc: 0.218750]\n",
            "35465: [discriminator loss: 0.598384, acc: 0.625000] [adversarial loss: 0.955148, acc: 0.375000]\n",
            "35466: [discriminator loss: 0.639662, acc: 0.664062] [adversarial loss: 1.071493, acc: 0.296875]\n",
            "35467: [discriminator loss: 0.557192, acc: 0.671875] [adversarial loss: 0.935546, acc: 0.375000]\n",
            "35468: [discriminator loss: 0.620876, acc: 0.625000] [adversarial loss: 0.917036, acc: 0.406250]\n",
            "35469: [discriminator loss: 0.554157, acc: 0.718750] [adversarial loss: 1.044419, acc: 0.250000]\n",
            "35470: [discriminator loss: 0.521250, acc: 0.757812] [adversarial loss: 0.764010, acc: 0.500000]\n",
            "35471: [discriminator loss: 0.577376, acc: 0.687500] [adversarial loss: 1.224567, acc: 0.171875]\n",
            "35472: [discriminator loss: 0.615663, acc: 0.648438] [adversarial loss: 0.959898, acc: 0.390625]\n",
            "35473: [discriminator loss: 0.581362, acc: 0.695312] [adversarial loss: 1.181933, acc: 0.156250]\n",
            "35474: [discriminator loss: 0.610974, acc: 0.671875] [adversarial loss: 1.102317, acc: 0.250000]\n",
            "35475: [discriminator loss: 0.657831, acc: 0.648438] [adversarial loss: 1.365317, acc: 0.125000]\n",
            "35476: [discriminator loss: 0.618347, acc: 0.617188] [adversarial loss: 0.701721, acc: 0.562500]\n",
            "35477: [discriminator loss: 0.613844, acc: 0.671875] [adversarial loss: 1.280269, acc: 0.140625]\n",
            "35478: [discriminator loss: 0.622749, acc: 0.640625] [adversarial loss: 1.064525, acc: 0.328125]\n",
            "35479: [discriminator loss: 0.544123, acc: 0.734375] [adversarial loss: 1.010178, acc: 0.312500]\n",
            "35480: [discriminator loss: 0.541825, acc: 0.703125] [adversarial loss: 0.987352, acc: 0.328125]\n",
            "35481: [discriminator loss: 0.519022, acc: 0.750000] [adversarial loss: 1.225664, acc: 0.250000]\n",
            "35482: [discriminator loss: 0.577686, acc: 0.664062] [adversarial loss: 0.953920, acc: 0.468750]\n",
            "35483: [discriminator loss: 0.639221, acc: 0.609375] [adversarial loss: 1.160634, acc: 0.265625]\n",
            "35484: [discriminator loss: 0.607588, acc: 0.617188] [adversarial loss: 0.931070, acc: 0.328125]\n",
            "35485: [discriminator loss: 0.549982, acc: 0.734375] [adversarial loss: 1.071813, acc: 0.296875]\n",
            "35486: [discriminator loss: 0.583304, acc: 0.664062] [adversarial loss: 0.941385, acc: 0.343750]\n",
            "35487: [discriminator loss: 0.568975, acc: 0.664062] [adversarial loss: 1.406302, acc: 0.171875]\n",
            "35488: [discriminator loss: 0.617934, acc: 0.632812] [adversarial loss: 0.858972, acc: 0.484375]\n",
            "35489: [discriminator loss: 0.647692, acc: 0.593750] [adversarial loss: 1.066481, acc: 0.359375]\n",
            "35490: [discriminator loss: 0.646462, acc: 0.609375] [adversarial loss: 1.063869, acc: 0.328125]\n",
            "35491: [discriminator loss: 0.621926, acc: 0.648438] [adversarial loss: 0.909199, acc: 0.359375]\n",
            "35492: [discriminator loss: 0.558463, acc: 0.718750] [adversarial loss: 1.114453, acc: 0.265625]\n",
            "35493: [discriminator loss: 0.603695, acc: 0.648438] [adversarial loss: 0.826319, acc: 0.468750]\n",
            "35494: [discriminator loss: 0.599720, acc: 0.648438] [adversarial loss: 1.055611, acc: 0.281250]\n",
            "35495: [discriminator loss: 0.578781, acc: 0.632812] [adversarial loss: 0.878455, acc: 0.312500]\n",
            "35496: [discriminator loss: 0.553543, acc: 0.703125] [adversarial loss: 0.832893, acc: 0.515625]\n",
            "35497: [discriminator loss: 0.552731, acc: 0.695312] [adversarial loss: 1.143882, acc: 0.187500]\n",
            "35498: [discriminator loss: 0.565890, acc: 0.726562] [adversarial loss: 0.831517, acc: 0.500000]\n",
            "35499: [discriminator loss: 0.634133, acc: 0.710938] [adversarial loss: 1.436644, acc: 0.078125]\n",
            "35500: [discriminator loss: 0.522643, acc: 0.734375] [adversarial loss: 1.072125, acc: 0.250000]\n",
            "35501: [discriminator loss: 0.630280, acc: 0.671875] [adversarial loss: 1.154958, acc: 0.296875]\n",
            "35502: [discriminator loss: 0.613675, acc: 0.656250] [adversarial loss: 0.974438, acc: 0.328125]\n",
            "35503: [discriminator loss: 0.623287, acc: 0.601562] [adversarial loss: 1.057598, acc: 0.234375]\n",
            "35504: [discriminator loss: 0.628551, acc: 0.679688] [adversarial loss: 1.014449, acc: 0.406250]\n",
            "35505: [discriminator loss: 0.622939, acc: 0.687500] [adversarial loss: 1.049850, acc: 0.312500]\n",
            "35506: [discriminator loss: 0.529944, acc: 0.734375] [adversarial loss: 0.842662, acc: 0.500000]\n",
            "35507: [discriminator loss: 0.638185, acc: 0.656250] [adversarial loss: 1.311168, acc: 0.203125]\n",
            "35508: [discriminator loss: 0.621988, acc: 0.679688] [adversarial loss: 0.866803, acc: 0.437500]\n",
            "35509: [discriminator loss: 0.595244, acc: 0.671875] [adversarial loss: 0.948323, acc: 0.343750]\n",
            "35510: [discriminator loss: 0.622638, acc: 0.656250] [adversarial loss: 1.083523, acc: 0.312500]\n",
            "35511: [discriminator loss: 0.513618, acc: 0.796875] [adversarial loss: 1.077313, acc: 0.296875]\n",
            "35512: [discriminator loss: 0.623278, acc: 0.640625] [adversarial loss: 1.082321, acc: 0.218750]\n",
            "35513: [discriminator loss: 0.535981, acc: 0.750000] [adversarial loss: 0.961307, acc: 0.375000]\n",
            "35514: [discriminator loss: 0.536745, acc: 0.765625] [adversarial loss: 1.172435, acc: 0.250000]\n",
            "35515: [discriminator loss: 0.586999, acc: 0.687500] [adversarial loss: 0.987408, acc: 0.296875]\n",
            "35516: [discriminator loss: 0.570823, acc: 0.679688] [adversarial loss: 1.246893, acc: 0.171875]\n",
            "35517: [discriminator loss: 0.507960, acc: 0.765625] [adversarial loss: 1.059602, acc: 0.343750]\n",
            "35518: [discriminator loss: 0.598544, acc: 0.687500] [adversarial loss: 1.083578, acc: 0.250000]\n",
            "35519: [discriminator loss: 0.643107, acc: 0.632812] [adversarial loss: 0.907527, acc: 0.375000]\n",
            "35520: [discriminator loss: 0.589690, acc: 0.648438] [adversarial loss: 0.778845, acc: 0.421875]\n",
            "35521: [discriminator loss: 0.601570, acc: 0.640625] [adversarial loss: 1.122164, acc: 0.187500]\n",
            "35522: [discriminator loss: 0.605854, acc: 0.671875] [adversarial loss: 0.894730, acc: 0.328125]\n",
            "35523: [discriminator loss: 0.532365, acc: 0.750000] [adversarial loss: 0.846362, acc: 0.515625]\n",
            "35524: [discriminator loss: 0.539319, acc: 0.710938] [adversarial loss: 1.136721, acc: 0.312500]\n",
            "35525: [discriminator loss: 0.572972, acc: 0.625000] [adversarial loss: 0.931719, acc: 0.421875]\n",
            "35526: [discriminator loss: 0.565699, acc: 0.695312] [adversarial loss: 1.214014, acc: 0.203125]\n",
            "35527: [discriminator loss: 0.561903, acc: 0.718750] [adversarial loss: 0.905479, acc: 0.359375]\n",
            "35528: [discriminator loss: 0.668933, acc: 0.625000] [adversarial loss: 1.112646, acc: 0.218750]\n",
            "35529: [discriminator loss: 0.642266, acc: 0.648438] [adversarial loss: 1.016436, acc: 0.296875]\n",
            "35530: [discriminator loss: 0.565731, acc: 0.695312] [adversarial loss: 1.324709, acc: 0.125000]\n",
            "35531: [discriminator loss: 0.582947, acc: 0.687500] [adversarial loss: 0.870108, acc: 0.390625]\n",
            "35532: [discriminator loss: 0.621848, acc: 0.625000] [adversarial loss: 1.332173, acc: 0.109375]\n",
            "35533: [discriminator loss: 0.643922, acc: 0.585938] [adversarial loss: 0.997527, acc: 0.312500]\n",
            "35534: [discriminator loss: 0.711040, acc: 0.562500] [adversarial loss: 1.345795, acc: 0.078125]\n",
            "35535: [discriminator loss: 0.560391, acc: 0.734375] [adversarial loss: 0.875447, acc: 0.359375]\n",
            "35536: [discriminator loss: 0.568465, acc: 0.648438] [adversarial loss: 1.218679, acc: 0.234375]\n",
            "35537: [discriminator loss: 0.565163, acc: 0.718750] [adversarial loss: 0.920925, acc: 0.343750]\n",
            "35538: [discriminator loss: 0.606490, acc: 0.671875] [adversarial loss: 0.924337, acc: 0.437500]\n",
            "35539: [discriminator loss: 0.624428, acc: 0.632812] [adversarial loss: 0.977598, acc: 0.390625]\n",
            "35540: [discriminator loss: 0.614738, acc: 0.671875] [adversarial loss: 0.963813, acc: 0.359375]\n",
            "35541: [discriminator loss: 0.577872, acc: 0.679688] [adversarial loss: 0.848002, acc: 0.406250]\n",
            "35542: [discriminator loss: 0.616417, acc: 0.648438] [adversarial loss: 1.173546, acc: 0.187500]\n",
            "35543: [discriminator loss: 0.560107, acc: 0.750000] [adversarial loss: 1.009425, acc: 0.312500]\n",
            "35544: [discriminator loss: 0.596258, acc: 0.710938] [adversarial loss: 1.081004, acc: 0.390625]\n",
            "35545: [discriminator loss: 0.606336, acc: 0.656250] [adversarial loss: 0.788000, acc: 0.453125]\n",
            "35546: [discriminator loss: 0.567874, acc: 0.679688] [adversarial loss: 1.090447, acc: 0.250000]\n",
            "35547: [discriminator loss: 0.576477, acc: 0.703125] [adversarial loss: 0.910357, acc: 0.390625]\n",
            "35548: [discriminator loss: 0.591991, acc: 0.687500] [adversarial loss: 1.282504, acc: 0.171875]\n",
            "35549: [discriminator loss: 0.567592, acc: 0.710938] [adversarial loss: 0.930257, acc: 0.500000]\n",
            "35550: [discriminator loss: 0.556189, acc: 0.718750] [adversarial loss: 1.370241, acc: 0.140625]\n",
            "35551: [discriminator loss: 0.635391, acc: 0.609375] [adversarial loss: 0.852411, acc: 0.421875]\n",
            "35552: [discriminator loss: 0.566512, acc: 0.687500] [adversarial loss: 1.187064, acc: 0.281250]\n",
            "35553: [discriminator loss: 0.618626, acc: 0.656250] [adversarial loss: 0.923234, acc: 0.421875]\n",
            "35554: [discriminator loss: 0.554433, acc: 0.695312] [adversarial loss: 0.983848, acc: 0.296875]\n",
            "35555: [discriminator loss: 0.638386, acc: 0.640625] [adversarial loss: 1.214692, acc: 0.187500]\n",
            "35556: [discriminator loss: 0.620022, acc: 0.609375] [adversarial loss: 0.724734, acc: 0.515625]\n",
            "35557: [discriminator loss: 0.558869, acc: 0.679688] [adversarial loss: 1.178758, acc: 0.312500]\n",
            "35558: [discriminator loss: 0.594733, acc: 0.679688] [adversarial loss: 0.701907, acc: 0.562500]\n",
            "35559: [discriminator loss: 0.591117, acc: 0.710938] [adversarial loss: 1.509678, acc: 0.125000]\n",
            "35560: [discriminator loss: 0.605860, acc: 0.679688] [adversarial loss: 0.705461, acc: 0.562500]\n",
            "35561: [discriminator loss: 0.625967, acc: 0.656250] [adversarial loss: 1.340629, acc: 0.218750]\n",
            "35562: [discriminator loss: 0.620516, acc: 0.664062] [adversarial loss: 0.877445, acc: 0.484375]\n",
            "35563: [discriminator loss: 0.521167, acc: 0.789062] [adversarial loss: 0.998974, acc: 0.296875]\n",
            "35564: [discriminator loss: 0.555631, acc: 0.710938] [adversarial loss: 1.028072, acc: 0.328125]\n",
            "35565: [discriminator loss: 0.586113, acc: 0.687500] [adversarial loss: 1.108305, acc: 0.296875]\n",
            "35566: [discriminator loss: 0.640805, acc: 0.703125] [adversarial loss: 1.224916, acc: 0.203125]\n",
            "35567: [discriminator loss: 0.645625, acc: 0.640625] [adversarial loss: 1.037602, acc: 0.328125]\n",
            "35568: [discriminator loss: 0.645132, acc: 0.625000] [adversarial loss: 0.881364, acc: 0.359375]\n",
            "35569: [discriminator loss: 0.563143, acc: 0.757812] [adversarial loss: 0.996348, acc: 0.359375]\n",
            "35570: [discriminator loss: 0.619620, acc: 0.671875] [adversarial loss: 0.873242, acc: 0.390625]\n",
            "35571: [discriminator loss: 0.561855, acc: 0.695312] [adversarial loss: 0.890511, acc: 0.421875]\n",
            "35572: [discriminator loss: 0.588789, acc: 0.679688] [adversarial loss: 1.056226, acc: 0.281250]\n",
            "35573: [discriminator loss: 0.579649, acc: 0.687500] [adversarial loss: 0.920279, acc: 0.406250]\n",
            "35574: [discriminator loss: 0.546495, acc: 0.734375] [adversarial loss: 0.892514, acc: 0.437500]\n",
            "35575: [discriminator loss: 0.563311, acc: 0.664062] [adversarial loss: 0.840119, acc: 0.500000]\n",
            "35576: [discriminator loss: 0.603456, acc: 0.679688] [adversarial loss: 1.296451, acc: 0.234375]\n",
            "35577: [discriminator loss: 0.617914, acc: 0.601562] [adversarial loss: 0.931950, acc: 0.328125]\n",
            "35578: [discriminator loss: 0.558979, acc: 0.718750] [adversarial loss: 1.142359, acc: 0.328125]\n",
            "35579: [discriminator loss: 0.593165, acc: 0.710938] [adversarial loss: 1.256334, acc: 0.312500]\n",
            "35580: [discriminator loss: 0.513428, acc: 0.742188] [adversarial loss: 0.823938, acc: 0.546875]\n",
            "35581: [discriminator loss: 0.572557, acc: 0.656250] [adversarial loss: 1.127417, acc: 0.281250]\n",
            "35582: [discriminator loss: 0.647941, acc: 0.679688] [adversarial loss: 0.987567, acc: 0.359375]\n",
            "35583: [discriminator loss: 0.569027, acc: 0.695312] [adversarial loss: 0.882469, acc: 0.500000]\n",
            "35584: [discriminator loss: 0.538258, acc: 0.703125] [adversarial loss: 1.310568, acc: 0.218750]\n",
            "35585: [discriminator loss: 0.589007, acc: 0.734375] [adversarial loss: 1.150586, acc: 0.250000]\n",
            "35586: [discriminator loss: 0.568723, acc: 0.679688] [adversarial loss: 1.256879, acc: 0.281250]\n",
            "35587: [discriminator loss: 0.586610, acc: 0.695312] [adversarial loss: 0.723938, acc: 0.562500]\n",
            "35588: [discriminator loss: 0.563467, acc: 0.726562] [adversarial loss: 1.447183, acc: 0.156250]\n",
            "35589: [discriminator loss: 0.684849, acc: 0.546875] [adversarial loss: 0.727720, acc: 0.562500]\n",
            "35590: [discriminator loss: 0.621787, acc: 0.640625] [adversarial loss: 1.297039, acc: 0.156250]\n",
            "35591: [discriminator loss: 0.569907, acc: 0.726562] [adversarial loss: 0.978695, acc: 0.343750]\n",
            "35592: [discriminator loss: 0.549679, acc: 0.726562] [adversarial loss: 1.155818, acc: 0.250000]\n",
            "35593: [discriminator loss: 0.577441, acc: 0.710938] [adversarial loss: 1.200242, acc: 0.171875]\n",
            "35594: [discriminator loss: 0.535560, acc: 0.710938] [adversarial loss: 0.905342, acc: 0.421875]\n",
            "35595: [discriminator loss: 0.613920, acc: 0.648438] [adversarial loss: 1.171540, acc: 0.265625]\n",
            "35596: [discriminator loss: 0.579964, acc: 0.648438] [adversarial loss: 0.991670, acc: 0.359375]\n",
            "35597: [discriminator loss: 0.606231, acc: 0.703125] [adversarial loss: 1.396560, acc: 0.140625]\n",
            "35598: [discriminator loss: 0.537207, acc: 0.703125] [adversarial loss: 1.126479, acc: 0.328125]\n",
            "35599: [discriminator loss: 0.592550, acc: 0.671875] [adversarial loss: 0.822454, acc: 0.515625]\n",
            "35600: [discriminator loss: 0.654230, acc: 0.648438] [adversarial loss: 1.346937, acc: 0.093750]\n",
            "35601: [discriminator loss: 0.578810, acc: 0.695312] [adversarial loss: 0.747615, acc: 0.531250]\n",
            "35602: [discriminator loss: 0.581502, acc: 0.632812] [adversarial loss: 1.114295, acc: 0.281250]\n",
            "35603: [discriminator loss: 0.595916, acc: 0.710938] [adversarial loss: 0.854371, acc: 0.437500]\n",
            "35604: [discriminator loss: 0.600457, acc: 0.671875] [adversarial loss: 1.018056, acc: 0.250000]\n",
            "35605: [discriminator loss: 0.624014, acc: 0.640625] [adversarial loss: 0.917603, acc: 0.500000]\n",
            "35606: [discriminator loss: 0.582871, acc: 0.695312] [adversarial loss: 1.028650, acc: 0.328125]\n",
            "35607: [discriminator loss: 0.586017, acc: 0.726562] [adversarial loss: 1.039076, acc: 0.359375]\n",
            "35608: [discriminator loss: 0.537018, acc: 0.742188] [adversarial loss: 0.791183, acc: 0.515625]\n",
            "35609: [discriminator loss: 0.603661, acc: 0.601562] [adversarial loss: 1.333882, acc: 0.171875]\n",
            "35610: [discriminator loss: 0.541569, acc: 0.742188] [adversarial loss: 0.825426, acc: 0.484375]\n",
            "35611: [discriminator loss: 0.597408, acc: 0.679688] [adversarial loss: 1.048925, acc: 0.234375]\n",
            "35612: [discriminator loss: 0.666841, acc: 0.625000] [adversarial loss: 0.982287, acc: 0.375000]\n",
            "35613: [discriminator loss: 0.572139, acc: 0.695312] [adversarial loss: 1.007573, acc: 0.359375]\n",
            "35614: [discriminator loss: 0.622517, acc: 0.640625] [adversarial loss: 1.184641, acc: 0.265625]\n",
            "35615: [discriminator loss: 0.564286, acc: 0.710938] [adversarial loss: 0.944055, acc: 0.343750]\n",
            "35616: [discriminator loss: 0.577592, acc: 0.703125] [adversarial loss: 1.096901, acc: 0.265625]\n",
            "35617: [discriminator loss: 0.593584, acc: 0.695312] [adversarial loss: 1.151659, acc: 0.296875]\n",
            "35618: [discriminator loss: 0.512436, acc: 0.789062] [adversarial loss: 1.116588, acc: 0.187500]\n",
            "35619: [discriminator loss: 0.586365, acc: 0.648438] [adversarial loss: 0.838669, acc: 0.500000]\n",
            "35620: [discriminator loss: 0.618435, acc: 0.671875] [adversarial loss: 1.564720, acc: 0.078125]\n",
            "35621: [discriminator loss: 0.588958, acc: 0.687500] [adversarial loss: 1.022023, acc: 0.296875]\n",
            "35622: [discriminator loss: 0.641974, acc: 0.648438] [adversarial loss: 1.149798, acc: 0.312500]\n",
            "35623: [discriminator loss: 0.582287, acc: 0.687500] [adversarial loss: 0.849548, acc: 0.453125]\n",
            "35624: [discriminator loss: 0.623197, acc: 0.656250] [adversarial loss: 1.017555, acc: 0.328125]\n",
            "35625: [discriminator loss: 0.601614, acc: 0.656250] [adversarial loss: 1.085605, acc: 0.156250]\n",
            "35626: [discriminator loss: 0.617680, acc: 0.687500] [adversarial loss: 0.959751, acc: 0.312500]\n",
            "35627: [discriminator loss: 0.545196, acc: 0.734375] [adversarial loss: 1.134012, acc: 0.296875]\n",
            "35628: [discriminator loss: 0.589029, acc: 0.687500] [adversarial loss: 1.084871, acc: 0.296875]\n",
            "35629: [discriminator loss: 0.568253, acc: 0.679688] [adversarial loss: 0.945587, acc: 0.359375]\n",
            "35630: [discriminator loss: 0.557718, acc: 0.703125] [adversarial loss: 1.102586, acc: 0.296875]\n",
            "35631: [discriminator loss: 0.624213, acc: 0.632812] [adversarial loss: 0.917117, acc: 0.328125]\n",
            "35632: [discriminator loss: 0.508769, acc: 0.757812] [adversarial loss: 1.260580, acc: 0.218750]\n",
            "35633: [discriminator loss: 0.572677, acc: 0.726562] [adversarial loss: 0.978605, acc: 0.359375]\n",
            "35634: [discriminator loss: 0.567221, acc: 0.695312] [adversarial loss: 0.998753, acc: 0.375000]\n",
            "35635: [discriminator loss: 0.568793, acc: 0.687500] [adversarial loss: 1.179858, acc: 0.156250]\n",
            "35636: [discriminator loss: 0.574610, acc: 0.710938] [adversarial loss: 0.948096, acc: 0.343750]\n",
            "35637: [discriminator loss: 0.561888, acc: 0.695312] [adversarial loss: 1.138680, acc: 0.265625]\n",
            "35638: [discriminator loss: 0.581628, acc: 0.703125] [adversarial loss: 0.785756, acc: 0.593750]\n",
            "35639: [discriminator loss: 0.673921, acc: 0.593750] [adversarial loss: 1.209507, acc: 0.140625]\n",
            "35640: [discriminator loss: 0.559869, acc: 0.703125] [adversarial loss: 1.050601, acc: 0.265625]\n",
            "35641: [discriminator loss: 0.570717, acc: 0.664062] [adversarial loss: 1.373965, acc: 0.140625]\n",
            "35642: [discriminator loss: 0.607726, acc: 0.648438] [adversarial loss: 0.914019, acc: 0.437500]\n",
            "35643: [discriminator loss: 0.577614, acc: 0.718750] [adversarial loss: 1.257772, acc: 0.203125]\n",
            "35644: [discriminator loss: 0.553074, acc: 0.718750] [adversarial loss: 0.815324, acc: 0.500000]\n",
            "35645: [discriminator loss: 0.593336, acc: 0.679688] [adversarial loss: 1.054085, acc: 0.312500]\n",
            "35646: [discriminator loss: 0.532401, acc: 0.750000] [adversarial loss: 1.191841, acc: 0.296875]\n",
            "35647: [discriminator loss: 0.607586, acc: 0.671875] [adversarial loss: 1.139239, acc: 0.312500]\n",
            "35648: [discriminator loss: 0.590012, acc: 0.687500] [adversarial loss: 0.960627, acc: 0.375000]\n",
            "35649: [discriminator loss: 0.536332, acc: 0.718750] [adversarial loss: 1.016557, acc: 0.328125]\n",
            "35650: [discriminator loss: 0.630274, acc: 0.656250] [adversarial loss: 0.931544, acc: 0.468750]\n",
            "35651: [discriminator loss: 0.627367, acc: 0.609375] [adversarial loss: 1.100735, acc: 0.250000]\n",
            "35652: [discriminator loss: 0.579712, acc: 0.679688] [adversarial loss: 0.939251, acc: 0.250000]\n",
            "35653: [discriminator loss: 0.590784, acc: 0.695312] [adversarial loss: 1.041163, acc: 0.265625]\n",
            "35654: [discriminator loss: 0.668270, acc: 0.585938] [adversarial loss: 1.203732, acc: 0.203125]\n",
            "35655: [discriminator loss: 0.625225, acc: 0.664062] [adversarial loss: 1.024152, acc: 0.328125]\n",
            "35656: [discriminator loss: 0.607919, acc: 0.656250] [adversarial loss: 1.034698, acc: 0.187500]\n",
            "35657: [discriminator loss: 0.581347, acc: 0.726562] [adversarial loss: 0.994070, acc: 0.265625]\n",
            "35658: [discriminator loss: 0.608231, acc: 0.656250] [adversarial loss: 1.137568, acc: 0.187500]\n",
            "35659: [discriminator loss: 0.625459, acc: 0.609375] [adversarial loss: 1.030887, acc: 0.296875]\n",
            "35660: [discriminator loss: 0.579110, acc: 0.718750] [adversarial loss: 0.980944, acc: 0.375000]\n",
            "35661: [discriminator loss: 0.570292, acc: 0.687500] [adversarial loss: 1.267112, acc: 0.218750]\n",
            "35662: [discriminator loss: 0.554064, acc: 0.703125] [adversarial loss: 1.041989, acc: 0.375000]\n",
            "35663: [discriminator loss: 0.580469, acc: 0.710938] [adversarial loss: 1.102125, acc: 0.296875]\n",
            "35664: [discriminator loss: 0.600924, acc: 0.718750] [adversarial loss: 1.002802, acc: 0.328125]\n",
            "35665: [discriminator loss: 0.599739, acc: 0.656250] [adversarial loss: 0.891018, acc: 0.406250]\n",
            "35666: [discriminator loss: 0.604431, acc: 0.656250] [adversarial loss: 0.913962, acc: 0.406250]\n",
            "35667: [discriminator loss: 0.571831, acc: 0.664062] [adversarial loss: 1.216454, acc: 0.156250]\n",
            "35668: [discriminator loss: 0.594604, acc: 0.609375] [adversarial loss: 0.911244, acc: 0.453125]\n",
            "35669: [discriminator loss: 0.554419, acc: 0.710938] [adversarial loss: 1.195395, acc: 0.234375]\n",
            "35670: [discriminator loss: 0.576712, acc: 0.695312] [adversarial loss: 0.875645, acc: 0.500000]\n",
            "35671: [discriminator loss: 0.619485, acc: 0.648438] [adversarial loss: 1.032677, acc: 0.281250]\n",
            "35672: [discriminator loss: 0.555047, acc: 0.742188] [adversarial loss: 1.007826, acc: 0.359375]\n",
            "35673: [discriminator loss: 0.550090, acc: 0.718750] [adversarial loss: 1.066539, acc: 0.218750]\n",
            "35674: [discriminator loss: 0.596176, acc: 0.648438] [adversarial loss: 1.036018, acc: 0.312500]\n",
            "35675: [discriminator loss: 0.514432, acc: 0.750000] [adversarial loss: 1.061027, acc: 0.328125]\n",
            "35676: [discriminator loss: 0.639119, acc: 0.585938] [adversarial loss: 1.313263, acc: 0.234375]\n",
            "35677: [discriminator loss: 0.614990, acc: 0.632812] [adversarial loss: 0.916656, acc: 0.453125]\n",
            "35678: [discriminator loss: 0.607213, acc: 0.671875] [adversarial loss: 1.532519, acc: 0.109375]\n",
            "35679: [discriminator loss: 0.625175, acc: 0.625000] [adversarial loss: 0.844485, acc: 0.406250]\n",
            "35680: [discriminator loss: 0.599608, acc: 0.703125] [adversarial loss: 1.337059, acc: 0.156250]\n",
            "35681: [discriminator loss: 0.649596, acc: 0.648438] [adversarial loss: 0.834119, acc: 0.484375]\n",
            "35682: [discriminator loss: 0.609226, acc: 0.695312] [adversarial loss: 1.055410, acc: 0.328125]\n",
            "35683: [discriminator loss: 0.547431, acc: 0.734375] [adversarial loss: 0.873580, acc: 0.375000]\n",
            "35684: [discriminator loss: 0.606868, acc: 0.656250] [adversarial loss: 1.141929, acc: 0.218750]\n",
            "35685: [discriminator loss: 0.602422, acc: 0.640625] [adversarial loss: 0.750393, acc: 0.500000]\n",
            "35686: [discriminator loss: 0.594063, acc: 0.687500] [adversarial loss: 1.145763, acc: 0.265625]\n",
            "35687: [discriminator loss: 0.581275, acc: 0.703125] [adversarial loss: 0.921189, acc: 0.406250]\n",
            "35688: [discriminator loss: 0.584481, acc: 0.671875] [adversarial loss: 1.072435, acc: 0.265625]\n",
            "35689: [discriminator loss: 0.602300, acc: 0.648438] [adversarial loss: 1.052773, acc: 0.296875]\n",
            "35690: [discriminator loss: 0.598413, acc: 0.703125] [adversarial loss: 0.802775, acc: 0.437500]\n",
            "35691: [discriminator loss: 0.564263, acc: 0.718750] [adversarial loss: 0.796117, acc: 0.546875]\n",
            "35692: [discriminator loss: 0.628662, acc: 0.632812] [adversarial loss: 0.868478, acc: 0.437500]\n",
            "35693: [discriminator loss: 0.604013, acc: 0.664062] [adversarial loss: 1.121907, acc: 0.265625]\n",
            "35694: [discriminator loss: 0.618939, acc: 0.656250] [adversarial loss: 0.940114, acc: 0.406250]\n",
            "35695: [discriminator loss: 0.586650, acc: 0.703125] [adversarial loss: 1.027504, acc: 0.265625]\n",
            "35696: [discriminator loss: 0.526378, acc: 0.710938] [adversarial loss: 1.123361, acc: 0.343750]\n",
            "35697: [discriminator loss: 0.567272, acc: 0.718750] [adversarial loss: 0.843834, acc: 0.453125]\n",
            "35698: [discriminator loss: 0.533801, acc: 0.789062] [adversarial loss: 1.324271, acc: 0.203125]\n",
            "35699: [discriminator loss: 0.576031, acc: 0.679688] [adversarial loss: 0.873921, acc: 0.453125]\n",
            "35700: [discriminator loss: 0.591442, acc: 0.648438] [adversarial loss: 1.275427, acc: 0.171875]\n",
            "35701: [discriminator loss: 0.572296, acc: 0.656250] [adversarial loss: 0.875457, acc: 0.421875]\n",
            "35702: [discriminator loss: 0.554861, acc: 0.664062] [adversarial loss: 1.102500, acc: 0.234375]\n",
            "35703: [discriminator loss: 0.574353, acc: 0.656250] [adversarial loss: 0.829159, acc: 0.546875]\n",
            "35704: [discriminator loss: 0.592464, acc: 0.703125] [adversarial loss: 1.362562, acc: 0.140625]\n",
            "35705: [discriminator loss: 0.529866, acc: 0.726562] [adversarial loss: 0.926930, acc: 0.421875]\n",
            "35706: [discriminator loss: 0.579620, acc: 0.664062] [adversarial loss: 1.207427, acc: 0.140625]\n",
            "35707: [discriminator loss: 0.601267, acc: 0.679688] [adversarial loss: 0.852423, acc: 0.421875]\n",
            "35708: [discriminator loss: 0.584671, acc: 0.703125] [adversarial loss: 1.337257, acc: 0.125000]\n",
            "35709: [discriminator loss: 0.622903, acc: 0.648438] [adversarial loss: 0.954923, acc: 0.265625]\n",
            "35710: [discriminator loss: 0.593873, acc: 0.679688] [adversarial loss: 1.074395, acc: 0.281250]\n",
            "35711: [discriminator loss: 0.598941, acc: 0.640625] [adversarial loss: 1.004869, acc: 0.390625]\n",
            "35712: [discriminator loss: 0.591167, acc: 0.664062] [adversarial loss: 1.060687, acc: 0.328125]\n",
            "35713: [discriminator loss: 0.567520, acc: 0.734375] [adversarial loss: 0.959304, acc: 0.375000]\n",
            "35714: [discriminator loss: 0.614159, acc: 0.671875] [adversarial loss: 1.378485, acc: 0.109375]\n",
            "35715: [discriminator loss: 0.598010, acc: 0.664062] [adversarial loss: 1.001152, acc: 0.421875]\n",
            "35716: [discriminator loss: 0.510103, acc: 0.757812] [adversarial loss: 1.158815, acc: 0.156250]\n",
            "35717: [discriminator loss: 0.557274, acc: 0.726562] [adversarial loss: 1.102811, acc: 0.296875]\n",
            "35718: [discriminator loss: 0.613614, acc: 0.664062] [adversarial loss: 1.085779, acc: 0.296875]\n",
            "35719: [discriminator loss: 0.586342, acc: 0.679688] [adversarial loss: 0.995916, acc: 0.359375]\n",
            "35720: [discriminator loss: 0.618550, acc: 0.664062] [adversarial loss: 0.858328, acc: 0.484375]\n",
            "35721: [discriminator loss: 0.552932, acc: 0.648438] [adversarial loss: 1.347417, acc: 0.156250]\n",
            "35722: [discriminator loss: 0.593143, acc: 0.687500] [adversarial loss: 0.847829, acc: 0.437500]\n",
            "35723: [discriminator loss: 0.606406, acc: 0.648438] [adversarial loss: 1.288438, acc: 0.187500]\n",
            "35724: [discriminator loss: 0.572806, acc: 0.710938] [adversarial loss: 0.820969, acc: 0.437500]\n",
            "35725: [discriminator loss: 0.613484, acc: 0.664062] [adversarial loss: 1.492795, acc: 0.078125]\n",
            "35726: [discriminator loss: 0.580839, acc: 0.703125] [adversarial loss: 0.705602, acc: 0.640625]\n",
            "35727: [discriminator loss: 0.572649, acc: 0.687500] [adversarial loss: 1.250481, acc: 0.109375]\n",
            "35728: [discriminator loss: 0.625107, acc: 0.648438] [adversarial loss: 0.982047, acc: 0.296875]\n",
            "35729: [discriminator loss: 0.576861, acc: 0.679688] [adversarial loss: 1.023189, acc: 0.296875]\n",
            "35730: [discriminator loss: 0.638299, acc: 0.648438] [adversarial loss: 0.992741, acc: 0.265625]\n",
            "35731: [discriminator loss: 0.609149, acc: 0.664062] [adversarial loss: 1.284685, acc: 0.109375]\n",
            "35732: [discriminator loss: 0.570069, acc: 0.703125] [adversarial loss: 0.834765, acc: 0.453125]\n",
            "35733: [discriminator loss: 0.611647, acc: 0.640625] [adversarial loss: 1.377830, acc: 0.203125]\n",
            "35734: [discriminator loss: 0.638810, acc: 0.617188] [adversarial loss: 1.060843, acc: 0.281250]\n",
            "35735: [discriminator loss: 0.579692, acc: 0.710938] [adversarial loss: 0.898546, acc: 0.453125]\n",
            "35736: [discriminator loss: 0.605492, acc: 0.656250] [adversarial loss: 1.162506, acc: 0.250000]\n",
            "35737: [discriminator loss: 0.571708, acc: 0.656250] [adversarial loss: 0.719596, acc: 0.500000]\n",
            "35738: [discriminator loss: 0.625695, acc: 0.687500] [adversarial loss: 1.289398, acc: 0.109375]\n",
            "35739: [discriminator loss: 0.592423, acc: 0.648438] [adversarial loss: 0.874075, acc: 0.500000]\n",
            "35740: [discriminator loss: 0.609027, acc: 0.625000] [adversarial loss: 0.963591, acc: 0.359375]\n",
            "35741: [discriminator loss: 0.569403, acc: 0.687500] [adversarial loss: 1.140965, acc: 0.234375]\n",
            "35742: [discriminator loss: 0.588355, acc: 0.656250] [adversarial loss: 0.793020, acc: 0.531250]\n",
            "35743: [discriminator loss: 0.622187, acc: 0.664062] [adversarial loss: 1.181774, acc: 0.171875]\n",
            "35744: [discriminator loss: 0.593638, acc: 0.640625] [adversarial loss: 0.974098, acc: 0.390625]\n",
            "35745: [discriminator loss: 0.538522, acc: 0.742188] [adversarial loss: 1.242710, acc: 0.265625]\n",
            "35746: [discriminator loss: 0.583312, acc: 0.601562] [adversarial loss: 1.051006, acc: 0.328125]\n",
            "35747: [discriminator loss: 0.594434, acc: 0.656250] [adversarial loss: 1.064748, acc: 0.328125]\n",
            "35748: [discriminator loss: 0.569187, acc: 0.718750] [adversarial loss: 1.147938, acc: 0.312500]\n",
            "35749: [discriminator loss: 0.613075, acc: 0.679688] [adversarial loss: 0.814629, acc: 0.500000]\n",
            "35750: [discriminator loss: 0.591179, acc: 0.648438] [adversarial loss: 0.978829, acc: 0.359375]\n",
            "35751: [discriminator loss: 0.563714, acc: 0.710938] [adversarial loss: 0.990416, acc: 0.375000]\n",
            "35752: [discriminator loss: 0.563101, acc: 0.703125] [adversarial loss: 0.986863, acc: 0.328125]\n",
            "35753: [discriminator loss: 0.593077, acc: 0.664062] [adversarial loss: 1.063161, acc: 0.359375]\n",
            "35754: [discriminator loss: 0.506731, acc: 0.757812] [adversarial loss: 0.869260, acc: 0.421875]\n",
            "35755: [discriminator loss: 0.608529, acc: 0.640625] [adversarial loss: 1.053815, acc: 0.250000]\n",
            "35756: [discriminator loss: 0.609929, acc: 0.640625] [adversarial loss: 0.993199, acc: 0.359375]\n",
            "35757: [discriminator loss: 0.575458, acc: 0.679688] [adversarial loss: 0.958706, acc: 0.390625]\n",
            "35758: [discriminator loss: 0.580399, acc: 0.679688] [adversarial loss: 1.455493, acc: 0.203125]\n",
            "35759: [discriminator loss: 0.694396, acc: 0.562500] [adversarial loss: 0.790078, acc: 0.515625]\n",
            "35760: [discriminator loss: 0.632047, acc: 0.664062] [adversarial loss: 1.435572, acc: 0.203125]\n",
            "35761: [discriminator loss: 0.567489, acc: 0.695312] [adversarial loss: 1.058413, acc: 0.359375]\n",
            "35762: [discriminator loss: 0.619143, acc: 0.664062] [adversarial loss: 1.398859, acc: 0.156250]\n",
            "35763: [discriminator loss: 0.547422, acc: 0.726562] [adversarial loss: 0.797309, acc: 0.484375]\n",
            "35764: [discriminator loss: 0.668589, acc: 0.640625] [adversarial loss: 1.324604, acc: 0.078125]\n",
            "35765: [discriminator loss: 0.521229, acc: 0.750000] [adversarial loss: 0.982775, acc: 0.312500]\n",
            "35766: [discriminator loss: 0.632391, acc: 0.640625] [adversarial loss: 0.925682, acc: 0.359375]\n",
            "35767: [discriminator loss: 0.633826, acc: 0.601562] [adversarial loss: 1.098921, acc: 0.296875]\n",
            "35768: [discriminator loss: 0.589311, acc: 0.726562] [adversarial loss: 0.849193, acc: 0.390625]\n",
            "35769: [discriminator loss: 0.622902, acc: 0.593750] [adversarial loss: 0.912010, acc: 0.406250]\n",
            "35770: [discriminator loss: 0.607187, acc: 0.687500] [adversarial loss: 1.152160, acc: 0.218750]\n",
            "35771: [discriminator loss: 0.580273, acc: 0.679688] [adversarial loss: 0.916549, acc: 0.359375]\n",
            "35772: [discriminator loss: 0.531906, acc: 0.734375] [adversarial loss: 1.259018, acc: 0.250000]\n",
            "35773: [discriminator loss: 0.540292, acc: 0.726562] [adversarial loss: 1.024569, acc: 0.312500]\n",
            "35774: [discriminator loss: 0.592584, acc: 0.671875] [adversarial loss: 0.702942, acc: 0.562500]\n",
            "35775: [discriminator loss: 0.595331, acc: 0.664062] [adversarial loss: 1.042878, acc: 0.265625]\n",
            "35776: [discriminator loss: 0.589420, acc: 0.687500] [adversarial loss: 1.044374, acc: 0.328125]\n",
            "35777: [discriminator loss: 0.557805, acc: 0.734375] [adversarial loss: 1.176086, acc: 0.203125]\n",
            "35778: [discriminator loss: 0.546215, acc: 0.718750] [adversarial loss: 1.025507, acc: 0.265625]\n",
            "35779: [discriminator loss: 0.561245, acc: 0.710938] [adversarial loss: 1.137123, acc: 0.203125]\n",
            "35780: [discriminator loss: 0.568375, acc: 0.695312] [adversarial loss: 0.876528, acc: 0.375000]\n",
            "35781: [discriminator loss: 0.545884, acc: 0.710938] [adversarial loss: 1.204400, acc: 0.250000]\n",
            "35782: [discriminator loss: 0.613282, acc: 0.640625] [adversarial loss: 1.179732, acc: 0.375000]\n",
            "35783: [discriminator loss: 0.600300, acc: 0.656250] [adversarial loss: 0.960764, acc: 0.328125]\n",
            "35784: [discriminator loss: 0.603489, acc: 0.664062] [adversarial loss: 1.385826, acc: 0.156250]\n",
            "35785: [discriminator loss: 0.561259, acc: 0.687500] [adversarial loss: 0.793280, acc: 0.500000]\n",
            "35786: [discriminator loss: 0.633685, acc: 0.648438] [adversarial loss: 1.236218, acc: 0.203125]\n",
            "35787: [discriminator loss: 0.640961, acc: 0.609375] [adversarial loss: 0.907758, acc: 0.390625]\n",
            "35788: [discriminator loss: 0.557443, acc: 0.703125] [adversarial loss: 1.227794, acc: 0.250000]\n",
            "35789: [discriminator loss: 0.551776, acc: 0.671875] [adversarial loss: 1.043725, acc: 0.328125]\n",
            "35790: [discriminator loss: 0.567512, acc: 0.703125] [adversarial loss: 0.857675, acc: 0.421875]\n",
            "35791: [discriminator loss: 0.588170, acc: 0.695312] [adversarial loss: 0.767716, acc: 0.484375]\n",
            "35792: [discriminator loss: 0.647239, acc: 0.664062] [adversarial loss: 1.373547, acc: 0.078125]\n",
            "35793: [discriminator loss: 0.595100, acc: 0.679688] [adversarial loss: 0.955250, acc: 0.375000]\n",
            "35794: [discriminator loss: 0.549924, acc: 0.687500] [adversarial loss: 1.164517, acc: 0.250000]\n",
            "35795: [discriminator loss: 0.578455, acc: 0.695312] [adversarial loss: 1.076179, acc: 0.281250]\n",
            "35796: [discriminator loss: 0.578579, acc: 0.648438] [adversarial loss: 1.134794, acc: 0.218750]\n",
            "35797: [discriminator loss: 0.610455, acc: 0.656250] [adversarial loss: 1.083143, acc: 0.281250]\n",
            "35798: [discriminator loss: 0.570866, acc: 0.679688] [adversarial loss: 0.973500, acc: 0.375000]\n",
            "35799: [discriminator loss: 0.580915, acc: 0.695312] [adversarial loss: 1.150458, acc: 0.265625]\n",
            "35800: [discriminator loss: 0.611596, acc: 0.656250] [adversarial loss: 1.251040, acc: 0.203125]\n",
            "35801: [discriminator loss: 0.597788, acc: 0.679688] [adversarial loss: 0.987887, acc: 0.359375]\n",
            "35802: [discriminator loss: 0.612268, acc: 0.710938] [adversarial loss: 0.860229, acc: 0.437500]\n",
            "35803: [discriminator loss: 0.569522, acc: 0.679688] [adversarial loss: 1.104120, acc: 0.265625]\n",
            "35804: [discriminator loss: 0.585545, acc: 0.695312] [adversarial loss: 1.063809, acc: 0.328125]\n",
            "35805: [discriminator loss: 0.583080, acc: 0.671875] [adversarial loss: 1.095593, acc: 0.218750]\n",
            "35806: [discriminator loss: 0.601727, acc: 0.656250] [adversarial loss: 0.893660, acc: 0.437500]\n",
            "35807: [discriminator loss: 0.610779, acc: 0.648438] [adversarial loss: 1.244743, acc: 0.171875]\n",
            "35808: [discriminator loss: 0.611065, acc: 0.640625] [adversarial loss: 0.853362, acc: 0.546875]\n",
            "35809: [discriminator loss: 0.748812, acc: 0.531250] [adversarial loss: 1.297056, acc: 0.156250]\n",
            "35810: [discriminator loss: 0.657147, acc: 0.609375] [adversarial loss: 0.728324, acc: 0.531250]\n",
            "35811: [discriminator loss: 0.581061, acc: 0.734375] [adversarial loss: 1.341895, acc: 0.093750]\n",
            "35812: [discriminator loss: 0.589380, acc: 0.703125] [adversarial loss: 0.940916, acc: 0.359375]\n",
            "35813: [discriminator loss: 0.560863, acc: 0.726562] [adversarial loss: 1.123973, acc: 0.312500]\n",
            "35814: [discriminator loss: 0.617355, acc: 0.664062] [adversarial loss: 1.022796, acc: 0.328125]\n",
            "35815: [discriminator loss: 0.556891, acc: 0.726562] [adversarial loss: 1.026903, acc: 0.312500]\n",
            "35816: [discriminator loss: 0.546769, acc: 0.757812] [adversarial loss: 1.020604, acc: 0.328125]\n",
            "35817: [discriminator loss: 0.628622, acc: 0.656250] [adversarial loss: 1.128193, acc: 0.218750]\n",
            "35818: [discriminator loss: 0.504492, acc: 0.734375] [adversarial loss: 0.912493, acc: 0.296875]\n",
            "35819: [discriminator loss: 0.644007, acc: 0.617188] [adversarial loss: 1.232579, acc: 0.140625]\n",
            "35820: [discriminator loss: 0.589029, acc: 0.664062] [adversarial loss: 1.058329, acc: 0.218750]\n",
            "35821: [discriminator loss: 0.574074, acc: 0.710938] [adversarial loss: 1.081915, acc: 0.250000]\n",
            "35822: [discriminator loss: 0.595767, acc: 0.695312] [adversarial loss: 0.794256, acc: 0.500000]\n",
            "35823: [discriminator loss: 0.598093, acc: 0.687500] [adversarial loss: 1.174931, acc: 0.187500]\n",
            "35824: [discriminator loss: 0.612722, acc: 0.640625] [adversarial loss: 0.898477, acc: 0.359375]\n",
            "35825: [discriminator loss: 0.632378, acc: 0.656250] [adversarial loss: 0.956937, acc: 0.281250]\n",
            "35826: [discriminator loss: 0.531595, acc: 0.734375] [adversarial loss: 1.098074, acc: 0.343750]\n",
            "35827: [discriminator loss: 0.556930, acc: 0.750000] [adversarial loss: 1.032328, acc: 0.312500]\n",
            "35828: [discriminator loss: 0.562778, acc: 0.726562] [adversarial loss: 0.924474, acc: 0.421875]\n",
            "35829: [discriminator loss: 0.547257, acc: 0.695312] [adversarial loss: 1.120457, acc: 0.203125]\n",
            "35830: [discriminator loss: 0.595521, acc: 0.687500] [adversarial loss: 0.899519, acc: 0.437500]\n",
            "35831: [discriminator loss: 0.600636, acc: 0.671875] [adversarial loss: 1.092500, acc: 0.312500]\n",
            "35832: [discriminator loss: 0.605327, acc: 0.679688] [adversarial loss: 0.933221, acc: 0.359375]\n",
            "35833: [discriminator loss: 0.545957, acc: 0.742188] [adversarial loss: 1.375023, acc: 0.140625]\n",
            "35834: [discriminator loss: 0.619631, acc: 0.656250] [adversarial loss: 0.975123, acc: 0.343750]\n",
            "35835: [discriminator loss: 0.603571, acc: 0.640625] [adversarial loss: 1.297168, acc: 0.125000]\n",
            "35836: [discriminator loss: 0.550737, acc: 0.718750] [adversarial loss: 1.019264, acc: 0.375000]\n",
            "35837: [discriminator loss: 0.537721, acc: 0.750000] [adversarial loss: 1.301273, acc: 0.312500]\n",
            "35838: [discriminator loss: 0.578393, acc: 0.695312] [adversarial loss: 1.122856, acc: 0.218750]\n",
            "35839: [discriminator loss: 0.573950, acc: 0.664062] [adversarial loss: 1.051748, acc: 0.296875]\n",
            "35840: [discriminator loss: 0.565193, acc: 0.695312] [adversarial loss: 1.102482, acc: 0.187500]\n",
            "35841: [discriminator loss: 0.619867, acc: 0.656250] [adversarial loss: 1.077874, acc: 0.281250]\n",
            "35842: [discriminator loss: 0.534488, acc: 0.734375] [adversarial loss: 0.955232, acc: 0.421875]\n",
            "35843: [discriminator loss: 0.558383, acc: 0.726562] [adversarial loss: 0.993926, acc: 0.375000]\n",
            "35844: [discriminator loss: 0.590196, acc: 0.656250] [adversarial loss: 1.098609, acc: 0.312500]\n",
            "35845: [discriminator loss: 0.676666, acc: 0.585938] [adversarial loss: 1.209749, acc: 0.265625]\n",
            "35846: [discriminator loss: 0.627301, acc: 0.609375] [adversarial loss: 1.273010, acc: 0.171875]\n",
            "35847: [discriminator loss: 0.614290, acc: 0.648438] [adversarial loss: 0.640099, acc: 0.656250]\n",
            "35848: [discriminator loss: 0.597071, acc: 0.671875] [adversarial loss: 1.558682, acc: 0.062500]\n",
            "35849: [discriminator loss: 0.630505, acc: 0.648438] [adversarial loss: 0.708862, acc: 0.562500]\n",
            "35850: [discriminator loss: 0.575031, acc: 0.664062] [adversarial loss: 1.101135, acc: 0.296875]\n",
            "35851: [discriminator loss: 0.596617, acc: 0.664062] [adversarial loss: 0.852326, acc: 0.468750]\n",
            "35852: [discriminator loss: 0.571857, acc: 0.679688] [adversarial loss: 1.159485, acc: 0.312500]\n",
            "35853: [discriminator loss: 0.620689, acc: 0.601562] [adversarial loss: 0.936504, acc: 0.421875]\n",
            "35854: [discriminator loss: 0.604498, acc: 0.625000] [adversarial loss: 0.859064, acc: 0.468750]\n",
            "35855: [discriminator loss: 0.553417, acc: 0.718750] [adversarial loss: 1.205969, acc: 0.218750]\n",
            "35856: [discriminator loss: 0.531339, acc: 0.742188] [adversarial loss: 1.038455, acc: 0.390625]\n",
            "35857: [discriminator loss: 0.618957, acc: 0.640625] [adversarial loss: 1.023525, acc: 0.343750]\n",
            "35858: [discriminator loss: 0.646904, acc: 0.632812] [adversarial loss: 1.137810, acc: 0.296875]\n",
            "35859: [discriminator loss: 0.580716, acc: 0.656250] [adversarial loss: 0.819163, acc: 0.484375]\n",
            "35860: [discriminator loss: 0.655955, acc: 0.656250] [adversarial loss: 1.361431, acc: 0.125000]\n",
            "35861: [discriminator loss: 0.597133, acc: 0.703125] [adversarial loss: 0.803327, acc: 0.453125]\n",
            "35862: [discriminator loss: 0.538516, acc: 0.718750] [adversarial loss: 1.193382, acc: 0.234375]\n",
            "35863: [discriminator loss: 0.653778, acc: 0.585938] [adversarial loss: 0.801100, acc: 0.484375]\n",
            "35864: [discriminator loss: 0.708089, acc: 0.609375] [adversarial loss: 1.422297, acc: 0.109375]\n",
            "35865: [discriminator loss: 0.624093, acc: 0.617188] [adversarial loss: 1.012517, acc: 0.296875]\n",
            "35866: [discriminator loss: 0.565950, acc: 0.695312] [adversarial loss: 1.314042, acc: 0.062500]\n",
            "35867: [discriminator loss: 0.598794, acc: 0.671875] [adversarial loss: 0.952083, acc: 0.359375]\n",
            "35868: [discriminator loss: 0.558686, acc: 0.710938] [adversarial loss: 1.071192, acc: 0.312500]\n",
            "35869: [discriminator loss: 0.602579, acc: 0.687500] [adversarial loss: 0.787226, acc: 0.531250]\n",
            "35870: [discriminator loss: 0.586305, acc: 0.664062] [adversarial loss: 1.214108, acc: 0.203125]\n",
            "35871: [discriminator loss: 0.611782, acc: 0.648438] [adversarial loss: 0.878407, acc: 0.468750]\n",
            "35872: [discriminator loss: 0.572954, acc: 0.734375] [adversarial loss: 1.199680, acc: 0.250000]\n",
            "35873: [discriminator loss: 0.637053, acc: 0.625000] [adversarial loss: 1.079022, acc: 0.281250]\n",
            "35874: [discriminator loss: 0.570518, acc: 0.734375] [adversarial loss: 0.968117, acc: 0.390625]\n",
            "35875: [discriminator loss: 0.591699, acc: 0.648438] [adversarial loss: 0.914927, acc: 0.406250]\n",
            "35876: [discriminator loss: 0.620006, acc: 0.632812] [adversarial loss: 1.130828, acc: 0.187500]\n",
            "35877: [discriminator loss: 0.630922, acc: 0.632812] [adversarial loss: 0.949325, acc: 0.328125]\n",
            "35878: [discriminator loss: 0.575394, acc: 0.695312] [adversarial loss: 0.896587, acc: 0.484375]\n",
            "35879: [discriminator loss: 0.606766, acc: 0.710938] [adversarial loss: 1.008736, acc: 0.406250]\n",
            "35880: [discriminator loss: 0.549748, acc: 0.718750] [adversarial loss: 1.148434, acc: 0.296875]\n",
            "35881: [discriminator loss: 0.564140, acc: 0.726562] [adversarial loss: 0.817123, acc: 0.500000]\n",
            "35882: [discriminator loss: 0.660530, acc: 0.593750] [adversarial loss: 1.254962, acc: 0.171875]\n",
            "35883: [discriminator loss: 0.555835, acc: 0.687500] [adversarial loss: 0.827683, acc: 0.390625]\n",
            "35884: [discriminator loss: 0.658356, acc: 0.648438] [adversarial loss: 1.443171, acc: 0.140625]\n",
            "35885: [discriminator loss: 0.626910, acc: 0.632812] [adversarial loss: 0.773746, acc: 0.500000]\n",
            "35886: [discriminator loss: 0.628182, acc: 0.671875] [adversarial loss: 1.416662, acc: 0.062500]\n",
            "35887: [discriminator loss: 0.638799, acc: 0.617188] [adversarial loss: 0.856462, acc: 0.468750]\n",
            "35888: [discriminator loss: 0.661379, acc: 0.648438] [adversarial loss: 1.090451, acc: 0.234375]\n",
            "35889: [discriminator loss: 0.567709, acc: 0.703125] [adversarial loss: 0.810434, acc: 0.359375]\n",
            "35890: [discriminator loss: 0.646380, acc: 0.632812] [adversarial loss: 1.333519, acc: 0.156250]\n",
            "35891: [discriminator loss: 0.595517, acc: 0.679688] [adversarial loss: 0.989855, acc: 0.390625]\n",
            "35892: [discriminator loss: 0.585968, acc: 0.656250] [adversarial loss: 1.090890, acc: 0.328125]\n",
            "35893: [discriminator loss: 0.600049, acc: 0.664062] [adversarial loss: 1.019554, acc: 0.234375]\n",
            "35894: [discriminator loss: 0.610582, acc: 0.656250] [adversarial loss: 1.064079, acc: 0.203125]\n",
            "35895: [discriminator loss: 0.647116, acc: 0.609375] [adversarial loss: 0.867119, acc: 0.453125]\n",
            "35896: [discriminator loss: 0.610676, acc: 0.656250] [adversarial loss: 1.136431, acc: 0.171875]\n",
            "35897: [discriminator loss: 0.554747, acc: 0.718750] [adversarial loss: 1.028209, acc: 0.265625]\n",
            "35898: [discriminator loss: 0.569946, acc: 0.664062] [adversarial loss: 0.889052, acc: 0.421875]\n",
            "35899: [discriminator loss: 0.570790, acc: 0.710938] [adversarial loss: 1.139078, acc: 0.250000]\n",
            "35900: [discriminator loss: 0.581447, acc: 0.671875] [adversarial loss: 1.138795, acc: 0.203125]\n",
            "35901: [discriminator loss: 0.609897, acc: 0.656250] [adversarial loss: 0.899611, acc: 0.437500]\n",
            "35902: [discriminator loss: 0.581362, acc: 0.664062] [adversarial loss: 1.351013, acc: 0.203125]\n",
            "35903: [discriminator loss: 0.610681, acc: 0.679688] [adversarial loss: 0.808567, acc: 0.468750]\n",
            "35904: [discriminator loss: 0.549034, acc: 0.687500] [adversarial loss: 1.209717, acc: 0.250000]\n",
            "35905: [discriminator loss: 0.625280, acc: 0.656250] [adversarial loss: 0.761270, acc: 0.562500]\n",
            "35906: [discriminator loss: 0.597556, acc: 0.664062] [adversarial loss: 1.315591, acc: 0.156250]\n",
            "35907: [discriminator loss: 0.566540, acc: 0.687500] [adversarial loss: 0.847181, acc: 0.453125]\n",
            "35908: [discriminator loss: 0.530522, acc: 0.695312] [adversarial loss: 1.008223, acc: 0.390625]\n",
            "35909: [discriminator loss: 0.565522, acc: 0.726562] [adversarial loss: 0.879742, acc: 0.406250]\n",
            "35910: [discriminator loss: 0.660090, acc: 0.578125] [adversarial loss: 1.129944, acc: 0.234375]\n",
            "35911: [discriminator loss: 0.552120, acc: 0.734375] [adversarial loss: 0.866161, acc: 0.500000]\n",
            "35912: [discriminator loss: 0.606489, acc: 0.679688] [adversarial loss: 1.321573, acc: 0.203125]\n",
            "35913: [discriminator loss: 0.653593, acc: 0.625000] [adversarial loss: 0.772712, acc: 0.562500]\n",
            "35914: [discriminator loss: 0.666461, acc: 0.632812] [adversarial loss: 0.980953, acc: 0.343750]\n",
            "35915: [discriminator loss: 0.590167, acc: 0.687500] [adversarial loss: 0.981830, acc: 0.296875]\n",
            "35916: [discriminator loss: 0.554224, acc: 0.718750] [adversarial loss: 1.026422, acc: 0.218750]\n",
            "35917: [discriminator loss: 0.558042, acc: 0.695312] [adversarial loss: 1.096966, acc: 0.203125]\n",
            "35918: [discriminator loss: 0.647851, acc: 0.578125] [adversarial loss: 0.916317, acc: 0.359375]\n",
            "35919: [discriminator loss: 0.636505, acc: 0.648438] [adversarial loss: 1.042945, acc: 0.390625]\n",
            "35920: [discriminator loss: 0.589212, acc: 0.687500] [adversarial loss: 1.161761, acc: 0.156250]\n",
            "35921: [discriminator loss: 0.548815, acc: 0.703125] [adversarial loss: 0.819553, acc: 0.515625]\n",
            "35922: [discriminator loss: 0.583128, acc: 0.664062] [adversarial loss: 1.049576, acc: 0.281250]\n",
            "35923: [discriminator loss: 0.550654, acc: 0.718750] [adversarial loss: 1.068446, acc: 0.265625]\n",
            "35924: [discriminator loss: 0.632413, acc: 0.601562] [adversarial loss: 0.999324, acc: 0.328125]\n",
            "35925: [discriminator loss: 0.579679, acc: 0.679688] [adversarial loss: 1.048320, acc: 0.312500]\n",
            "35926: [discriminator loss: 0.589446, acc: 0.695312] [adversarial loss: 1.159379, acc: 0.187500]\n",
            "35927: [discriminator loss: 0.561844, acc: 0.718750] [adversarial loss: 1.009898, acc: 0.312500]\n",
            "35928: [discriminator loss: 0.612029, acc: 0.617188] [adversarial loss: 0.976920, acc: 0.343750]\n",
            "35929: [discriminator loss: 0.575648, acc: 0.687500] [adversarial loss: 1.239147, acc: 0.234375]\n",
            "35930: [discriminator loss: 0.556564, acc: 0.664062] [adversarial loss: 0.910814, acc: 0.390625]\n",
            "35931: [discriminator loss: 0.576982, acc: 0.710938] [adversarial loss: 1.101348, acc: 0.250000]\n",
            "35932: [discriminator loss: 0.522623, acc: 0.765625] [adversarial loss: 1.020148, acc: 0.375000]\n",
            "35933: [discriminator loss: 0.562650, acc: 0.679688] [adversarial loss: 1.027314, acc: 0.296875]\n",
            "35934: [discriminator loss: 0.576682, acc: 0.679688] [adversarial loss: 1.134534, acc: 0.296875]\n",
            "35935: [discriminator loss: 0.599476, acc: 0.656250] [adversarial loss: 0.936056, acc: 0.437500]\n",
            "35936: [discriminator loss: 0.570443, acc: 0.718750] [adversarial loss: 1.222033, acc: 0.234375]\n",
            "35937: [discriminator loss: 0.616019, acc: 0.656250] [adversarial loss: 0.904844, acc: 0.406250]\n",
            "35938: [discriminator loss: 0.542013, acc: 0.734375] [adversarial loss: 1.035938, acc: 0.250000]\n",
            "35939: [discriminator loss: 0.530958, acc: 0.726562] [adversarial loss: 0.810519, acc: 0.500000]\n",
            "35940: [discriminator loss: 0.532804, acc: 0.734375] [adversarial loss: 1.168537, acc: 0.265625]\n",
            "35941: [discriminator loss: 0.538774, acc: 0.695312] [adversarial loss: 0.927180, acc: 0.359375]\n",
            "35942: [discriminator loss: 0.586640, acc: 0.679688] [adversarial loss: 0.999253, acc: 0.359375]\n",
            "35943: [discriminator loss: 0.576374, acc: 0.703125] [adversarial loss: 1.165249, acc: 0.187500]\n",
            "35944: [discriminator loss: 0.590368, acc: 0.671875] [adversarial loss: 0.994249, acc: 0.343750]\n",
            "35945: [discriminator loss: 0.656715, acc: 0.570312] [adversarial loss: 1.032268, acc: 0.250000]\n",
            "35946: [discriminator loss: 0.567663, acc: 0.679688] [adversarial loss: 1.002746, acc: 0.343750]\n",
            "35947: [discriminator loss: 0.591115, acc: 0.703125] [adversarial loss: 1.309061, acc: 0.171875]\n",
            "35948: [discriminator loss: 0.640856, acc: 0.640625] [adversarial loss: 0.640892, acc: 0.593750]\n",
            "35949: [discriminator loss: 0.647472, acc: 0.648438] [adversarial loss: 1.407735, acc: 0.093750]\n",
            "35950: [discriminator loss: 0.620728, acc: 0.656250] [adversarial loss: 1.060846, acc: 0.343750]\n",
            "35951: [discriminator loss: 0.645049, acc: 0.585938] [adversarial loss: 1.085473, acc: 0.203125]\n",
            "35952: [discriminator loss: 0.521254, acc: 0.742188] [adversarial loss: 1.167246, acc: 0.296875]\n",
            "35953: [discriminator loss: 0.559348, acc: 0.710938] [adversarial loss: 0.850801, acc: 0.453125]\n",
            "35954: [discriminator loss: 0.602054, acc: 0.703125] [adversarial loss: 1.193882, acc: 0.171875]\n",
            "35955: [discriminator loss: 0.578852, acc: 0.703125] [adversarial loss: 0.987937, acc: 0.312500]\n",
            "35956: [discriminator loss: 0.577884, acc: 0.703125] [adversarial loss: 1.151196, acc: 0.265625]\n",
            "35957: [discriminator loss: 0.603526, acc: 0.632812] [adversarial loss: 0.840298, acc: 0.406250]\n",
            "35958: [discriminator loss: 0.634704, acc: 0.656250] [adversarial loss: 1.205923, acc: 0.218750]\n",
            "35959: [discriminator loss: 0.557830, acc: 0.734375] [adversarial loss: 0.904287, acc: 0.437500]\n",
            "35960: [discriminator loss: 0.536608, acc: 0.710938] [adversarial loss: 1.094418, acc: 0.312500]\n",
            "35961: [discriminator loss: 0.616177, acc: 0.656250] [adversarial loss: 0.851339, acc: 0.484375]\n",
            "35962: [discriminator loss: 0.620105, acc: 0.695312] [adversarial loss: 1.188964, acc: 0.140625]\n",
            "35963: [discriminator loss: 0.518860, acc: 0.765625] [adversarial loss: 1.024834, acc: 0.281250]\n",
            "35964: [discriminator loss: 0.577239, acc: 0.734375] [adversarial loss: 0.895786, acc: 0.406250]\n",
            "35965: [discriminator loss: 0.584881, acc: 0.687500] [adversarial loss: 0.997856, acc: 0.343750]\n",
            "35966: [discriminator loss: 0.643846, acc: 0.664062] [adversarial loss: 0.880896, acc: 0.406250]\n",
            "35967: [discriminator loss: 0.656327, acc: 0.601562] [adversarial loss: 1.044440, acc: 0.218750]\n",
            "35968: [discriminator loss: 0.576252, acc: 0.656250] [adversarial loss: 0.978705, acc: 0.343750]\n",
            "35969: [discriminator loss: 0.570696, acc: 0.640625] [adversarial loss: 1.218713, acc: 0.187500]\n",
            "35970: [discriminator loss: 0.638115, acc: 0.609375] [adversarial loss: 0.875821, acc: 0.421875]\n",
            "35971: [discriminator loss: 0.589834, acc: 0.742188] [adversarial loss: 1.059098, acc: 0.312500]\n",
            "35972: [discriminator loss: 0.613320, acc: 0.671875] [adversarial loss: 1.164842, acc: 0.281250]\n",
            "35973: [discriminator loss: 0.559564, acc: 0.742188] [adversarial loss: 1.085441, acc: 0.281250]\n",
            "35974: [discriminator loss: 0.582591, acc: 0.679688] [adversarial loss: 1.266306, acc: 0.187500]\n",
            "35975: [discriminator loss: 0.603706, acc: 0.695312] [adversarial loss: 0.989751, acc: 0.375000]\n",
            "35976: [discriminator loss: 0.641016, acc: 0.656250] [adversarial loss: 1.156711, acc: 0.218750]\n",
            "35977: [discriminator loss: 0.569025, acc: 0.695312] [adversarial loss: 0.731669, acc: 0.562500]\n",
            "35978: [discriminator loss: 0.617517, acc: 0.656250] [adversarial loss: 1.165785, acc: 0.156250]\n",
            "35979: [discriminator loss: 0.593250, acc: 0.648438] [adversarial loss: 0.946696, acc: 0.343750]\n",
            "35980: [discriminator loss: 0.635376, acc: 0.640625] [adversarial loss: 1.053003, acc: 0.203125]\n",
            "35981: [discriminator loss: 0.617810, acc: 0.664062] [adversarial loss: 0.981164, acc: 0.390625]\n",
            "35982: [discriminator loss: 0.658768, acc: 0.609375] [adversarial loss: 0.981517, acc: 0.312500]\n",
            "35983: [discriminator loss: 0.654186, acc: 0.648438] [adversarial loss: 1.161840, acc: 0.218750]\n",
            "35984: [discriminator loss: 0.589896, acc: 0.632812] [adversarial loss: 1.060679, acc: 0.265625]\n",
            "35985: [discriminator loss: 0.644667, acc: 0.640625] [adversarial loss: 1.163318, acc: 0.281250]\n",
            "35986: [discriminator loss: 0.613711, acc: 0.671875] [adversarial loss: 1.258160, acc: 0.171875]\n",
            "35987: [discriminator loss: 0.562790, acc: 0.734375] [adversarial loss: 1.095282, acc: 0.359375]\n",
            "35988: [discriminator loss: 0.583897, acc: 0.648438] [adversarial loss: 0.921676, acc: 0.312500]\n",
            "35989: [discriminator loss: 0.581420, acc: 0.679688] [adversarial loss: 1.223745, acc: 0.187500]\n",
            "35990: [discriminator loss: 0.634049, acc: 0.640625] [adversarial loss: 1.011737, acc: 0.343750]\n",
            "35991: [discriminator loss: 0.560188, acc: 0.742188] [adversarial loss: 1.176131, acc: 0.218750]\n",
            "35992: [discriminator loss: 0.578731, acc: 0.671875] [adversarial loss: 0.982473, acc: 0.296875]\n",
            "35993: [discriminator loss: 0.549888, acc: 0.742188] [adversarial loss: 0.998949, acc: 0.375000]\n",
            "35994: [discriminator loss: 0.610322, acc: 0.632812] [adversarial loss: 0.853255, acc: 0.437500]\n",
            "35995: [discriminator loss: 0.591139, acc: 0.687500] [adversarial loss: 1.091938, acc: 0.218750]\n",
            "35996: [discriminator loss: 0.596225, acc: 0.671875] [adversarial loss: 0.785260, acc: 0.531250]\n",
            "35997: [discriminator loss: 0.556105, acc: 0.656250] [adversarial loss: 1.396057, acc: 0.125000]\n",
            "35998: [discriminator loss: 0.590784, acc: 0.648438] [adversarial loss: 1.033299, acc: 0.328125]\n",
            "35999: [discriminator loss: 0.537232, acc: 0.703125] [adversarial loss: 0.950986, acc: 0.390625]\n",
            "cgan_mnist  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
            "36000: [discriminator loss: 0.600812, acc: 0.703125] [adversarial loss: 1.326167, acc: 0.140625]\n",
            "36001: [discriminator loss: 0.600378, acc: 0.664062] [adversarial loss: 0.875361, acc: 0.468750]\n",
            "36002: [discriminator loss: 0.653669, acc: 0.617188] [adversarial loss: 1.147455, acc: 0.265625]\n",
            "36003: [discriminator loss: 0.569820, acc: 0.710938] [adversarial loss: 0.958189, acc: 0.375000]\n",
            "36004: [discriminator loss: 0.583992, acc: 0.718750] [adversarial loss: 1.123363, acc: 0.328125]\n",
            "36005: [discriminator loss: 0.567051, acc: 0.671875] [adversarial loss: 1.063677, acc: 0.328125]\n",
            "36006: [discriminator loss: 0.564634, acc: 0.679688] [adversarial loss: 1.094092, acc: 0.343750]\n",
            "36007: [discriminator loss: 0.515761, acc: 0.773438] [adversarial loss: 1.177719, acc: 0.234375]\n",
            "36008: [discriminator loss: 0.565174, acc: 0.734375] [adversarial loss: 1.110537, acc: 0.296875]\n",
            "36009: [discriminator loss: 0.577840, acc: 0.671875] [adversarial loss: 1.107842, acc: 0.265625]\n",
            "36010: [discriminator loss: 0.649541, acc: 0.625000] [adversarial loss: 0.904308, acc: 0.484375]\n",
            "36011: [discriminator loss: 0.628557, acc: 0.664062] [adversarial loss: 1.212164, acc: 0.187500]\n",
            "36012: [discriminator loss: 0.618886, acc: 0.632812] [adversarial loss: 0.890002, acc: 0.390625]\n",
            "36013: [discriminator loss: 0.524248, acc: 0.703125] [adversarial loss: 1.236304, acc: 0.203125]\n",
            "36014: [discriminator loss: 0.611108, acc: 0.648438] [adversarial loss: 0.909438, acc: 0.437500]\n",
            "36015: [discriminator loss: 0.556345, acc: 0.710938] [adversarial loss: 1.230142, acc: 0.187500]\n",
            "36016: [discriminator loss: 0.557866, acc: 0.710938] [adversarial loss: 1.082296, acc: 0.328125]\n",
            "36017: [discriminator loss: 0.616834, acc: 0.640625] [adversarial loss: 1.168782, acc: 0.187500]\n",
            "36018: [discriminator loss: 0.650576, acc: 0.609375] [adversarial loss: 0.816192, acc: 0.500000]\n",
            "36019: [discriminator loss: 0.694711, acc: 0.578125] [adversarial loss: 1.227453, acc: 0.250000]\n",
            "36020: [discriminator loss: 0.564053, acc: 0.687500] [adversarial loss: 0.957355, acc: 0.328125]\n",
            "36021: [discriminator loss: 0.588368, acc: 0.742188] [adversarial loss: 0.924412, acc: 0.359375]\n",
            "36022: [discriminator loss: 0.519527, acc: 0.765625] [adversarial loss: 1.078379, acc: 0.265625]\n",
            "36023: [discriminator loss: 0.594602, acc: 0.648438] [adversarial loss: 0.708827, acc: 0.562500]\n",
            "36024: [discriminator loss: 0.697109, acc: 0.585938] [adversarial loss: 1.413441, acc: 0.187500]\n",
            "36025: [discriminator loss: 0.611368, acc: 0.664062] [adversarial loss: 0.798697, acc: 0.500000]\n",
            "36026: [discriminator loss: 0.628289, acc: 0.656250] [adversarial loss: 1.338409, acc: 0.125000]\n",
            "36027: [discriminator loss: 0.560018, acc: 0.664062] [adversarial loss: 0.854285, acc: 0.453125]\n",
            "36028: [discriminator loss: 0.605416, acc: 0.718750] [adversarial loss: 1.049682, acc: 0.265625]\n",
            "36029: [discriminator loss: 0.592271, acc: 0.640625] [adversarial loss: 1.014471, acc: 0.343750]\n",
            "36030: [discriminator loss: 0.522082, acc: 0.765625] [adversarial loss: 0.911388, acc: 0.421875]\n",
            "36031: [discriminator loss: 0.576841, acc: 0.687500] [adversarial loss: 0.946182, acc: 0.328125]\n",
            "36032: [discriminator loss: 0.627719, acc: 0.640625] [adversarial loss: 1.095523, acc: 0.359375]\n",
            "36033: [discriminator loss: 0.556323, acc: 0.718750] [adversarial loss: 1.151311, acc: 0.250000]\n",
            "36034: [discriminator loss: 0.547612, acc: 0.750000] [adversarial loss: 1.036337, acc: 0.328125]\n",
            "36035: [discriminator loss: 0.558219, acc: 0.695312] [adversarial loss: 1.053143, acc: 0.234375]\n",
            "36036: [discriminator loss: 0.595138, acc: 0.648438] [adversarial loss: 0.991006, acc: 0.312500]\n",
            "36037: [discriminator loss: 0.583752, acc: 0.687500] [adversarial loss: 0.936718, acc: 0.359375]\n",
            "36038: [discriminator loss: 0.629519, acc: 0.632812] [adversarial loss: 1.119195, acc: 0.265625]\n",
            "36039: [discriminator loss: 0.559912, acc: 0.726562] [adversarial loss: 0.903056, acc: 0.406250]\n",
            "36040: [discriminator loss: 0.623654, acc: 0.656250] [adversarial loss: 1.108767, acc: 0.296875]\n",
            "36041: [discriminator loss: 0.525888, acc: 0.718750] [adversarial loss: 1.103360, acc: 0.218750]\n",
            "36042: [discriminator loss: 0.627125, acc: 0.585938] [adversarial loss: 0.875739, acc: 0.468750]\n",
            "36043: [discriminator loss: 0.576751, acc: 0.718750] [adversarial loss: 1.153385, acc: 0.265625]\n",
            "36044: [discriminator loss: 0.577524, acc: 0.695312] [adversarial loss: 0.907400, acc: 0.406250]\n",
            "36045: [discriminator loss: 0.559986, acc: 0.656250] [adversarial loss: 1.203448, acc: 0.171875]\n",
            "36046: [discriminator loss: 0.655616, acc: 0.625000] [adversarial loss: 0.752977, acc: 0.468750]\n",
            "36047: [discriminator loss: 0.554036, acc: 0.687500] [adversarial loss: 1.126265, acc: 0.203125]\n",
            "36048: [discriminator loss: 0.639576, acc: 0.609375] [adversarial loss: 0.869124, acc: 0.468750]\n",
            "36049: [discriminator loss: 0.612828, acc: 0.656250] [adversarial loss: 1.160986, acc: 0.156250]\n",
            "36050: [discriminator loss: 0.573161, acc: 0.726562] [adversarial loss: 0.845329, acc: 0.468750]\n",
            "36051: [discriminator loss: 0.565418, acc: 0.695312] [adversarial loss: 1.217086, acc: 0.234375]\n",
            "36052: [discriminator loss: 0.622742, acc: 0.656250] [adversarial loss: 0.908065, acc: 0.281250]\n",
            "36053: [discriminator loss: 0.534822, acc: 0.742188] [adversarial loss: 1.070299, acc: 0.203125]\n",
            "36054: [discriminator loss: 0.553679, acc: 0.703125] [adversarial loss: 1.149727, acc: 0.203125]\n",
            "36055: [discriminator loss: 0.595637, acc: 0.703125] [adversarial loss: 1.040704, acc: 0.343750]\n",
            "36056: [discriminator loss: 0.601946, acc: 0.679688] [adversarial loss: 1.100850, acc: 0.265625]\n",
            "36057: [discriminator loss: 0.635574, acc: 0.617188] [adversarial loss: 1.001548, acc: 0.265625]\n",
            "36058: [discriminator loss: 0.570544, acc: 0.734375] [adversarial loss: 1.092423, acc: 0.343750]\n",
            "36059: [discriminator loss: 0.557087, acc: 0.703125] [adversarial loss: 0.840190, acc: 0.421875]\n",
            "36060: [discriminator loss: 0.596723, acc: 0.679688] [adversarial loss: 1.166259, acc: 0.281250]\n",
            "36061: [discriminator loss: 0.581105, acc: 0.695312] [adversarial loss: 0.965655, acc: 0.390625]\n",
            "36062: [discriminator loss: 0.584082, acc: 0.703125] [adversarial loss: 1.224510, acc: 0.218750]\n",
            "36063: [discriminator loss: 0.586089, acc: 0.656250] [adversarial loss: 0.963156, acc: 0.375000]\n",
            "36064: [discriminator loss: 0.569503, acc: 0.710938] [adversarial loss: 1.214776, acc: 0.281250]\n",
            "36065: [discriminator loss: 0.658336, acc: 0.601562] [adversarial loss: 0.921906, acc: 0.375000]\n",
            "36066: [discriminator loss: 0.555640, acc: 0.703125] [adversarial loss: 1.057981, acc: 0.296875]\n",
            "36067: [discriminator loss: 0.576178, acc: 0.648438] [adversarial loss: 1.300850, acc: 0.140625]\n",
            "36068: [discriminator loss: 0.603542, acc: 0.656250] [adversarial loss: 1.205033, acc: 0.218750]\n",
            "36069: [discriminator loss: 0.611036, acc: 0.671875] [adversarial loss: 0.929976, acc: 0.312500]\n",
            "36070: [discriminator loss: 0.619875, acc: 0.625000] [adversarial loss: 1.040275, acc: 0.218750]\n",
            "36071: [discriminator loss: 0.591386, acc: 0.679688] [adversarial loss: 1.133303, acc: 0.203125]\n",
            "36072: [discriminator loss: 0.563625, acc: 0.679688] [adversarial loss: 0.838381, acc: 0.453125]\n",
            "36073: [discriminator loss: 0.634318, acc: 0.656250] [adversarial loss: 1.446861, acc: 0.125000]\n",
            "36074: [discriminator loss: 0.643710, acc: 0.601562] [adversarial loss: 0.684970, acc: 0.593750]\n",
            "36075: [discriminator loss: 0.563321, acc: 0.726562] [adversarial loss: 1.278765, acc: 0.109375]\n",
            "36076: [discriminator loss: 0.630136, acc: 0.648438] [adversarial loss: 1.094374, acc: 0.218750]\n",
            "36077: [discriminator loss: 0.555683, acc: 0.687500] [adversarial loss: 1.032217, acc: 0.250000]\n",
            "36078: [discriminator loss: 0.547301, acc: 0.718750] [adversarial loss: 0.906482, acc: 0.390625]\n",
            "36079: [discriminator loss: 0.593191, acc: 0.664062] [adversarial loss: 1.175468, acc: 0.156250]\n",
            "36080: [discriminator loss: 0.571448, acc: 0.695312] [adversarial loss: 0.938101, acc: 0.359375]\n",
            "36081: [discriminator loss: 0.583654, acc: 0.671875] [adversarial loss: 1.026837, acc: 0.234375]\n",
            "36082: [discriminator loss: 0.599399, acc: 0.648438] [adversarial loss: 0.936744, acc: 0.312500]\n",
            "36083: [discriminator loss: 0.571423, acc: 0.656250] [adversarial loss: 1.050036, acc: 0.328125]\n",
            "36084: [discriminator loss: 0.535097, acc: 0.734375] [adversarial loss: 1.108997, acc: 0.250000]\n",
            "36085: [discriminator loss: 0.631356, acc: 0.656250] [adversarial loss: 0.939474, acc: 0.375000]\n",
            "36086: [discriminator loss: 0.590549, acc: 0.695312] [adversarial loss: 0.920126, acc: 0.359375]\n",
            "36087: [discriminator loss: 0.587414, acc: 0.687500] [adversarial loss: 1.137719, acc: 0.265625]\n",
            "36088: [discriminator loss: 0.591715, acc: 0.648438] [adversarial loss: 1.027265, acc: 0.375000]\n",
            "36089: [discriminator loss: 0.551906, acc: 0.734375] [adversarial loss: 0.991181, acc: 0.296875]\n",
            "36090: [discriminator loss: 0.515172, acc: 0.765625] [adversarial loss: 0.786587, acc: 0.453125]\n",
            "36091: [discriminator loss: 0.595077, acc: 0.617188] [adversarial loss: 1.300925, acc: 0.156250]\n",
            "36092: [discriminator loss: 0.558890, acc: 0.703125] [adversarial loss: 0.737500, acc: 0.515625]\n",
            "36093: [discriminator loss: 0.567720, acc: 0.734375] [adversarial loss: 1.136089, acc: 0.281250]\n",
            "36094: [discriminator loss: 0.548095, acc: 0.710938] [adversarial loss: 1.262661, acc: 0.203125]\n",
            "36095: [discriminator loss: 0.559921, acc: 0.687500] [adversarial loss: 0.961318, acc: 0.390625]\n",
            "36096: [discriminator loss: 0.583843, acc: 0.687500] [adversarial loss: 0.945384, acc: 0.312500]\n",
            "36097: [discriminator loss: 0.579441, acc: 0.679688] [adversarial loss: 0.948337, acc: 0.375000]\n",
            "36098: [discriminator loss: 0.598731, acc: 0.664062] [adversarial loss: 1.173701, acc: 0.218750]\n",
            "36099: [discriminator loss: 0.533263, acc: 0.718750] [adversarial loss: 1.041720, acc: 0.312500]\n",
            "36100: [discriminator loss: 0.557541, acc: 0.734375] [adversarial loss: 0.992672, acc: 0.359375]\n",
            "36101: [discriminator loss: 0.612497, acc: 0.656250] [adversarial loss: 1.004866, acc: 0.312500]\n",
            "36102: [discriminator loss: 0.637569, acc: 0.632812] [adversarial loss: 1.122895, acc: 0.296875]\n",
            "36103: [discriminator loss: 0.636888, acc: 0.617188] [adversarial loss: 0.934294, acc: 0.421875]\n",
            "36104: [discriminator loss: 0.554939, acc: 0.679688] [adversarial loss: 1.206450, acc: 0.218750]\n",
            "36105: [discriminator loss: 0.603109, acc: 0.695312] [adversarial loss: 0.882792, acc: 0.359375]\n",
            "36106: [discriminator loss: 0.552426, acc: 0.710938] [adversarial loss: 1.204087, acc: 0.265625]\n",
            "36107: [discriminator loss: 0.556003, acc: 0.703125] [adversarial loss: 1.002267, acc: 0.296875]\n",
            "36108: [discriminator loss: 0.590141, acc: 0.664062] [adversarial loss: 1.139640, acc: 0.265625]\n",
            "36109: [discriminator loss: 0.587114, acc: 0.671875] [adversarial loss: 0.937676, acc: 0.406250]\n",
            "36110: [discriminator loss: 0.602548, acc: 0.710938] [adversarial loss: 1.388738, acc: 0.093750]\n",
            "36111: [discriminator loss: 0.606960, acc: 0.671875] [adversarial loss: 0.866243, acc: 0.484375]\n",
            "36112: [discriminator loss: 0.602044, acc: 0.664062] [adversarial loss: 1.127439, acc: 0.281250]\n",
            "36113: [discriminator loss: 0.608059, acc: 0.640625] [adversarial loss: 1.013221, acc: 0.343750]\n",
            "36114: [discriminator loss: 0.578932, acc: 0.671875] [adversarial loss: 1.367983, acc: 0.171875]\n",
            "36115: [discriminator loss: 0.596059, acc: 0.656250] [adversarial loss: 0.781237, acc: 0.500000]\n",
            "36116: [discriminator loss: 0.581313, acc: 0.679688] [adversarial loss: 1.045297, acc: 0.375000]\n",
            "36117: [discriminator loss: 0.559335, acc: 0.734375] [adversarial loss: 1.075162, acc: 0.281250]\n",
            "36118: [discriminator loss: 0.608912, acc: 0.640625] [adversarial loss: 1.467099, acc: 0.156250]\n",
            "36119: [discriminator loss: 0.609728, acc: 0.671875] [adversarial loss: 0.825073, acc: 0.484375]\n",
            "36120: [discriminator loss: 0.570563, acc: 0.664062] [adversarial loss: 1.292831, acc: 0.125000]\n",
            "36121: [discriminator loss: 0.573372, acc: 0.726562] [adversarial loss: 0.984024, acc: 0.375000]\n",
            "36122: [discriminator loss: 0.568501, acc: 0.703125] [adversarial loss: 1.077744, acc: 0.359375]\n",
            "36123: [discriminator loss: 0.573893, acc: 0.710938] [adversarial loss: 0.854525, acc: 0.406250]\n",
            "36124: [discriminator loss: 0.570760, acc: 0.695312] [adversarial loss: 1.173348, acc: 0.187500]\n",
            "36125: [discriminator loss: 0.538684, acc: 0.765625] [adversarial loss: 0.787301, acc: 0.531250]\n",
            "36126: [discriminator loss: 0.544823, acc: 0.687500] [adversarial loss: 1.438753, acc: 0.156250]\n",
            "36127: [discriminator loss: 0.574307, acc: 0.648438] [adversarial loss: 0.788370, acc: 0.515625]\n",
            "36128: [discriminator loss: 0.595532, acc: 0.679688] [adversarial loss: 1.104352, acc: 0.281250]\n",
            "36129: [discriminator loss: 0.562959, acc: 0.695312] [adversarial loss: 1.024247, acc: 0.328125]\n",
            "36130: [discriminator loss: 0.658453, acc: 0.632812] [adversarial loss: 1.068748, acc: 0.265625]\n",
            "36131: [discriminator loss: 0.541566, acc: 0.695312] [adversarial loss: 0.923774, acc: 0.328125]\n",
            "36132: [discriminator loss: 0.494656, acc: 0.750000] [adversarial loss: 0.938273, acc: 0.312500]\n",
            "36133: [discriminator loss: 0.573386, acc: 0.695312] [adversarial loss: 1.100303, acc: 0.250000]\n",
            "36134: [discriminator loss: 0.591174, acc: 0.687500] [adversarial loss: 0.902935, acc: 0.406250]\n",
            "36135: [discriminator loss: 0.603277, acc: 0.656250] [adversarial loss: 1.361573, acc: 0.156250]\n",
            "36136: [discriminator loss: 0.592339, acc: 0.664062] [adversarial loss: 0.846118, acc: 0.500000]\n",
            "36137: [discriminator loss: 0.570010, acc: 0.695312] [adversarial loss: 1.438511, acc: 0.125000]\n",
            "36138: [discriminator loss: 0.632468, acc: 0.625000] [adversarial loss: 0.798739, acc: 0.484375]\n",
            "36139: [discriminator loss: 0.595216, acc: 0.664062] [adversarial loss: 1.209689, acc: 0.171875]\n",
            "36140: [discriminator loss: 0.563908, acc: 0.695312] [adversarial loss: 1.079329, acc: 0.312500]\n",
            "36141: [discriminator loss: 0.631234, acc: 0.593750] [adversarial loss: 1.070192, acc: 0.312500]\n",
            "36142: [discriminator loss: 0.534016, acc: 0.773438] [adversarial loss: 1.343949, acc: 0.171875]\n",
            "36143: [discriminator loss: 0.606064, acc: 0.648438] [adversarial loss: 0.883842, acc: 0.437500]\n",
            "36144: [discriminator loss: 0.634050, acc: 0.687500] [adversarial loss: 1.418314, acc: 0.171875]\n",
            "36145: [discriminator loss: 0.578523, acc: 0.671875] [adversarial loss: 0.987757, acc: 0.437500]\n",
            "36146: [discriminator loss: 0.546112, acc: 0.742188] [adversarial loss: 0.979304, acc: 0.250000]\n",
            "36147: [discriminator loss: 0.589032, acc: 0.695312] [adversarial loss: 1.108405, acc: 0.328125]\n",
            "36148: [discriminator loss: 0.585778, acc: 0.679688] [adversarial loss: 0.960021, acc: 0.484375]\n",
            "36149: [discriminator loss: 0.578023, acc: 0.695312] [adversarial loss: 1.089312, acc: 0.359375]\n",
            "36150: [discriminator loss: 0.566603, acc: 0.703125] [adversarial loss: 0.913796, acc: 0.437500]\n",
            "36151: [discriminator loss: 0.605438, acc: 0.625000] [adversarial loss: 1.172890, acc: 0.203125]\n",
            "36152: [discriminator loss: 0.546791, acc: 0.695312] [adversarial loss: 0.936882, acc: 0.375000]\n",
            "36153: [discriminator loss: 0.547862, acc: 0.750000] [adversarial loss: 1.266204, acc: 0.218750]\n",
            "36154: [discriminator loss: 0.602472, acc: 0.664062] [adversarial loss: 1.026138, acc: 0.375000]\n",
            "36155: [discriminator loss: 0.591793, acc: 0.617188] [adversarial loss: 0.943252, acc: 0.328125]\n",
            "36156: [discriminator loss: 0.620063, acc: 0.632812] [adversarial loss: 1.077510, acc: 0.234375]\n",
            "36157: [discriminator loss: 0.515265, acc: 0.757812] [adversarial loss: 0.986563, acc: 0.343750]\n",
            "36158: [discriminator loss: 0.492587, acc: 0.750000] [adversarial loss: 0.923452, acc: 0.406250]\n",
            "36159: [discriminator loss: 0.613385, acc: 0.648438] [adversarial loss: 1.123313, acc: 0.359375]\n",
            "36160: [discriminator loss: 0.644853, acc: 0.617188] [adversarial loss: 0.930505, acc: 0.281250]\n",
            "36161: [discriminator loss: 0.521626, acc: 0.734375] [adversarial loss: 1.158110, acc: 0.234375]\n",
            "36162: [discriminator loss: 0.662050, acc: 0.640625] [adversarial loss: 1.093760, acc: 0.234375]\n",
            "36163: [discriminator loss: 0.637695, acc: 0.546875] [adversarial loss: 1.214786, acc: 0.250000]\n",
            "36164: [discriminator loss: 0.557612, acc: 0.695312] [adversarial loss: 0.746685, acc: 0.500000]\n",
            "36165: [discriminator loss: 0.633059, acc: 0.640625] [adversarial loss: 1.504218, acc: 0.125000]\n",
            "36166: [discriminator loss: 0.595341, acc: 0.648438] [adversarial loss: 0.904144, acc: 0.453125]\n",
            "36167: [discriminator loss: 0.585908, acc: 0.718750] [adversarial loss: 0.928160, acc: 0.375000]\n",
            "36168: [discriminator loss: 0.621074, acc: 0.656250] [adversarial loss: 1.068984, acc: 0.281250]\n",
            "36169: [discriminator loss: 0.567912, acc: 0.695312] [adversarial loss: 1.144512, acc: 0.375000]\n",
            "36170: [discriminator loss: 0.612331, acc: 0.679688] [adversarial loss: 0.946504, acc: 0.437500]\n",
            "36171: [discriminator loss: 0.664204, acc: 0.632812] [adversarial loss: 1.329854, acc: 0.125000]\n",
            "36172: [discriminator loss: 0.613070, acc: 0.617188] [adversarial loss: 0.835807, acc: 0.406250]\n",
            "36173: [discriminator loss: 0.589779, acc: 0.687500] [adversarial loss: 1.236177, acc: 0.156250]\n",
            "36174: [discriminator loss: 0.630517, acc: 0.648438] [adversarial loss: 0.898524, acc: 0.328125]\n",
            "36175: [discriminator loss: 0.630389, acc: 0.640625] [adversarial loss: 1.197952, acc: 0.250000]\n",
            "36176: [discriminator loss: 0.612427, acc: 0.664062] [adversarial loss: 1.134223, acc: 0.312500]\n",
            "36177: [discriminator loss: 0.612181, acc: 0.648438] [adversarial loss: 1.370964, acc: 0.109375]\n",
            "36178: [discriminator loss: 0.579589, acc: 0.695312] [adversarial loss: 0.924264, acc: 0.484375]\n",
            "36179: [discriminator loss: 0.614117, acc: 0.671875] [adversarial loss: 1.303300, acc: 0.140625]\n",
            "36180: [discriminator loss: 0.613255, acc: 0.656250] [adversarial loss: 1.151377, acc: 0.203125]\n",
            "36181: [discriminator loss: 0.613636, acc: 0.679688] [adversarial loss: 0.826840, acc: 0.453125]\n",
            "36182: [discriminator loss: 0.550932, acc: 0.718750] [adversarial loss: 1.065326, acc: 0.265625]\n",
            "36183: [discriminator loss: 0.676999, acc: 0.632812] [adversarial loss: 1.001389, acc: 0.296875]\n",
            "36184: [discriminator loss: 0.590696, acc: 0.648438] [adversarial loss: 1.012027, acc: 0.281250]\n",
            "36185: [discriminator loss: 0.564448, acc: 0.695312] [adversarial loss: 0.989283, acc: 0.250000]\n",
            "36186: [discriminator loss: 0.545607, acc: 0.750000] [adversarial loss: 1.154475, acc: 0.296875]\n",
            "36187: [discriminator loss: 0.608500, acc: 0.671875] [adversarial loss: 1.255479, acc: 0.187500]\n",
            "36188: [discriminator loss: 0.559963, acc: 0.656250] [adversarial loss: 0.943390, acc: 0.390625]\n",
            "36189: [discriminator loss: 0.570611, acc: 0.734375] [adversarial loss: 1.106104, acc: 0.265625]\n",
            "36190: [discriminator loss: 0.522385, acc: 0.718750] [adversarial loss: 0.853376, acc: 0.453125]\n",
            "36191: [discriminator loss: 0.585575, acc: 0.710938] [adversarial loss: 1.120206, acc: 0.281250]\n",
            "36192: [discriminator loss: 0.593817, acc: 0.640625] [adversarial loss: 0.949437, acc: 0.421875]\n",
            "36193: [discriminator loss: 0.581993, acc: 0.664062] [adversarial loss: 1.205532, acc: 0.234375]\n",
            "36194: [discriminator loss: 0.540677, acc: 0.703125] [adversarial loss: 0.898947, acc: 0.375000]\n",
            "36195: [discriminator loss: 0.582616, acc: 0.687500] [adversarial loss: 0.937238, acc: 0.343750]\n",
            "36196: [discriminator loss: 0.598130, acc: 0.679688] [adversarial loss: 1.122472, acc: 0.234375]\n",
            "36197: [discriminator loss: 0.577663, acc: 0.664062] [adversarial loss: 1.026610, acc: 0.359375]\n",
            "36198: [discriminator loss: 0.562288, acc: 0.703125] [adversarial loss: 1.083309, acc: 0.281250]\n",
            "36199: [discriminator loss: 0.596967, acc: 0.664062] [adversarial loss: 0.785606, acc: 0.515625]\n",
            "36200: [discriminator loss: 0.536892, acc: 0.742188] [adversarial loss: 1.261858, acc: 0.156250]\n",
            "36201: [discriminator loss: 0.598599, acc: 0.664062] [adversarial loss: 0.877319, acc: 0.453125]\n",
            "36202: [discriminator loss: 0.564755, acc: 0.703125] [adversarial loss: 1.173020, acc: 0.265625]\n",
            "36203: [discriminator loss: 0.588326, acc: 0.656250] [adversarial loss: 0.761195, acc: 0.546875]\n",
            "36204: [discriminator loss: 0.612719, acc: 0.648438] [adversarial loss: 1.100813, acc: 0.203125]\n",
            "36205: [discriminator loss: 0.581045, acc: 0.679688] [adversarial loss: 1.228687, acc: 0.203125]\n",
            "36206: [discriminator loss: 0.558410, acc: 0.710938] [adversarial loss: 0.863660, acc: 0.343750]\n",
            "36207: [discriminator loss: 0.567310, acc: 0.726562] [adversarial loss: 1.241223, acc: 0.203125]\n",
            "36208: [discriminator loss: 0.615860, acc: 0.664062] [adversarial loss: 0.841076, acc: 0.437500]\n",
            "36209: [discriminator loss: 0.617859, acc: 0.671875] [adversarial loss: 1.145823, acc: 0.140625]\n",
            "36210: [discriminator loss: 0.590792, acc: 0.664062] [adversarial loss: 0.795667, acc: 0.546875]\n",
            "36211: [discriminator loss: 0.550779, acc: 0.750000] [adversarial loss: 1.041319, acc: 0.359375]\n",
            "36212: [discriminator loss: 0.595813, acc: 0.679688] [adversarial loss: 1.030434, acc: 0.328125]\n",
            "36213: [discriminator loss: 0.562154, acc: 0.679688] [adversarial loss: 1.444953, acc: 0.140625]\n",
            "36214: [discriminator loss: 0.565138, acc: 0.718750] [adversarial loss: 0.895823, acc: 0.421875]\n",
            "36215: [discriminator loss: 0.583177, acc: 0.671875] [adversarial loss: 1.127192, acc: 0.203125]\n",
            "36216: [discriminator loss: 0.596764, acc: 0.632812] [adversarial loss: 1.086669, acc: 0.250000]\n",
            "36217: [discriminator loss: 0.653390, acc: 0.625000] [adversarial loss: 1.114041, acc: 0.203125]\n",
            "36218: [discriminator loss: 0.592736, acc: 0.703125] [adversarial loss: 0.975687, acc: 0.375000]\n",
            "36219: [discriminator loss: 0.503287, acc: 0.781250] [adversarial loss: 0.947628, acc: 0.375000]\n",
            "36220: [discriminator loss: 0.543897, acc: 0.703125] [adversarial loss: 1.108674, acc: 0.281250]\n",
            "36221: [discriminator loss: 0.568333, acc: 0.695312] [adversarial loss: 0.903600, acc: 0.421875]\n",
            "36222: [discriminator loss: 0.579583, acc: 0.703125] [adversarial loss: 1.232280, acc: 0.187500]\n",
            "36223: [discriminator loss: 0.609208, acc: 0.710938] [adversarial loss: 0.960430, acc: 0.390625]\n",
            "36224: [discriminator loss: 0.691463, acc: 0.625000] [adversarial loss: 1.390079, acc: 0.187500]\n",
            "36225: [discriminator loss: 0.620990, acc: 0.632812] [adversarial loss: 0.690566, acc: 0.562500]\n",
            "36226: [discriminator loss: 0.667210, acc: 0.609375] [adversarial loss: 1.410162, acc: 0.156250]\n",
            "36227: [discriminator loss: 0.600481, acc: 0.648438] [adversarial loss: 0.925694, acc: 0.312500]\n",
            "36228: [discriminator loss: 0.474702, acc: 0.796875] [adversarial loss: 0.983613, acc: 0.359375]\n",
            "36229: [discriminator loss: 0.591085, acc: 0.687500] [adversarial loss: 1.417855, acc: 0.093750]\n",
            "36230: [discriminator loss: 0.574698, acc: 0.679688] [adversarial loss: 0.856532, acc: 0.390625]\n",
            "36231: [discriminator loss: 0.520647, acc: 0.734375] [adversarial loss: 1.364524, acc: 0.218750]\n",
            "36232: [discriminator loss: 0.608817, acc: 0.625000] [adversarial loss: 1.033424, acc: 0.343750]\n",
            "36233: [discriminator loss: 0.572317, acc: 0.671875] [adversarial loss: 0.826290, acc: 0.421875]\n",
            "36234: [discriminator loss: 0.582792, acc: 0.703125] [adversarial loss: 1.075470, acc: 0.171875]\n",
            "36235: [discriminator loss: 0.560064, acc: 0.765625] [adversarial loss: 1.263266, acc: 0.125000]\n",
            "36236: [discriminator loss: 0.550237, acc: 0.710938] [adversarial loss: 1.088338, acc: 0.265625]\n",
            "36237: [discriminator loss: 0.583390, acc: 0.656250] [adversarial loss: 1.291273, acc: 0.296875]\n",
            "36238: [discriminator loss: 0.597759, acc: 0.710938] [adversarial loss: 0.865758, acc: 0.437500]\n",
            "36239: [discriminator loss: 0.612607, acc: 0.703125] [adversarial loss: 1.233141, acc: 0.156250]\n",
            "36240: [discriminator loss: 0.550314, acc: 0.734375] [adversarial loss: 0.898855, acc: 0.390625]\n",
            "36241: [discriminator loss: 0.578917, acc: 0.718750] [adversarial loss: 1.255469, acc: 0.234375]\n",
            "36242: [discriminator loss: 0.572706, acc: 0.695312] [adversarial loss: 0.812200, acc: 0.468750]\n",
            "36243: [discriminator loss: 0.667031, acc: 0.593750] [adversarial loss: 1.265835, acc: 0.218750]\n",
            "36244: [discriminator loss: 0.593261, acc: 0.664062] [adversarial loss: 0.980598, acc: 0.328125]\n",
            "36245: [discriminator loss: 0.544074, acc: 0.757812] [adversarial loss: 1.183102, acc: 0.234375]\n",
            "36246: [discriminator loss: 0.600637, acc: 0.625000] [adversarial loss: 0.980897, acc: 0.375000]\n",
            "36247: [discriminator loss: 0.663799, acc: 0.601562] [adversarial loss: 0.840902, acc: 0.437500]\n",
            "36248: [discriminator loss: 0.604126, acc: 0.695312] [adversarial loss: 1.368327, acc: 0.140625]\n",
            "36249: [discriminator loss: 0.605889, acc: 0.679688] [adversarial loss: 0.744397, acc: 0.562500]\n",
            "36250: [discriminator loss: 0.564662, acc: 0.750000] [adversarial loss: 1.226512, acc: 0.234375]\n",
            "36251: [discriminator loss: 0.579592, acc: 0.687500] [adversarial loss: 0.921751, acc: 0.343750]\n",
            "36252: [discriminator loss: 0.574309, acc: 0.687500] [adversarial loss: 1.052320, acc: 0.218750]\n",
            "36253: [discriminator loss: 0.641245, acc: 0.656250] [adversarial loss: 1.138826, acc: 0.296875]\n",
            "36254: [discriminator loss: 0.596356, acc: 0.664062] [adversarial loss: 0.751939, acc: 0.515625]\n",
            "36255: [discriminator loss: 0.627796, acc: 0.671875] [adversarial loss: 1.050828, acc: 0.265625]\n",
            "36256: [discriminator loss: 0.528663, acc: 0.710938] [adversarial loss: 0.972256, acc: 0.296875]\n",
            "36257: [discriminator loss: 0.641050, acc: 0.570312] [adversarial loss: 1.269020, acc: 0.171875]\n",
            "36258: [discriminator loss: 0.589273, acc: 0.687500] [adversarial loss: 0.872007, acc: 0.453125]\n",
            "36259: [discriminator loss: 0.615742, acc: 0.703125] [adversarial loss: 1.219327, acc: 0.359375]\n",
            "36260: [discriminator loss: 0.588195, acc: 0.679688] [adversarial loss: 0.880298, acc: 0.421875]\n",
            "36261: [discriminator loss: 0.533594, acc: 0.718750] [adversarial loss: 1.086409, acc: 0.203125]\n",
            "36262: [discriminator loss: 0.616059, acc: 0.664062] [adversarial loss: 1.038325, acc: 0.296875]\n",
            "36263: [discriminator loss: 0.594257, acc: 0.632812] [adversarial loss: 1.031123, acc: 0.265625]\n",
            "36264: [discriminator loss: 0.582547, acc: 0.656250] [adversarial loss: 0.932787, acc: 0.421875]\n",
            "36265: [discriminator loss: 0.576488, acc: 0.710938] [adversarial loss: 0.887302, acc: 0.453125]\n",
            "36266: [discriminator loss: 0.597125, acc: 0.656250] [adversarial loss: 1.374627, acc: 0.171875]\n",
            "36267: [discriminator loss: 0.581770, acc: 0.710938] [adversarial loss: 0.897273, acc: 0.406250]\n",
            "36268: [discriminator loss: 0.610767, acc: 0.632812] [adversarial loss: 1.284671, acc: 0.203125]\n",
            "36269: [discriminator loss: 0.586266, acc: 0.656250] [adversarial loss: 1.064047, acc: 0.343750]\n",
            "36270: [discriminator loss: 0.620093, acc: 0.664062] [adversarial loss: 1.042899, acc: 0.234375]\n",
            "36271: [discriminator loss: 0.635995, acc: 0.671875] [adversarial loss: 1.148330, acc: 0.265625]\n",
            "36272: [discriminator loss: 0.642117, acc: 0.585938] [adversarial loss: 0.782581, acc: 0.453125]\n",
            "36273: [discriminator loss: 0.553861, acc: 0.695312] [adversarial loss: 1.396427, acc: 0.140625]\n",
            "36274: [discriminator loss: 0.665960, acc: 0.601562] [adversarial loss: 0.747450, acc: 0.515625]\n",
            "36275: [discriminator loss: 0.546193, acc: 0.742188] [adversarial loss: 1.136472, acc: 0.281250]\n",
            "36276: [discriminator loss: 0.526305, acc: 0.687500] [adversarial loss: 0.915843, acc: 0.390625]\n",
            "36277: [discriminator loss: 0.691763, acc: 0.640625] [adversarial loss: 0.988416, acc: 0.312500]\n",
            "36278: [discriminator loss: 0.602512, acc: 0.656250] [adversarial loss: 1.037864, acc: 0.359375]\n",
            "36279: [discriminator loss: 0.596582, acc: 0.718750] [adversarial loss: 1.228106, acc: 0.187500]\n",
            "36280: [discriminator loss: 0.619950, acc: 0.671875] [adversarial loss: 0.868972, acc: 0.562500]\n",
            "36281: [discriminator loss: 0.590019, acc: 0.648438] [adversarial loss: 1.334183, acc: 0.140625]\n",
            "36282: [discriminator loss: 0.591030, acc: 0.671875] [adversarial loss: 1.237981, acc: 0.171875]\n",
            "36283: [discriminator loss: 0.606252, acc: 0.664062] [adversarial loss: 1.059838, acc: 0.406250]\n",
            "36284: [discriminator loss: 0.544235, acc: 0.687500] [adversarial loss: 0.980974, acc: 0.375000]\n",
            "36285: [discriminator loss: 0.607049, acc: 0.648438] [adversarial loss: 1.168664, acc: 0.265625]\n",
            "36286: [discriminator loss: 0.541223, acc: 0.773438] [adversarial loss: 0.828012, acc: 0.406250]\n",
            "36287: [discriminator loss: 0.615053, acc: 0.671875] [adversarial loss: 1.496925, acc: 0.140625]\n",
            "36288: [discriminator loss: 0.563095, acc: 0.718750] [adversarial loss: 0.895906, acc: 0.421875]\n",
            "36289: [discriminator loss: 0.603432, acc: 0.671875] [adversarial loss: 1.347468, acc: 0.125000]\n",
            "36290: [discriminator loss: 0.619762, acc: 0.664062] [adversarial loss: 1.025769, acc: 0.375000]\n",
            "36291: [discriminator loss: 0.492691, acc: 0.828125] [adversarial loss: 1.075867, acc: 0.312500]\n",
            "36292: [discriminator loss: 0.625131, acc: 0.640625] [adversarial loss: 1.144965, acc: 0.265625]\n",
            "36293: [discriminator loss: 0.586043, acc: 0.656250] [adversarial loss: 1.132680, acc: 0.296875]\n",
            "36294: [discriminator loss: 0.570192, acc: 0.664062] [adversarial loss: 0.815723, acc: 0.500000]\n",
            "36295: [discriminator loss: 0.569384, acc: 0.750000] [adversarial loss: 1.110920, acc: 0.265625]\n",
            "36296: [discriminator loss: 0.568758, acc: 0.695312] [adversarial loss: 1.208660, acc: 0.218750]\n",
            "36297: [discriminator loss: 0.632505, acc: 0.632812] [adversarial loss: 1.117714, acc: 0.343750]\n",
            "36298: [discriminator loss: 0.664217, acc: 0.656250] [adversarial loss: 1.001384, acc: 0.265625]\n",
            "36299: [discriminator loss: 0.620415, acc: 0.632812] [adversarial loss: 1.223660, acc: 0.203125]\n",
            "36300: [discriminator loss: 0.669947, acc: 0.625000] [adversarial loss: 0.873556, acc: 0.406250]\n",
            "36301: [discriminator loss: 0.593509, acc: 0.625000] [adversarial loss: 1.224545, acc: 0.156250]\n",
            "36302: [discriminator loss: 0.524511, acc: 0.726562] [adversarial loss: 0.824494, acc: 0.375000]\n",
            "36303: [discriminator loss: 0.658411, acc: 0.570312] [adversarial loss: 1.123545, acc: 0.328125]\n",
            "36304: [discriminator loss: 0.567037, acc: 0.695312] [adversarial loss: 0.918905, acc: 0.343750]\n",
            "36305: [discriminator loss: 0.573679, acc: 0.632812] [adversarial loss: 1.230508, acc: 0.140625]\n",
            "36306: [discriminator loss: 0.548776, acc: 0.750000] [adversarial loss: 0.835906, acc: 0.390625]\n",
            "36307: [discriminator loss: 0.569541, acc: 0.718750] [adversarial loss: 1.415197, acc: 0.093750]\n",
            "36308: [discriminator loss: 0.558433, acc: 0.734375] [adversarial loss: 1.103792, acc: 0.312500]\n",
            "36309: [discriminator loss: 0.577829, acc: 0.710938] [adversarial loss: 1.168803, acc: 0.296875]\n",
            "36310: [discriminator loss: 0.591867, acc: 0.664062] [adversarial loss: 1.047133, acc: 0.328125]\n",
            "36311: [discriminator loss: 0.604643, acc: 0.671875] [adversarial loss: 1.223374, acc: 0.218750]\n",
            "36312: [discriminator loss: 0.601886, acc: 0.617188] [adversarial loss: 0.982351, acc: 0.343750]\n",
            "36313: [discriminator loss: 0.533752, acc: 0.710938] [adversarial loss: 1.183451, acc: 0.218750]\n",
            "36314: [discriminator loss: 0.555911, acc: 0.695312] [adversarial loss: 0.957694, acc: 0.296875]\n",
            "36315: [discriminator loss: 0.545399, acc: 0.726562] [adversarial loss: 1.299354, acc: 0.296875]\n",
            "36316: [discriminator loss: 0.577397, acc: 0.679688] [adversarial loss: 0.857581, acc: 0.421875]\n",
            "36317: [discriminator loss: 0.593639, acc: 0.656250] [adversarial loss: 1.462832, acc: 0.093750]\n",
            "36318: [discriminator loss: 0.634981, acc: 0.632812] [adversarial loss: 0.833214, acc: 0.453125]\n",
            "36319: [discriminator loss: 0.619453, acc: 0.632812] [adversarial loss: 1.362584, acc: 0.156250]\n",
            "36320: [discriminator loss: 0.637493, acc: 0.687500] [adversarial loss: 0.941052, acc: 0.328125]\n",
            "36321: [discriminator loss: 0.625873, acc: 0.640625] [adversarial loss: 1.122927, acc: 0.250000]\n",
            "36322: [discriminator loss: 0.626981, acc: 0.632812] [adversarial loss: 0.940005, acc: 0.312500]\n",
            "36323: [discriminator loss: 0.580385, acc: 0.718750] [adversarial loss: 0.971601, acc: 0.281250]\n",
            "36324: [discriminator loss: 0.561699, acc: 0.679688] [adversarial loss: 1.057230, acc: 0.250000]\n",
            "36325: [discriminator loss: 0.614934, acc: 0.632812] [adversarial loss: 1.193452, acc: 0.265625]\n",
            "36326: [discriminator loss: 0.592951, acc: 0.671875] [adversarial loss: 1.092655, acc: 0.250000]\n",
            "36327: [discriminator loss: 0.586155, acc: 0.695312] [adversarial loss: 0.970865, acc: 0.390625]\n",
            "36328: [discriminator loss: 0.630159, acc: 0.609375] [adversarial loss: 0.971013, acc: 0.359375]\n",
            "36329: [discriminator loss: 0.539885, acc: 0.687500] [adversarial loss: 1.010126, acc: 0.343750]\n",
            "36330: [discriminator loss: 0.600479, acc: 0.656250] [adversarial loss: 1.170135, acc: 0.203125]\n",
            "36331: [discriminator loss: 0.531745, acc: 0.757812] [adversarial loss: 0.961392, acc: 0.390625]\n",
            "36332: [discriminator loss: 0.533242, acc: 0.734375] [adversarial loss: 1.077129, acc: 0.265625]\n",
            "36333: [discriminator loss: 0.589299, acc: 0.601562] [adversarial loss: 0.895678, acc: 0.375000]\n",
            "36334: [discriminator loss: 0.609765, acc: 0.664062] [adversarial loss: 1.064762, acc: 0.187500]\n",
            "36335: [discriminator loss: 0.628501, acc: 0.640625] [adversarial loss: 0.871558, acc: 0.359375]\n",
            "36336: [discriminator loss: 0.605990, acc: 0.648438] [adversarial loss: 1.172977, acc: 0.250000]\n",
            "36337: [discriminator loss: 0.538794, acc: 0.742188] [adversarial loss: 1.105536, acc: 0.281250]\n",
            "36338: [discriminator loss: 0.550040, acc: 0.718750] [adversarial loss: 1.048333, acc: 0.359375]\n",
            "36339: [discriminator loss: 0.558942, acc: 0.679688] [adversarial loss: 1.347483, acc: 0.156250]\n",
            "36340: [discriminator loss: 0.614883, acc: 0.648438] [adversarial loss: 0.986022, acc: 0.375000]\n",
            "36341: [discriminator loss: 0.609607, acc: 0.625000] [adversarial loss: 0.997585, acc: 0.312500]\n",
            "36342: [discriminator loss: 0.540988, acc: 0.687500] [adversarial loss: 1.046544, acc: 0.250000]\n",
            "36343: [discriminator loss: 0.584598, acc: 0.687500] [adversarial loss: 0.792879, acc: 0.515625]\n",
            "36344: [discriminator loss: 0.608292, acc: 0.656250] [adversarial loss: 1.498821, acc: 0.156250]\n",
            "36345: [discriminator loss: 0.617508, acc: 0.648438] [adversarial loss: 1.002153, acc: 0.312500]\n",
            "36346: [discriminator loss: 0.579408, acc: 0.703125] [adversarial loss: 1.170937, acc: 0.312500]\n",
            "36347: [discriminator loss: 0.644986, acc: 0.601562] [adversarial loss: 0.841141, acc: 0.406250]\n",
            "36348: [discriminator loss: 0.563714, acc: 0.718750] [adversarial loss: 1.111127, acc: 0.296875]\n",
            "36349: [discriminator loss: 0.612894, acc: 0.648438] [adversarial loss: 1.042559, acc: 0.312500]\n",
            "36350: [discriminator loss: 0.563156, acc: 0.687500] [adversarial loss: 1.118508, acc: 0.312500]\n",
            "36351: [discriminator loss: 0.600132, acc: 0.703125] [adversarial loss: 0.904257, acc: 0.468750]\n",
            "36352: [discriminator loss: 0.628731, acc: 0.664062] [adversarial loss: 1.015477, acc: 0.296875]\n",
            "36353: [discriminator loss: 0.572710, acc: 0.726562] [adversarial loss: 1.022196, acc: 0.296875]\n",
            "36354: [discriminator loss: 0.543550, acc: 0.718750] [adversarial loss: 1.071078, acc: 0.312500]\n",
            "36355: [discriminator loss: 0.538669, acc: 0.718750] [adversarial loss: 1.070016, acc: 0.296875]\n",
            "36356: [discriminator loss: 0.578087, acc: 0.671875] [adversarial loss: 1.138108, acc: 0.312500]\n",
            "36357: [discriminator loss: 0.588481, acc: 0.648438] [adversarial loss: 1.117497, acc: 0.281250]\n",
            "36358: [discriminator loss: 0.605102, acc: 0.656250] [adversarial loss: 1.081168, acc: 0.265625]\n",
            "36359: [discriminator loss: 0.549502, acc: 0.726562] [adversarial loss: 1.202428, acc: 0.265625]\n",
            "36360: [discriminator loss: 0.597283, acc: 0.656250] [adversarial loss: 0.775235, acc: 0.500000]\n",
            "36361: [discriminator loss: 0.540030, acc: 0.742188] [adversarial loss: 1.382845, acc: 0.078125]\n",
            "36362: [discriminator loss: 0.605187, acc: 0.617188] [adversarial loss: 0.754240, acc: 0.531250]\n",
            "36363: [discriminator loss: 0.622942, acc: 0.656250] [adversarial loss: 1.434152, acc: 0.109375]\n",
            "36364: [discriminator loss: 0.741439, acc: 0.554688] [adversarial loss: 0.668730, acc: 0.578125]\n",
            "36365: [discriminator loss: 0.545455, acc: 0.718750] [adversarial loss: 1.108804, acc: 0.250000]\n",
            "36366: [discriminator loss: 0.582044, acc: 0.687500] [adversarial loss: 1.084638, acc: 0.265625]\n",
            "36367: [discriminator loss: 0.593488, acc: 0.656250] [adversarial loss: 1.048154, acc: 0.312500]\n",
            "36368: [discriminator loss: 0.610035, acc: 0.695312] [adversarial loss: 1.106645, acc: 0.328125]\n",
            "36369: [discriminator loss: 0.529536, acc: 0.703125] [adversarial loss: 1.061204, acc: 0.296875]\n",
            "36370: [discriminator loss: 0.597314, acc: 0.703125] [adversarial loss: 1.325917, acc: 0.265625]\n",
            "36371: [discriminator loss: 0.688125, acc: 0.585938] [adversarial loss: 0.896321, acc: 0.468750]\n",
            "36372: [discriminator loss: 0.546244, acc: 0.703125] [adversarial loss: 1.199676, acc: 0.218750]\n",
            "36373: [discriminator loss: 0.558385, acc: 0.687500] [adversarial loss: 0.824522, acc: 0.515625]\n",
            "36374: [discriminator loss: 0.588001, acc: 0.703125] [adversarial loss: 1.130260, acc: 0.250000]\n",
            "36375: [discriminator loss: 0.598593, acc: 0.687500] [adversarial loss: 0.915305, acc: 0.453125]\n",
            "36376: [discriminator loss: 0.617764, acc: 0.632812] [adversarial loss: 1.199752, acc: 0.250000]\n",
            "36377: [discriminator loss: 0.575374, acc: 0.695312] [adversarial loss: 0.818773, acc: 0.515625]\n",
            "36378: [discriminator loss: 0.626276, acc: 0.593750] [adversarial loss: 1.201405, acc: 0.296875]\n",
            "36379: [discriminator loss: 0.596590, acc: 0.664062] [adversarial loss: 1.063037, acc: 0.359375]\n",
            "36380: [discriminator loss: 0.543720, acc: 0.703125] [adversarial loss: 1.250677, acc: 0.187500]\n",
            "36381: [discriminator loss: 0.606957, acc: 0.679688] [adversarial loss: 0.952864, acc: 0.375000]\n",
            "36382: [discriminator loss: 0.564397, acc: 0.687500] [adversarial loss: 1.256495, acc: 0.312500]\n",
            "36383: [discriminator loss: 0.591944, acc: 0.710938] [adversarial loss: 0.913790, acc: 0.437500]\n",
            "36384: [discriminator loss: 0.601933, acc: 0.648438] [adversarial loss: 1.230479, acc: 0.234375]\n",
            "36385: [discriminator loss: 0.616637, acc: 0.695312] [adversarial loss: 0.899704, acc: 0.406250]\n",
            "36386: [discriminator loss: 0.590377, acc: 0.671875] [adversarial loss: 1.000155, acc: 0.437500]\n",
            "36387: [discriminator loss: 0.559039, acc: 0.703125] [adversarial loss: 1.198826, acc: 0.250000]\n",
            "36388: [discriminator loss: 0.548151, acc: 0.718750] [adversarial loss: 1.138305, acc: 0.234375]\n",
            "36389: [discriminator loss: 0.566393, acc: 0.695312] [adversarial loss: 1.373550, acc: 0.109375]\n",
            "36390: [discriminator loss: 0.589083, acc: 0.679688] [adversarial loss: 0.925862, acc: 0.468750]\n",
            "36391: [discriminator loss: 0.582182, acc: 0.726562] [adversarial loss: 1.331058, acc: 0.218750]\n",
            "36392: [discriminator loss: 0.600896, acc: 0.648438] [adversarial loss: 0.871370, acc: 0.484375]\n",
            "36393: [discriminator loss: 0.587226, acc: 0.671875] [adversarial loss: 1.193053, acc: 0.203125]\n",
            "36394: [discriminator loss: 0.552976, acc: 0.750000] [adversarial loss: 0.820812, acc: 0.406250]\n",
            "36395: [discriminator loss: 0.568601, acc: 0.710938] [adversarial loss: 1.312080, acc: 0.171875]\n",
            "36396: [discriminator loss: 0.605773, acc: 0.671875] [adversarial loss: 0.951542, acc: 0.281250]\n",
            "36397: [discriminator loss: 0.511095, acc: 0.710938] [adversarial loss: 1.095680, acc: 0.296875]\n",
            "36398: [discriminator loss: 0.571925, acc: 0.671875] [adversarial loss: 0.955956, acc: 0.296875]\n",
            "36399: [discriminator loss: 0.571766, acc: 0.679688] [adversarial loss: 1.268385, acc: 0.140625]\n",
            "36400: [discriminator loss: 0.607743, acc: 0.671875] [adversarial loss: 0.924640, acc: 0.390625]\n",
            "36401: [discriminator loss: 0.566424, acc: 0.664062] [adversarial loss: 1.131188, acc: 0.234375]\n",
            "36402: [discriminator loss: 0.538608, acc: 0.718750] [adversarial loss: 1.066945, acc: 0.234375]\n",
            "36403: [discriminator loss: 0.557850, acc: 0.742188] [adversarial loss: 1.503576, acc: 0.109375]\n",
            "36404: [discriminator loss: 0.579525, acc: 0.664062] [adversarial loss: 0.799502, acc: 0.453125]\n",
            "36405: [discriminator loss: 0.637192, acc: 0.617188] [adversarial loss: 1.437654, acc: 0.109375]\n",
            "36406: [discriminator loss: 0.607536, acc: 0.703125] [adversarial loss: 0.780237, acc: 0.531250]\n",
            "36407: [discriminator loss: 0.559709, acc: 0.726562] [adversarial loss: 1.139329, acc: 0.171875]\n",
            "36408: [discriminator loss: 0.589364, acc: 0.718750] [adversarial loss: 1.061701, acc: 0.281250]\n",
            "36409: [discriminator loss: 0.597536, acc: 0.648438] [adversarial loss: 1.193956, acc: 0.250000]\n",
            "36410: [discriminator loss: 0.581648, acc: 0.679688] [adversarial loss: 0.914626, acc: 0.375000]\n",
            "36411: [discriminator loss: 0.604782, acc: 0.671875] [adversarial loss: 1.402586, acc: 0.140625]\n",
            "36412: [discriminator loss: 0.596548, acc: 0.687500] [adversarial loss: 0.939297, acc: 0.390625]\n",
            "36413: [discriminator loss: 0.605453, acc: 0.664062] [adversarial loss: 1.132068, acc: 0.296875]\n",
            "36414: [discriminator loss: 0.631457, acc: 0.632812] [adversarial loss: 0.916964, acc: 0.421875]\n",
            "36415: [discriminator loss: 0.541480, acc: 0.679688] [adversarial loss: 1.032363, acc: 0.312500]\n",
            "36416: [discriminator loss: 0.547333, acc: 0.695312] [adversarial loss: 0.902753, acc: 0.453125]\n",
            "36417: [discriminator loss: 0.627857, acc: 0.648438] [adversarial loss: 1.446487, acc: 0.156250]\n",
            "36418: [discriminator loss: 0.605492, acc: 0.664062] [adversarial loss: 0.904190, acc: 0.468750]\n",
            "36419: [discriminator loss: 0.531782, acc: 0.718750] [adversarial loss: 1.054600, acc: 0.359375]\n",
            "36420: [discriminator loss: 0.552535, acc: 0.703125] [adversarial loss: 1.156659, acc: 0.343750]\n",
            "36421: [discriminator loss: 0.518580, acc: 0.750000] [adversarial loss: 0.989885, acc: 0.406250]\n",
            "36422: [discriminator loss: 0.509231, acc: 0.804688] [adversarial loss: 1.182918, acc: 0.265625]\n",
            "36423: [discriminator loss: 0.581983, acc: 0.726562] [adversarial loss: 0.904741, acc: 0.421875]\n",
            "36424: [discriminator loss: 0.519316, acc: 0.726562] [adversarial loss: 1.245475, acc: 0.234375]\n",
            "36425: [discriminator loss: 0.566415, acc: 0.726562] [adversarial loss: 1.010604, acc: 0.312500]\n",
            "36426: [discriminator loss: 0.552392, acc: 0.718750] [adversarial loss: 1.100996, acc: 0.265625]\n",
            "36427: [discriminator loss: 0.539723, acc: 0.734375] [adversarial loss: 0.864694, acc: 0.437500]\n",
            "36428: [discriminator loss: 0.610211, acc: 0.687500] [adversarial loss: 1.285053, acc: 0.125000]\n",
            "36429: [discriminator loss: 0.600114, acc: 0.671875] [adversarial loss: 0.869302, acc: 0.468750]\n",
            "36430: [discriminator loss: 0.588418, acc: 0.648438] [adversarial loss: 1.118480, acc: 0.281250]\n",
            "36431: [discriminator loss: 0.582082, acc: 0.656250] [adversarial loss: 0.882911, acc: 0.437500]\n",
            "36432: [discriminator loss: 0.627182, acc: 0.632812] [adversarial loss: 1.270739, acc: 0.218750]\n",
            "36433: [discriminator loss: 0.603048, acc: 0.640625] [adversarial loss: 1.091698, acc: 0.328125]\n",
            "36434: [discriminator loss: 0.584879, acc: 0.687500] [adversarial loss: 0.971562, acc: 0.437500]\n",
            "36435: [discriminator loss: 0.518256, acc: 0.726562] [adversarial loss: 1.270842, acc: 0.250000]\n",
            "36436: [discriminator loss: 0.608067, acc: 0.710938] [adversarial loss: 1.017143, acc: 0.390625]\n",
            "36437: [discriminator loss: 0.538845, acc: 0.734375] [adversarial loss: 1.348867, acc: 0.156250]\n",
            "36438: [discriminator loss: 0.559399, acc: 0.703125] [adversarial loss: 1.004550, acc: 0.484375]\n",
            "36439: [discriminator loss: 0.652143, acc: 0.609375] [adversarial loss: 1.349746, acc: 0.265625]\n",
            "36440: [discriminator loss: 0.574344, acc: 0.640625] [adversarial loss: 0.963588, acc: 0.437500]\n",
            "36441: [discriminator loss: 0.583572, acc: 0.695312] [adversarial loss: 1.488570, acc: 0.187500]\n",
            "36442: [discriminator loss: 0.621911, acc: 0.648438] [adversarial loss: 0.876066, acc: 0.453125]\n",
            "36443: [discriminator loss: 0.577716, acc: 0.718750] [adversarial loss: 1.014341, acc: 0.437500]\n",
            "36444: [discriminator loss: 0.593209, acc: 0.687500] [adversarial loss: 0.952058, acc: 0.390625]\n",
            "36445: [discriminator loss: 0.598940, acc: 0.593750] [adversarial loss: 1.048286, acc: 0.328125]\n",
            "36446: [discriminator loss: 0.590086, acc: 0.695312] [adversarial loss: 1.133766, acc: 0.234375]\n",
            "36447: [discriminator loss: 0.571381, acc: 0.695312] [adversarial loss: 1.061748, acc: 0.343750]\n",
            "36448: [discriminator loss: 0.612111, acc: 0.664062] [adversarial loss: 1.122108, acc: 0.250000]\n",
            "36449: [discriminator loss: 0.584815, acc: 0.671875] [adversarial loss: 1.107961, acc: 0.265625]\n",
            "36450: [discriminator loss: 0.522985, acc: 0.718750] [adversarial loss: 1.029392, acc: 0.328125]\n",
            "36451: [discriminator loss: 0.650670, acc: 0.640625] [adversarial loss: 1.153309, acc: 0.328125]\n",
            "36452: [discriminator loss: 0.605736, acc: 0.656250] [adversarial loss: 0.934991, acc: 0.359375]\n",
            "36453: [discriminator loss: 0.578775, acc: 0.648438] [adversarial loss: 1.085399, acc: 0.328125]\n",
            "36454: [discriminator loss: 0.660417, acc: 0.648438] [adversarial loss: 0.840580, acc: 0.515625]\n",
            "36455: [discriminator loss: 0.613400, acc: 0.632812] [adversarial loss: 1.430684, acc: 0.093750]\n",
            "36456: [discriminator loss: 0.595434, acc: 0.687500] [adversarial loss: 0.946413, acc: 0.421875]\n",
            "36457: [discriminator loss: 0.596949, acc: 0.648438] [adversarial loss: 1.100779, acc: 0.265625]\n",
            "36458: [discriminator loss: 0.591459, acc: 0.664062] [adversarial loss: 1.006796, acc: 0.437500]\n",
            "36459: [discriminator loss: 0.561506, acc: 0.695312] [adversarial loss: 0.996188, acc: 0.343750]\n",
            "36460: [discriminator loss: 0.580855, acc: 0.679688] [adversarial loss: 1.054132, acc: 0.281250]\n",
            "36461: [discriminator loss: 0.525853, acc: 0.742188] [adversarial loss: 1.078079, acc: 0.265625]\n",
            "36462: [discriminator loss: 0.570806, acc: 0.742188] [adversarial loss: 0.870550, acc: 0.500000]\n",
            "36463: [discriminator loss: 0.615676, acc: 0.640625] [adversarial loss: 1.190744, acc: 0.218750]\n",
            "36464: [discriminator loss: 0.624654, acc: 0.679688] [adversarial loss: 0.862446, acc: 0.484375]\n",
            "36465: [discriminator loss: 0.598853, acc: 0.664062] [adversarial loss: 1.341446, acc: 0.109375]\n",
            "36466: [discriminator loss: 0.584547, acc: 0.703125] [adversarial loss: 0.845366, acc: 0.453125]\n",
            "36467: [discriminator loss: 0.619265, acc: 0.671875] [adversarial loss: 1.317715, acc: 0.171875]\n",
            "36468: [discriminator loss: 0.573256, acc: 0.703125] [adversarial loss: 0.833784, acc: 0.484375]\n",
            "36469: [discriminator loss: 0.555021, acc: 0.757812] [adversarial loss: 0.940377, acc: 0.406250]\n",
            "36470: [discriminator loss: 0.603870, acc: 0.617188] [adversarial loss: 1.345803, acc: 0.156250]\n",
            "36471: [discriminator loss: 0.552580, acc: 0.726562] [adversarial loss: 0.965111, acc: 0.343750]\n",
            "36472: [discriminator loss: 0.597336, acc: 0.656250] [adversarial loss: 1.342646, acc: 0.187500]\n",
            "36473: [discriminator loss: 0.649061, acc: 0.632812] [adversarial loss: 0.720227, acc: 0.515625]\n",
            "36474: [discriminator loss: 0.578677, acc: 0.695312] [adversarial loss: 1.050078, acc: 0.234375]\n",
            "36475: [discriminator loss: 0.606297, acc: 0.640625] [adversarial loss: 0.968081, acc: 0.375000]\n",
            "36476: [discriminator loss: 0.629724, acc: 0.640625] [adversarial loss: 1.171420, acc: 0.203125]\n",
            "36477: [discriminator loss: 0.591141, acc: 0.671875] [adversarial loss: 0.897320, acc: 0.406250]\n",
            "36478: [discriminator loss: 0.537671, acc: 0.734375] [adversarial loss: 1.229326, acc: 0.265625]\n",
            "36479: [discriminator loss: 0.582642, acc: 0.726562] [adversarial loss: 0.902931, acc: 0.375000]\n",
            "36480: [discriminator loss: 0.617015, acc: 0.671875] [adversarial loss: 1.197848, acc: 0.203125]\n",
            "36481: [discriminator loss: 0.544098, acc: 0.710938] [adversarial loss: 0.858635, acc: 0.437500]\n",
            "36482: [discriminator loss: 0.596749, acc: 0.710938] [adversarial loss: 1.538684, acc: 0.062500]\n",
            "36483: [discriminator loss: 0.617788, acc: 0.617188] [adversarial loss: 0.808258, acc: 0.484375]\n",
            "36484: [discriminator loss: 0.598692, acc: 0.703125] [adversarial loss: 1.227073, acc: 0.218750]\n",
            "36485: [discriminator loss: 0.597305, acc: 0.664062] [adversarial loss: 0.873272, acc: 0.468750]\n",
            "36486: [discriminator loss: 0.592903, acc: 0.710938] [adversarial loss: 1.120233, acc: 0.265625]\n",
            "36487: [discriminator loss: 0.589372, acc: 0.679688] [adversarial loss: 1.112602, acc: 0.250000]\n",
            "36488: [discriminator loss: 0.636110, acc: 0.632812] [adversarial loss: 1.148808, acc: 0.203125]\n",
            "36489: [discriminator loss: 0.573042, acc: 0.687500] [adversarial loss: 0.981245, acc: 0.375000]\n",
            "36490: [discriminator loss: 0.602537, acc: 0.703125] [adversarial loss: 1.093426, acc: 0.312500]\n",
            "36491: [discriminator loss: 0.631580, acc: 0.656250] [adversarial loss: 1.014018, acc: 0.359375]\n",
            "36492: [discriminator loss: 0.558061, acc: 0.695312] [adversarial loss: 1.187930, acc: 0.281250]\n",
            "36493: [discriminator loss: 0.599471, acc: 0.648438] [adversarial loss: 0.892236, acc: 0.453125]\n",
            "36494: [discriminator loss: 0.561548, acc: 0.687500] [adversarial loss: 1.199180, acc: 0.171875]\n",
            "36495: [discriminator loss: 0.650716, acc: 0.640625] [adversarial loss: 0.784927, acc: 0.531250]\n",
            "36496: [discriminator loss: 0.592624, acc: 0.679688] [adversarial loss: 1.146920, acc: 0.250000]\n",
            "36497: [discriminator loss: 0.646170, acc: 0.609375] [adversarial loss: 0.981616, acc: 0.375000]\n",
            "36498: [discriminator loss: 0.586690, acc: 0.687500] [adversarial loss: 1.021609, acc: 0.390625]\n",
            "36499: [discriminator loss: 0.600631, acc: 0.671875] [adversarial loss: 1.004114, acc: 0.390625]\n",
            "36500: [discriminator loss: 0.608018, acc: 0.664062] [adversarial loss: 1.049429, acc: 0.375000]\n",
            "36501: [discriminator loss: 0.558172, acc: 0.679688] [adversarial loss: 1.107494, acc: 0.296875]\n",
            "36502: [discriminator loss: 0.544384, acc: 0.695312] [adversarial loss: 1.001004, acc: 0.437500]\n",
            "36503: [discriminator loss: 0.539149, acc: 0.734375] [adversarial loss: 1.162490, acc: 0.312500]\n",
            "36504: [discriminator loss: 0.626495, acc: 0.640625] [adversarial loss: 1.255647, acc: 0.250000]\n",
            "36505: [discriminator loss: 0.588414, acc: 0.648438] [adversarial loss: 0.702618, acc: 0.593750]\n",
            "36506: [discriminator loss: 0.611227, acc: 0.664062] [adversarial loss: 1.302929, acc: 0.203125]\n",
            "36507: [discriminator loss: 0.619866, acc: 0.695312] [adversarial loss: 0.893119, acc: 0.390625]\n",
            "36508: [discriminator loss: 0.601250, acc: 0.648438] [adversarial loss: 1.235107, acc: 0.218750]\n",
            "36509: [discriminator loss: 0.560473, acc: 0.718750] [adversarial loss: 1.206186, acc: 0.218750]\n",
            "36510: [discriminator loss: 0.639734, acc: 0.640625] [adversarial loss: 0.991253, acc: 0.359375]\n",
            "36511: [discriminator loss: 0.621027, acc: 0.632812] [adversarial loss: 0.994152, acc: 0.265625]\n",
            "36512: [discriminator loss: 0.617240, acc: 0.687500] [adversarial loss: 1.217420, acc: 0.171875]\n",
            "36513: [discriminator loss: 0.606203, acc: 0.679688] [adversarial loss: 0.961105, acc: 0.390625]\n",
            "36514: [discriminator loss: 0.587152, acc: 0.640625] [adversarial loss: 1.043840, acc: 0.312500]\n",
            "36515: [discriminator loss: 0.540468, acc: 0.773438] [adversarial loss: 1.159574, acc: 0.281250]\n",
            "36516: [discriminator loss: 0.578819, acc: 0.664062] [adversarial loss: 0.737058, acc: 0.468750]\n",
            "36517: [discriminator loss: 0.613616, acc: 0.609375] [adversarial loss: 1.412968, acc: 0.171875]\n",
            "36518: [discriminator loss: 0.570108, acc: 0.664062] [adversarial loss: 0.839140, acc: 0.406250]\n",
            "36519: [discriminator loss: 0.581664, acc: 0.679688] [adversarial loss: 0.964728, acc: 0.375000]\n",
            "36520: [discriminator loss: 0.631067, acc: 0.648438] [adversarial loss: 1.055228, acc: 0.375000]\n",
            "36521: [discriminator loss: 0.662429, acc: 0.593750] [adversarial loss: 0.981222, acc: 0.328125]\n",
            "36522: [discriminator loss: 0.590488, acc: 0.687500] [adversarial loss: 1.258037, acc: 0.156250]\n",
            "36523: [discriminator loss: 0.543261, acc: 0.742188] [adversarial loss: 0.664731, acc: 0.687500]\n",
            "36524: [discriminator loss: 0.610180, acc: 0.656250] [adversarial loss: 1.414375, acc: 0.156250]\n",
            "36525: [discriminator loss: 0.607160, acc: 0.671875] [adversarial loss: 0.873777, acc: 0.453125]\n",
            "36526: [discriminator loss: 0.554901, acc: 0.679688] [adversarial loss: 1.011846, acc: 0.281250]\n",
            "36527: [discriminator loss: 0.527321, acc: 0.757812] [adversarial loss: 1.210594, acc: 0.187500]\n",
            "36528: [discriminator loss: 0.539871, acc: 0.742188] [adversarial loss: 0.936712, acc: 0.406250]\n",
            "36529: [discriminator loss: 0.554103, acc: 0.765625] [adversarial loss: 1.160999, acc: 0.296875]\n",
            "36530: [discriminator loss: 0.576436, acc: 0.679688] [adversarial loss: 0.849030, acc: 0.515625]\n",
            "36531: [discriminator loss: 0.689280, acc: 0.593750] [adversarial loss: 1.413921, acc: 0.062500]\n",
            "36532: [discriminator loss: 0.570970, acc: 0.710938] [adversarial loss: 0.927550, acc: 0.375000]\n",
            "36533: [discriminator loss: 0.601373, acc: 0.695312] [adversarial loss: 0.992709, acc: 0.296875]\n",
            "36534: [discriminator loss: 0.529894, acc: 0.742188] [adversarial loss: 1.226712, acc: 0.187500]\n",
            "36535: [discriminator loss: 0.556410, acc: 0.718750] [adversarial loss: 0.871006, acc: 0.390625]\n",
            "36536: [discriminator loss: 0.592182, acc: 0.687500] [adversarial loss: 1.165778, acc: 0.250000]\n",
            "36537: [discriminator loss: 0.514819, acc: 0.742188] [adversarial loss: 0.967257, acc: 0.328125]\n",
            "36538: [discriminator loss: 0.587400, acc: 0.664062] [adversarial loss: 1.175711, acc: 0.234375]\n",
            "36539: [discriminator loss: 0.538524, acc: 0.695312] [adversarial loss: 0.903073, acc: 0.343750]\n",
            "36540: [discriminator loss: 0.523910, acc: 0.710938] [adversarial loss: 1.212178, acc: 0.203125]\n",
            "36541: [discriminator loss: 0.614981, acc: 0.648438] [adversarial loss: 1.041986, acc: 0.375000]\n",
            "36542: [discriminator loss: 0.625963, acc: 0.671875] [adversarial loss: 1.109006, acc: 0.281250]\n",
            "36543: [discriminator loss: 0.536628, acc: 0.734375] [adversarial loss: 0.897946, acc: 0.390625]\n",
            "36544: [discriminator loss: 0.553167, acc: 0.703125] [adversarial loss: 1.355883, acc: 0.281250]\n",
            "36545: [discriminator loss: 0.579438, acc: 0.726562] [adversarial loss: 0.913863, acc: 0.421875]\n",
            "36546: [discriminator loss: 0.593268, acc: 0.656250] [adversarial loss: 1.535691, acc: 0.187500]\n",
            "36547: [discriminator loss: 0.619312, acc: 0.718750] [adversarial loss: 0.811871, acc: 0.484375]\n",
            "36548: [discriminator loss: 0.599346, acc: 0.640625] [adversarial loss: 1.175976, acc: 0.218750]\n",
            "36549: [discriminator loss: 0.580979, acc: 0.664062] [adversarial loss: 0.799989, acc: 0.484375]\n",
            "36550: [discriminator loss: 0.618416, acc: 0.664062] [adversarial loss: 1.296632, acc: 0.125000]\n",
            "36551: [discriminator loss: 0.605356, acc: 0.648438] [adversarial loss: 0.825584, acc: 0.531250]\n",
            "36552: [discriminator loss: 0.680985, acc: 0.632812] [adversarial loss: 1.158393, acc: 0.234375]\n",
            "36553: [discriminator loss: 0.587254, acc: 0.703125] [adversarial loss: 1.096244, acc: 0.296875]\n",
            "36554: [discriminator loss: 0.602172, acc: 0.687500] [adversarial loss: 1.064324, acc: 0.343750]\n",
            "36555: [discriminator loss: 0.622863, acc: 0.648438] [adversarial loss: 0.924521, acc: 0.406250]\n",
            "36556: [discriminator loss: 0.476314, acc: 0.820312] [adversarial loss: 1.285974, acc: 0.171875]\n",
            "36557: [discriminator loss: 0.552710, acc: 0.718750] [adversarial loss: 0.967391, acc: 0.328125]\n",
            "36558: [discriminator loss: 0.529341, acc: 0.742188] [adversarial loss: 1.128094, acc: 0.328125]\n",
            "36559: [discriminator loss: 0.625042, acc: 0.593750] [adversarial loss: 0.989504, acc: 0.359375]\n",
            "36560: [discriminator loss: 0.552352, acc: 0.742188] [adversarial loss: 1.413219, acc: 0.187500]\n",
            "36561: [discriminator loss: 0.569275, acc: 0.695312] [adversarial loss: 0.755281, acc: 0.546875]\n",
            "36562: [discriminator loss: 0.510558, acc: 0.781250] [adversarial loss: 1.405808, acc: 0.187500]\n",
            "36563: [discriminator loss: 0.546774, acc: 0.726562] [adversarial loss: 0.738315, acc: 0.484375]\n",
            "36564: [discriminator loss: 0.651430, acc: 0.632812] [adversarial loss: 1.450186, acc: 0.187500]\n",
            "36565: [discriminator loss: 0.614113, acc: 0.679688] [adversarial loss: 0.921892, acc: 0.406250]\n",
            "36566: [discriminator loss: 0.628391, acc: 0.656250] [adversarial loss: 1.145351, acc: 0.234375]\n",
            "36567: [discriminator loss: 0.581739, acc: 0.687500] [adversarial loss: 0.982992, acc: 0.375000]\n",
            "36568: [discriminator loss: 0.593506, acc: 0.671875] [adversarial loss: 1.255106, acc: 0.187500]\n",
            "36569: [discriminator loss: 0.610549, acc: 0.671875] [adversarial loss: 0.830562, acc: 0.375000]\n",
            "36570: [discriminator loss: 0.639227, acc: 0.656250] [adversarial loss: 1.331580, acc: 0.218750]\n",
            "36571: [discriminator loss: 0.549114, acc: 0.710938] [adversarial loss: 0.868865, acc: 0.421875]\n",
            "36572: [discriminator loss: 0.564329, acc: 0.695312] [adversarial loss: 1.128115, acc: 0.343750]\n",
            "36573: [discriminator loss: 0.599206, acc: 0.726562] [adversarial loss: 0.951047, acc: 0.421875]\n",
            "36574: [discriminator loss: 0.538130, acc: 0.718750] [adversarial loss: 1.094521, acc: 0.312500]\n",
            "36575: [discriminator loss: 0.616721, acc: 0.640625] [adversarial loss: 1.239183, acc: 0.281250]\n",
            "36576: [discriminator loss: 0.618050, acc: 0.640625] [adversarial loss: 0.927501, acc: 0.453125]\n",
            "36577: [discriminator loss: 0.587143, acc: 0.671875] [adversarial loss: 1.322318, acc: 0.187500]\n",
            "36578: [discriminator loss: 0.618073, acc: 0.640625] [adversarial loss: 0.900083, acc: 0.515625]\n",
            "36579: [discriminator loss: 0.582159, acc: 0.679688] [adversarial loss: 1.137117, acc: 0.281250]\n",
            "36580: [discriminator loss: 0.554892, acc: 0.710938] [adversarial loss: 1.019637, acc: 0.375000]\n",
            "36581: [discriminator loss: 0.559214, acc: 0.750000] [adversarial loss: 1.299639, acc: 0.203125]\n",
            "36582: [discriminator loss: 0.571647, acc: 0.664062] [adversarial loss: 1.145502, acc: 0.265625]\n",
            "36583: [discriminator loss: 0.502428, acc: 0.773438] [adversarial loss: 0.935302, acc: 0.406250]\n",
            "36584: [discriminator loss: 0.582557, acc: 0.687500] [adversarial loss: 1.057331, acc: 0.234375]\n",
            "36585: [discriminator loss: 0.584197, acc: 0.695312] [adversarial loss: 0.957698, acc: 0.312500]\n",
            "36586: [discriminator loss: 0.563625, acc: 0.687500] [adversarial loss: 1.226732, acc: 0.203125]\n",
            "36587: [discriminator loss: 0.534288, acc: 0.757812] [adversarial loss: 1.049705, acc: 0.406250]\n",
            "36588: [discriminator loss: 0.613025, acc: 0.625000] [adversarial loss: 1.349771, acc: 0.187500]\n",
            "36589: [discriminator loss: 0.579049, acc: 0.679688] [adversarial loss: 0.921809, acc: 0.500000]\n",
            "36590: [discriminator loss: 0.611235, acc: 0.687500] [adversarial loss: 1.234583, acc: 0.234375]\n",
            "36591: [discriminator loss: 0.671565, acc: 0.617188] [adversarial loss: 0.674522, acc: 0.656250]\n",
            "36592: [discriminator loss: 0.642306, acc: 0.656250] [adversarial loss: 1.165205, acc: 0.187500]\n",
            "36593: [discriminator loss: 0.584373, acc: 0.695312] [adversarial loss: 0.977812, acc: 0.437500]\n",
            "36594: [discriminator loss: 0.627030, acc: 0.687500] [adversarial loss: 1.341201, acc: 0.125000]\n",
            "36595: [discriminator loss: 0.569693, acc: 0.679688] [adversarial loss: 1.125251, acc: 0.265625]\n",
            "36596: [discriminator loss: 0.570567, acc: 0.648438] [adversarial loss: 1.077492, acc: 0.312500]\n",
            "36597: [discriminator loss: 0.550403, acc: 0.757812] [adversarial loss: 0.922794, acc: 0.406250]\n",
            "36598: [discriminator loss: 0.632157, acc: 0.679688] [adversarial loss: 1.324661, acc: 0.140625]\n",
            "36599: [discriminator loss: 0.556607, acc: 0.687500] [adversarial loss: 0.994481, acc: 0.218750]\n",
            "36600: [discriminator loss: 0.529800, acc: 0.750000] [adversarial loss: 1.032321, acc: 0.328125]\n",
            "36601: [discriminator loss: 0.581271, acc: 0.648438] [adversarial loss: 0.989105, acc: 0.343750]\n",
            "36602: [discriminator loss: 0.566297, acc: 0.742188] [adversarial loss: 1.099647, acc: 0.343750]\n",
            "36603: [discriminator loss: 0.605835, acc: 0.671875] [adversarial loss: 1.213681, acc: 0.203125]\n",
            "36604: [discriminator loss: 0.589353, acc: 0.671875] [adversarial loss: 0.978577, acc: 0.359375]\n",
            "36605: [discriminator loss: 0.604629, acc: 0.671875] [adversarial loss: 1.329438, acc: 0.171875]\n",
            "36606: [discriminator loss: 0.579578, acc: 0.726562] [adversarial loss: 0.969198, acc: 0.375000]\n",
            "36607: [discriminator loss: 0.627138, acc: 0.648438] [adversarial loss: 1.312652, acc: 0.109375]\n",
            "36608: [discriminator loss: 0.597901, acc: 0.617188] [adversarial loss: 0.940460, acc: 0.296875]\n",
            "36609: [discriminator loss: 0.567564, acc: 0.734375] [adversarial loss: 1.179028, acc: 0.203125]\n",
            "36610: [discriminator loss: 0.561900, acc: 0.710938] [adversarial loss: 0.906522, acc: 0.406250]\n",
            "36611: [discriminator loss: 0.650904, acc: 0.601562] [adversarial loss: 1.473899, acc: 0.109375]\n",
            "36612: [discriminator loss: 0.627175, acc: 0.648438] [adversarial loss: 0.961276, acc: 0.406250]\n",
            "36613: [discriminator loss: 0.613038, acc: 0.664062] [adversarial loss: 1.238008, acc: 0.109375]\n",
            "36614: [discriminator loss: 0.592620, acc: 0.664062] [adversarial loss: 0.878813, acc: 0.390625]\n",
            "36615: [discriminator loss: 0.579366, acc: 0.695312] [adversarial loss: 1.096876, acc: 0.250000]\n",
            "36616: [discriminator loss: 0.598005, acc: 0.648438] [adversarial loss: 1.085925, acc: 0.218750]\n",
            "36617: [discriminator loss: 0.482716, acc: 0.796875] [adversarial loss: 1.078792, acc: 0.250000]\n",
            "36618: [discriminator loss: 0.591467, acc: 0.664062] [adversarial loss: 0.902863, acc: 0.531250]\n",
            "36619: [discriminator loss: 0.551137, acc: 0.695312] [adversarial loss: 1.176803, acc: 0.140625]\n",
            "36620: [discriminator loss: 0.601369, acc: 0.648438] [adversarial loss: 0.912665, acc: 0.406250]\n",
            "36621: [discriminator loss: 0.636856, acc: 0.625000] [adversarial loss: 1.318925, acc: 0.156250]\n",
            "36622: [discriminator loss: 0.634436, acc: 0.609375] [adversarial loss: 0.787814, acc: 0.562500]\n",
            "36623: [discriminator loss: 0.580513, acc: 0.695312] [adversarial loss: 1.406941, acc: 0.093750]\n",
            "36624: [discriminator loss: 0.604668, acc: 0.656250] [adversarial loss: 0.845659, acc: 0.421875]\n",
            "36625: [discriminator loss: 0.614477, acc: 0.664062] [adversarial loss: 1.445657, acc: 0.109375]\n",
            "36626: [discriminator loss: 0.590880, acc: 0.648438] [adversarial loss: 1.105500, acc: 0.218750]\n",
            "36627: [discriminator loss: 0.555836, acc: 0.664062] [adversarial loss: 0.889952, acc: 0.437500]\n",
            "36628: [discriminator loss: 0.617592, acc: 0.718750] [adversarial loss: 1.185700, acc: 0.250000]\n",
            "36629: [discriminator loss: 0.643116, acc: 0.632812] [adversarial loss: 0.858054, acc: 0.421875]\n",
            "36630: [discriminator loss: 0.638228, acc: 0.632812] [adversarial loss: 1.212209, acc: 0.156250]\n",
            "36631: [discriminator loss: 0.557776, acc: 0.718750] [adversarial loss: 1.119510, acc: 0.250000]\n",
            "36632: [discriminator loss: 0.567306, acc: 0.703125] [adversarial loss: 0.969377, acc: 0.312500]\n",
            "36633: [discriminator loss: 0.546294, acc: 0.765625] [adversarial loss: 1.081624, acc: 0.312500]\n",
            "36634: [discriminator loss: 0.585082, acc: 0.687500] [adversarial loss: 1.135034, acc: 0.265625]\n",
            "36635: [discriminator loss: 0.591649, acc: 0.671875] [adversarial loss: 0.704600, acc: 0.625000]\n",
            "36636: [discriminator loss: 0.616153, acc: 0.648438] [adversarial loss: 1.649209, acc: 0.140625]\n",
            "36637: [discriminator loss: 0.637518, acc: 0.640625] [adversarial loss: 0.793892, acc: 0.484375]\n",
            "36638: [discriminator loss: 0.669057, acc: 0.617188] [adversarial loss: 1.320293, acc: 0.234375]\n",
            "36639: [discriminator loss: 0.551642, acc: 0.750000] [adversarial loss: 1.067657, acc: 0.312500]\n",
            "36640: [discriminator loss: 0.595820, acc: 0.640625] [adversarial loss: 1.325137, acc: 0.171875]\n",
            "36641: [discriminator loss: 0.568174, acc: 0.664062] [adversarial loss: 1.007413, acc: 0.234375]\n",
            "36642: [discriminator loss: 0.588609, acc: 0.664062] [adversarial loss: 0.974262, acc: 0.421875]\n",
            "36643: [discriminator loss: 0.541137, acc: 0.695312] [adversarial loss: 1.065020, acc: 0.265625]\n",
            "36644: [discriminator loss: 0.533439, acc: 0.750000] [adversarial loss: 0.928184, acc: 0.390625]\n",
            "36645: [discriminator loss: 0.623421, acc: 0.664062] [adversarial loss: 1.175725, acc: 0.187500]\n",
            "36646: [discriminator loss: 0.590096, acc: 0.671875] [adversarial loss: 0.893173, acc: 0.390625]\n",
            "36647: [discriminator loss: 0.551973, acc: 0.703125] [adversarial loss: 1.088858, acc: 0.281250]\n",
            "36648: [discriminator loss: 0.585696, acc: 0.664062] [adversarial loss: 1.016277, acc: 0.296875]\n",
            "36649: [discriminator loss: 0.547237, acc: 0.765625] [adversarial loss: 0.986956, acc: 0.312500]\n",
            "36650: [discriminator loss: 0.617519, acc: 0.679688] [adversarial loss: 1.036983, acc: 0.406250]\n",
            "36651: [discriminator loss: 0.568319, acc: 0.679688] [adversarial loss: 1.069636, acc: 0.343750]\n",
            "36652: [discriminator loss: 0.570417, acc: 0.695312] [adversarial loss: 0.875814, acc: 0.437500]\n",
            "36653: [discriminator loss: 0.546776, acc: 0.710938] [adversarial loss: 1.242216, acc: 0.187500]\n",
            "36654: [discriminator loss: 0.656474, acc: 0.625000] [adversarial loss: 0.879180, acc: 0.390625]\n",
            "36655: [discriminator loss: 0.559788, acc: 0.718750] [adversarial loss: 1.081579, acc: 0.234375]\n",
            "36656: [discriminator loss: 0.519462, acc: 0.773438] [adversarial loss: 0.895299, acc: 0.437500]\n",
            "36657: [discriminator loss: 0.603694, acc: 0.687500] [adversarial loss: 1.294945, acc: 0.140625]\n",
            "36658: [discriminator loss: 0.595226, acc: 0.679688] [adversarial loss: 0.830410, acc: 0.437500]\n",
            "36659: [discriminator loss: 0.593392, acc: 0.695312] [adversarial loss: 1.050442, acc: 0.359375]\n",
            "36660: [discriminator loss: 0.519556, acc: 0.718750] [adversarial loss: 0.955230, acc: 0.390625]\n",
            "36661: [discriminator loss: 0.606790, acc: 0.617188] [adversarial loss: 1.158553, acc: 0.281250]\n",
            "36662: [discriminator loss: 0.664545, acc: 0.625000] [adversarial loss: 0.825895, acc: 0.406250]\n",
            "36663: [discriminator loss: 0.541042, acc: 0.742188] [adversarial loss: 1.073331, acc: 0.312500]\n",
            "36664: [discriminator loss: 0.572648, acc: 0.703125] [adversarial loss: 1.004067, acc: 0.328125]\n",
            "36665: [discriminator loss: 0.537348, acc: 0.757812] [adversarial loss: 0.875914, acc: 0.390625]\n",
            "36666: [discriminator loss: 0.572397, acc: 0.703125] [adversarial loss: 1.185701, acc: 0.250000]\n",
            "36667: [discriminator loss: 0.603791, acc: 0.710938] [adversarial loss: 0.831762, acc: 0.437500]\n",
            "36668: [discriminator loss: 0.600246, acc: 0.648438] [adversarial loss: 1.149799, acc: 0.281250]\n",
            "36669: [discriminator loss: 0.638208, acc: 0.632812] [adversarial loss: 0.886301, acc: 0.406250]\n",
            "36670: [discriminator loss: 0.575246, acc: 0.695312] [adversarial loss: 1.264282, acc: 0.125000]\n",
            "36671: [discriminator loss: 0.644874, acc: 0.609375] [adversarial loss: 0.838305, acc: 0.468750]\n",
            "36672: [discriminator loss: 0.654673, acc: 0.632812] [adversarial loss: 1.195205, acc: 0.218750]\n",
            "36673: [discriminator loss: 0.600102, acc: 0.671875] [adversarial loss: 0.736863, acc: 0.578125]\n",
            "36674: [discriminator loss: 0.618169, acc: 0.679688] [adversarial loss: 1.303319, acc: 0.218750]\n",
            "36675: [discriminator loss: 0.622235, acc: 0.632812] [adversarial loss: 0.821190, acc: 0.468750]\n",
            "36676: [discriminator loss: 0.667023, acc: 0.593750] [adversarial loss: 1.204795, acc: 0.234375]\n",
            "36677: [discriminator loss: 0.575140, acc: 0.671875] [adversarial loss: 1.130535, acc: 0.265625]\n",
            "36678: [discriminator loss: 0.560256, acc: 0.687500] [adversarial loss: 1.052971, acc: 0.312500]\n",
            "36679: [discriminator loss: 0.690144, acc: 0.570312] [adversarial loss: 1.143185, acc: 0.234375]\n",
            "36680: [discriminator loss: 0.614225, acc: 0.671875] [adversarial loss: 0.887975, acc: 0.453125]\n",
            "36681: [discriminator loss: 0.567674, acc: 0.687500] [adversarial loss: 1.109902, acc: 0.218750]\n",
            "36682: [discriminator loss: 0.519118, acc: 0.750000] [adversarial loss: 1.191476, acc: 0.281250]\n",
            "36683: [discriminator loss: 0.623911, acc: 0.687500] [adversarial loss: 0.881156, acc: 0.437500]\n",
            "36684: [discriminator loss: 0.606255, acc: 0.656250] [adversarial loss: 1.255682, acc: 0.281250]\n",
            "36685: [discriminator loss: 0.616302, acc: 0.648438] [adversarial loss: 0.943841, acc: 0.359375]\n",
            "36686: [discriminator loss: 0.614678, acc: 0.679688] [adversarial loss: 0.995246, acc: 0.375000]\n",
            "36687: [discriminator loss: 0.558802, acc: 0.664062] [adversarial loss: 0.956298, acc: 0.296875]\n",
            "36688: [discriminator loss: 0.600285, acc: 0.664062] [adversarial loss: 1.150897, acc: 0.234375]\n",
            "36689: [discriminator loss: 0.563632, acc: 0.710938] [adversarial loss: 1.071574, acc: 0.281250]\n",
            "36690: [discriminator loss: 0.613566, acc: 0.687500] [adversarial loss: 0.926640, acc: 0.390625]\n",
            "36691: [discriminator loss: 0.545783, acc: 0.710938] [adversarial loss: 1.175093, acc: 0.171875]\n",
            "36692: [discriminator loss: 0.587164, acc: 0.695312] [adversarial loss: 1.164205, acc: 0.203125]\n",
            "36693: [discriminator loss: 0.555797, acc: 0.742188] [adversarial loss: 0.884896, acc: 0.343750]\n",
            "36694: [discriminator loss: 0.562575, acc: 0.687500] [adversarial loss: 1.296671, acc: 0.140625]\n",
            "36695: [discriminator loss: 0.575046, acc: 0.718750] [adversarial loss: 0.960661, acc: 0.312500]\n",
            "36696: [discriminator loss: 0.549539, acc: 0.734375] [adversarial loss: 1.068672, acc: 0.265625]\n",
            "36697: [discriminator loss: 0.555531, acc: 0.695312] [adversarial loss: 1.060569, acc: 0.312500]\n",
            "36698: [discriminator loss: 0.583658, acc: 0.718750] [adversarial loss: 1.379271, acc: 0.156250]\n",
            "36699: [discriminator loss: 0.570384, acc: 0.718750] [adversarial loss: 0.785700, acc: 0.468750]\n",
            "36700: [discriminator loss: 0.540385, acc: 0.695312] [adversarial loss: 1.101140, acc: 0.218750]\n",
            "36701: [discriminator loss: 0.577656, acc: 0.648438] [adversarial loss: 0.838187, acc: 0.515625]\n",
            "36702: [discriminator loss: 0.604819, acc: 0.656250] [adversarial loss: 1.365458, acc: 0.156250]\n",
            "36703: [discriminator loss: 0.639606, acc: 0.617188] [adversarial loss: 0.923644, acc: 0.406250]\n",
            "36704: [discriminator loss: 0.622447, acc: 0.632812] [adversarial loss: 1.039196, acc: 0.343750]\n",
            "36705: [discriminator loss: 0.514020, acc: 0.773438] [adversarial loss: 0.912242, acc: 0.390625]\n",
            "36706: [discriminator loss: 0.523144, acc: 0.781250] [adversarial loss: 1.171697, acc: 0.312500]\n",
            "36707: [discriminator loss: 0.567516, acc: 0.679688] [adversarial loss: 0.978706, acc: 0.359375]\n",
            "36708: [discriminator loss: 0.576278, acc: 0.703125] [adversarial loss: 1.095323, acc: 0.234375]\n",
            "36709: [discriminator loss: 0.538357, acc: 0.710938] [adversarial loss: 0.916725, acc: 0.328125]\n",
            "36710: [discriminator loss: 0.577090, acc: 0.679688] [adversarial loss: 1.272969, acc: 0.140625]\n",
            "36711: [discriminator loss: 0.562621, acc: 0.679688] [adversarial loss: 0.887051, acc: 0.453125]\n",
            "36712: [discriminator loss: 0.619231, acc: 0.656250] [adversarial loss: 1.267638, acc: 0.218750]\n",
            "36713: [discriminator loss: 0.558174, acc: 0.710938] [adversarial loss: 1.053173, acc: 0.359375]\n",
            "36714: [discriminator loss: 0.584702, acc: 0.617188] [adversarial loss: 1.043810, acc: 0.265625]\n",
            "36715: [discriminator loss: 0.585238, acc: 0.695312] [adversarial loss: 0.881453, acc: 0.421875]\n",
            "36716: [discriminator loss: 0.658992, acc: 0.648438] [adversarial loss: 1.322442, acc: 0.125000]\n",
            "36717: [discriminator loss: 0.660676, acc: 0.609375] [adversarial loss: 0.881775, acc: 0.406250]\n",
            "36718: [discriminator loss: 0.579854, acc: 0.726562] [adversarial loss: 1.395453, acc: 0.140625]\n",
            "36719: [discriminator loss: 0.609256, acc: 0.632812] [adversarial loss: 0.863449, acc: 0.453125]\n",
            "36720: [discriminator loss: 0.623350, acc: 0.609375] [adversarial loss: 1.224361, acc: 0.187500]\n",
            "36721: [discriminator loss: 0.607480, acc: 0.664062] [adversarial loss: 0.900594, acc: 0.390625]\n",
            "36722: [discriminator loss: 0.581457, acc: 0.710938] [adversarial loss: 1.210055, acc: 0.187500]\n",
            "36723: [discriminator loss: 0.591652, acc: 0.687500] [adversarial loss: 0.815465, acc: 0.531250]\n",
            "36724: [discriminator loss: 0.587237, acc: 0.710938] [adversarial loss: 1.185671, acc: 0.203125]\n",
            "36725: [discriminator loss: 0.583549, acc: 0.656250] [adversarial loss: 0.731487, acc: 0.562500]\n",
            "36726: [discriminator loss: 0.643681, acc: 0.609375] [adversarial loss: 1.192749, acc: 0.187500]\n",
            "36727: [discriminator loss: 0.565229, acc: 0.640625] [adversarial loss: 0.812873, acc: 0.531250]\n",
            "36728: [discriminator loss: 0.549324, acc: 0.734375] [adversarial loss: 0.972747, acc: 0.406250]\n",
            "36729: [discriminator loss: 0.549568, acc: 0.718750] [adversarial loss: 0.964103, acc: 0.296875]\n",
            "36730: [discriminator loss: 0.513563, acc: 0.789062] [adversarial loss: 1.024321, acc: 0.375000]\n",
            "36731: [discriminator loss: 0.563967, acc: 0.632812] [adversarial loss: 0.931925, acc: 0.453125]\n",
            "36732: [discriminator loss: 0.636922, acc: 0.671875] [adversarial loss: 1.171572, acc: 0.234375]\n",
            "36733: [discriminator loss: 0.622446, acc: 0.625000] [adversarial loss: 0.828508, acc: 0.484375]\n",
            "36734: [discriminator loss: 0.645476, acc: 0.648438] [adversarial loss: 1.358111, acc: 0.109375]\n",
            "36735: [discriminator loss: 0.571483, acc: 0.687500] [adversarial loss: 0.854235, acc: 0.500000]\n",
            "36736: [discriminator loss: 0.643274, acc: 0.671875] [adversarial loss: 1.242239, acc: 0.187500]\n",
            "36737: [discriminator loss: 0.578610, acc: 0.640625] [adversarial loss: 0.988609, acc: 0.296875]\n",
            "36738: [discriminator loss: 0.627136, acc: 0.703125] [adversarial loss: 1.005019, acc: 0.343750]\n",
            "36739: [discriminator loss: 0.579858, acc: 0.648438] [adversarial loss: 0.993883, acc: 0.328125]\n",
            "36740: [discriminator loss: 0.673054, acc: 0.617188] [adversarial loss: 0.939890, acc: 0.421875]\n",
            "36741: [discriminator loss: 0.573011, acc: 0.734375] [adversarial loss: 1.241120, acc: 0.171875]\n",
            "36742: [discriminator loss: 0.616358, acc: 0.648438] [adversarial loss: 0.964321, acc: 0.390625]\n",
            "36743: [discriminator loss: 0.580345, acc: 0.703125] [adversarial loss: 1.249749, acc: 0.109375]\n",
            "36744: [discriminator loss: 0.582025, acc: 0.671875] [adversarial loss: 0.879135, acc: 0.437500]\n",
            "36745: [discriminator loss: 0.548667, acc: 0.726562] [adversarial loss: 1.131991, acc: 0.187500]\n",
            "36746: [discriminator loss: 0.588840, acc: 0.671875] [adversarial loss: 0.977636, acc: 0.390625]\n",
            "36747: [discriminator loss: 0.589567, acc: 0.671875] [adversarial loss: 1.115205, acc: 0.218750]\n",
            "36748: [discriminator loss: 0.572321, acc: 0.671875] [adversarial loss: 0.892401, acc: 0.359375]\n",
            "36749: [discriminator loss: 0.613931, acc: 0.617188] [adversarial loss: 1.276712, acc: 0.171875]\n",
            "36750: [discriminator loss: 0.595508, acc: 0.656250] [adversarial loss: 0.881986, acc: 0.453125]\n",
            "36751: [discriminator loss: 0.561031, acc: 0.710938] [adversarial loss: 1.167504, acc: 0.187500]\n",
            "36752: [discriminator loss: 0.624071, acc: 0.617188] [adversarial loss: 1.200768, acc: 0.250000]\n",
            "36753: [discriminator loss: 0.539538, acc: 0.750000] [adversarial loss: 1.006134, acc: 0.375000]\n",
            "36754: [discriminator loss: 0.546938, acc: 0.757812] [adversarial loss: 0.881727, acc: 0.484375]\n",
            "36755: [discriminator loss: 0.569319, acc: 0.656250] [adversarial loss: 1.077277, acc: 0.250000]\n",
            "36756: [discriminator loss: 0.527379, acc: 0.742188] [adversarial loss: 0.945310, acc: 0.312500]\n",
            "36757: [discriminator loss: 0.662663, acc: 0.640625] [adversarial loss: 1.168068, acc: 0.140625]\n",
            "36758: [discriminator loss: 0.598981, acc: 0.710938] [adversarial loss: 0.877206, acc: 0.421875]\n",
            "36759: [discriminator loss: 0.605665, acc: 0.687500] [adversarial loss: 1.260399, acc: 0.187500]\n",
            "36760: [discriminator loss: 0.589195, acc: 0.640625] [adversarial loss: 0.688433, acc: 0.578125]\n",
            "36761: [discriminator loss: 0.569841, acc: 0.695312] [adversarial loss: 1.158083, acc: 0.171875]\n",
            "36762: [discriminator loss: 0.629832, acc: 0.671875] [adversarial loss: 1.083591, acc: 0.312500]\n",
            "36763: [discriminator loss: 0.574130, acc: 0.710938] [adversarial loss: 0.977472, acc: 0.343750]\n",
            "36764: [discriminator loss: 0.564799, acc: 0.679688] [adversarial loss: 1.216798, acc: 0.171875]\n",
            "36765: [discriminator loss: 0.549805, acc: 0.750000] [adversarial loss: 0.947360, acc: 0.421875]\n",
            "36766: [discriminator loss: 0.558367, acc: 0.687500] [adversarial loss: 1.275626, acc: 0.187500]\n",
            "36767: [discriminator loss: 0.656877, acc: 0.664062] [adversarial loss: 0.865027, acc: 0.453125]\n",
            "36768: [discriminator loss: 0.606284, acc: 0.671875] [adversarial loss: 1.159159, acc: 0.203125]\n",
            "36769: [discriminator loss: 0.566356, acc: 0.703125] [adversarial loss: 1.018183, acc: 0.312500]\n",
            "36770: [discriminator loss: 0.552816, acc: 0.703125] [adversarial loss: 1.080511, acc: 0.218750]\n",
            "36771: [discriminator loss: 0.547500, acc: 0.695312] [adversarial loss: 1.368367, acc: 0.203125]\n",
            "36772: [discriminator loss: 0.601688, acc: 0.625000] [adversarial loss: 1.053171, acc: 0.343750]\n",
            "36773: [discriminator loss: 0.603376, acc: 0.656250] [adversarial loss: 0.949349, acc: 0.343750]\n",
            "36774: [discriminator loss: 0.576384, acc: 0.710938] [adversarial loss: 1.090346, acc: 0.281250]\n",
            "36775: [discriminator loss: 0.577074, acc: 0.695312] [adversarial loss: 0.967365, acc: 0.343750]\n",
            "36776: [discriminator loss: 0.567904, acc: 0.710938] [adversarial loss: 1.242468, acc: 0.234375]\n",
            "36777: [discriminator loss: 0.566037, acc: 0.703125] [adversarial loss: 1.051791, acc: 0.328125]\n",
            "36778: [discriminator loss: 0.581005, acc: 0.671875] [adversarial loss: 0.753957, acc: 0.468750]\n",
            "36779: [discriminator loss: 0.584156, acc: 0.656250] [adversarial loss: 1.256946, acc: 0.218750]\n",
            "36780: [discriminator loss: 0.551036, acc: 0.695312] [adversarial loss: 0.961140, acc: 0.375000]\n",
            "36781: [discriminator loss: 0.597605, acc: 0.695312] [adversarial loss: 1.120200, acc: 0.296875]\n",
            "36782: [discriminator loss: 0.584675, acc: 0.687500] [adversarial loss: 1.110929, acc: 0.265625]\n",
            "36783: [discriminator loss: 0.573794, acc: 0.679688] [adversarial loss: 0.933692, acc: 0.296875]\n",
            "36784: [discriminator loss: 0.597732, acc: 0.656250] [adversarial loss: 0.831652, acc: 0.515625]\n",
            "36785: [discriminator loss: 0.657351, acc: 0.578125] [adversarial loss: 1.240341, acc: 0.203125]\n",
            "36786: [discriminator loss: 0.671320, acc: 0.578125] [adversarial loss: 0.758698, acc: 0.546875]\n",
            "36787: [discriminator loss: 0.544019, acc: 0.710938] [adversarial loss: 1.051075, acc: 0.296875]\n",
            "36788: [discriminator loss: 0.629353, acc: 0.632812] [adversarial loss: 1.002247, acc: 0.359375]\n",
            "36789: [discriminator loss: 0.592071, acc: 0.648438] [adversarial loss: 1.036684, acc: 0.296875]\n",
            "36790: [discriminator loss: 0.579197, acc: 0.671875] [adversarial loss: 1.101290, acc: 0.312500]\n",
            "36791: [discriminator loss: 0.574181, acc: 0.687500] [adversarial loss: 1.011944, acc: 0.328125]\n",
            "36792: [discriminator loss: 0.567367, acc: 0.757812] [adversarial loss: 1.303466, acc: 0.187500]\n",
            "36793: [discriminator loss: 0.551023, acc: 0.726562] [adversarial loss: 1.026709, acc: 0.296875]\n",
            "36794: [discriminator loss: 0.562279, acc: 0.664062] [adversarial loss: 1.129903, acc: 0.218750]\n",
            "36795: [discriminator loss: 0.566994, acc: 0.703125] [adversarial loss: 0.992303, acc: 0.328125]\n",
            "36796: [discriminator loss: 0.599727, acc: 0.609375] [adversarial loss: 1.061238, acc: 0.296875]\n",
            "36797: [discriminator loss: 0.540480, acc: 0.742188] [adversarial loss: 0.792828, acc: 0.578125]\n",
            "36798: [discriminator loss: 0.694997, acc: 0.617188] [adversarial loss: 1.342939, acc: 0.125000]\n",
            "36799: [discriminator loss: 0.702188, acc: 0.562500] [adversarial loss: 0.734643, acc: 0.578125]\n",
            "36800: [discriminator loss: 0.597624, acc: 0.648438] [adversarial loss: 1.107693, acc: 0.265625]\n",
            "36801: [discriminator loss: 0.555682, acc: 0.742188] [adversarial loss: 0.998070, acc: 0.250000]\n",
            "36802: [discriminator loss: 0.602776, acc: 0.656250] [adversarial loss: 1.001937, acc: 0.296875]\n",
            "36803: [discriminator loss: 0.557502, acc: 0.718750] [adversarial loss: 1.057370, acc: 0.187500]\n",
            "36804: [discriminator loss: 0.551811, acc: 0.750000] [adversarial loss: 1.093971, acc: 0.218750]\n",
            "36805: [discriminator loss: 0.546096, acc: 0.773438] [adversarial loss: 0.897645, acc: 0.359375]\n",
            "36806: [discriminator loss: 0.554743, acc: 0.703125] [adversarial loss: 1.022680, acc: 0.343750]\n",
            "36807: [discriminator loss: 0.550764, acc: 0.734375] [adversarial loss: 1.156647, acc: 0.265625]\n",
            "36808: [discriminator loss: 0.589066, acc: 0.671875] [adversarial loss: 1.149507, acc: 0.171875]\n",
            "36809: [discriminator loss: 0.660599, acc: 0.601562] [adversarial loss: 0.918212, acc: 0.343750]\n",
            "36810: [discriminator loss: 0.590846, acc: 0.710938] [adversarial loss: 1.187863, acc: 0.156250]\n",
            "36811: [discriminator loss: 0.571165, acc: 0.695312] [adversarial loss: 0.904455, acc: 0.421875]\n",
            "36812: [discriminator loss: 0.646215, acc: 0.625000] [adversarial loss: 1.283216, acc: 0.203125]\n",
            "36813: [discriminator loss: 0.621984, acc: 0.671875] [adversarial loss: 0.904330, acc: 0.296875]\n",
            "36814: [discriminator loss: 0.619232, acc: 0.617188] [adversarial loss: 1.231337, acc: 0.171875]\n",
            "36815: [discriminator loss: 0.616361, acc: 0.656250] [adversarial loss: 0.986117, acc: 0.390625]\n",
            "36816: [discriminator loss: 0.558145, acc: 0.703125] [adversarial loss: 1.148036, acc: 0.187500]\n",
            "36817: [discriminator loss: 0.577057, acc: 0.671875] [adversarial loss: 1.035738, acc: 0.281250]\n",
            "36818: [discriminator loss: 0.580190, acc: 0.656250] [adversarial loss: 0.892588, acc: 0.421875]\n",
            "36819: [discriminator loss: 0.568746, acc: 0.648438] [adversarial loss: 1.280362, acc: 0.125000]\n",
            "36820: [discriminator loss: 0.596153, acc: 0.664062] [adversarial loss: 1.048809, acc: 0.343750]\n",
            "36821: [discriminator loss: 0.573328, acc: 0.664062] [adversarial loss: 1.108297, acc: 0.296875]\n",
            "36822: [discriminator loss: 0.642171, acc: 0.648438] [adversarial loss: 1.057977, acc: 0.234375]\n",
            "36823: [discriminator loss: 0.561500, acc: 0.687500] [adversarial loss: 1.309505, acc: 0.234375]\n",
            "36824: [discriminator loss: 0.622701, acc: 0.703125] [adversarial loss: 1.073567, acc: 0.281250]\n",
            "36825: [discriminator loss: 0.645668, acc: 0.601562] [adversarial loss: 1.303777, acc: 0.156250]\n",
            "36826: [discriminator loss: 0.653465, acc: 0.625000] [adversarial loss: 0.930306, acc: 0.390625]\n",
            "36827: [discriminator loss: 0.580337, acc: 0.695312] [adversarial loss: 1.638248, acc: 0.093750]\n",
            "36828: [discriminator loss: 0.667146, acc: 0.632812] [adversarial loss: 0.772524, acc: 0.546875]\n",
            "36829: [discriminator loss: 0.660056, acc: 0.570312] [adversarial loss: 1.295651, acc: 0.125000]\n",
            "36830: [discriminator loss: 0.524611, acc: 0.734375] [adversarial loss: 0.838872, acc: 0.468750]\n",
            "36831: [discriminator loss: 0.537446, acc: 0.710938] [adversarial loss: 0.900762, acc: 0.343750]\n",
            "36832: [discriminator loss: 0.572459, acc: 0.664062] [adversarial loss: 1.005419, acc: 0.328125]\n",
            "36833: [discriminator loss: 0.621463, acc: 0.656250] [adversarial loss: 1.212355, acc: 0.156250]\n",
            "36834: [discriminator loss: 0.523349, acc: 0.773438] [adversarial loss: 1.098941, acc: 0.296875]\n",
            "36835: [discriminator loss: 0.544260, acc: 0.734375] [adversarial loss: 1.108347, acc: 0.281250]\n",
            "36836: [discriminator loss: 0.651616, acc: 0.617188] [adversarial loss: 1.132428, acc: 0.265625]\n",
            "36837: [discriminator loss: 0.522995, acc: 0.726562] [adversarial loss: 1.173435, acc: 0.171875]\n",
            "36838: [discriminator loss: 0.582455, acc: 0.640625] [adversarial loss: 1.050786, acc: 0.250000]\n",
            "36839: [discriminator loss: 0.621771, acc: 0.625000] [adversarial loss: 1.017816, acc: 0.265625]\n",
            "36840: [discriminator loss: 0.558822, acc: 0.703125] [adversarial loss: 0.999577, acc: 0.312500]\n",
            "36841: [discriminator loss: 0.554944, acc: 0.703125] [adversarial loss: 0.999524, acc: 0.234375]\n",
            "36842: [discriminator loss: 0.662849, acc: 0.601562] [adversarial loss: 1.021002, acc: 0.312500]\n",
            "36843: [discriminator loss: 0.570614, acc: 0.710938] [adversarial loss: 0.963577, acc: 0.390625]\n",
            "36844: [discriminator loss: 0.697477, acc: 0.593750] [adversarial loss: 1.135015, acc: 0.234375]\n",
            "36845: [discriminator loss: 0.580035, acc: 0.625000] [adversarial loss: 1.110982, acc: 0.203125]\n",
            "36846: [discriminator loss: 0.616403, acc: 0.656250] [adversarial loss: 1.007858, acc: 0.359375]\n",
            "36847: [discriminator loss: 0.569589, acc: 0.687500] [adversarial loss: 1.102840, acc: 0.203125]\n",
            "36848: [discriminator loss: 0.631819, acc: 0.656250] [adversarial loss: 1.076003, acc: 0.296875]\n",
            "36849: [discriminator loss: 0.632489, acc: 0.664062] [adversarial loss: 1.098585, acc: 0.359375]\n",
            "36850: [discriminator loss: 0.535594, acc: 0.750000] [adversarial loss: 0.882075, acc: 0.359375]\n",
            "36851: [discriminator loss: 0.630604, acc: 0.640625] [adversarial loss: 1.291543, acc: 0.187500]\n",
            "36852: [discriminator loss: 0.571165, acc: 0.656250] [adversarial loss: 1.013484, acc: 0.359375]\n",
            "36853: [discriminator loss: 0.568756, acc: 0.687500] [adversarial loss: 1.384235, acc: 0.156250]\n",
            "36854: [discriminator loss: 0.619527, acc: 0.632812] [adversarial loss: 1.013116, acc: 0.312500]\n",
            "36855: [discriminator loss: 0.612546, acc: 0.695312] [adversarial loss: 1.208487, acc: 0.187500]\n",
            "36856: [discriminator loss: 0.542743, acc: 0.726562] [adversarial loss: 0.832981, acc: 0.468750]\n",
            "36857: [discriminator loss: 0.564719, acc: 0.710938] [adversarial loss: 1.310775, acc: 0.156250]\n",
            "36858: [discriminator loss: 0.522396, acc: 0.718750] [adversarial loss: 0.715719, acc: 0.578125]\n",
            "36859: [discriminator loss: 0.614937, acc: 0.656250] [adversarial loss: 1.250149, acc: 0.171875]\n",
            "36860: [discriminator loss: 0.605620, acc: 0.656250] [adversarial loss: 0.797429, acc: 0.515625]\n",
            "36861: [discriminator loss: 0.669839, acc: 0.625000] [adversarial loss: 1.190691, acc: 0.125000]\n",
            "36862: [discriminator loss: 0.563124, acc: 0.703125] [adversarial loss: 0.875164, acc: 0.375000]\n",
            "36863: [discriminator loss: 0.574267, acc: 0.664062] [adversarial loss: 1.253333, acc: 0.187500]\n",
            "36864: [discriminator loss: 0.546174, acc: 0.703125] [adversarial loss: 1.025233, acc: 0.359375]\n",
            "36865: [discriminator loss: 0.637273, acc: 0.625000] [adversarial loss: 1.118456, acc: 0.265625]\n",
            "36866: [discriminator loss: 0.575007, acc: 0.703125] [adversarial loss: 1.118080, acc: 0.281250]\n",
            "36867: [discriminator loss: 0.548484, acc: 0.679688] [adversarial loss: 1.189248, acc: 0.265625]\n",
            "36868: [discriminator loss: 0.564750, acc: 0.742188] [adversarial loss: 1.233283, acc: 0.234375]\n",
            "36869: [discriminator loss: 0.642120, acc: 0.601562] [adversarial loss: 0.679096, acc: 0.609375]\n",
            "36870: [discriminator loss: 0.569034, acc: 0.679688] [adversarial loss: 1.443382, acc: 0.140625]\n",
            "36871: [discriminator loss: 0.601198, acc: 0.656250] [adversarial loss: 1.165011, acc: 0.296875]\n",
            "36872: [discriminator loss: 0.546196, acc: 0.718750] [adversarial loss: 1.170177, acc: 0.265625]\n",
            "36873: [discriminator loss: 0.587016, acc: 0.687500] [adversarial loss: 0.870484, acc: 0.375000]\n",
            "36874: [discriminator loss: 0.581386, acc: 0.664062] [adversarial loss: 0.882634, acc: 0.406250]\n",
            "36875: [discriminator loss: 0.657249, acc: 0.671875] [adversarial loss: 1.110831, acc: 0.343750]\n",
            "36876: [discriminator loss: 0.595445, acc: 0.671875] [adversarial loss: 0.976998, acc: 0.328125]\n",
            "36877: [discriminator loss: 0.587098, acc: 0.656250] [adversarial loss: 1.238843, acc: 0.218750]\n",
            "36878: [discriminator loss: 0.570971, acc: 0.687500] [adversarial loss: 0.888785, acc: 0.421875]\n",
            "36879: [discriminator loss: 0.529437, acc: 0.742188] [adversarial loss: 1.135916, acc: 0.375000]\n",
            "36880: [discriminator loss: 0.618131, acc: 0.640625] [adversarial loss: 1.029515, acc: 0.375000]\n",
            "36881: [discriminator loss: 0.579464, acc: 0.671875] [adversarial loss: 1.176698, acc: 0.296875]\n",
            "36882: [discriminator loss: 0.585346, acc: 0.656250] [adversarial loss: 0.816015, acc: 0.484375]\n",
            "36883: [discriminator loss: 0.524024, acc: 0.726562] [adversarial loss: 0.932269, acc: 0.375000]\n",
            "36884: [discriminator loss: 0.616197, acc: 0.632812] [adversarial loss: 1.001990, acc: 0.312500]\n",
            "36885: [discriminator loss: 0.573363, acc: 0.695312] [adversarial loss: 1.132049, acc: 0.203125]\n",
            "36886: [discriminator loss: 0.545523, acc: 0.726562] [adversarial loss: 0.938715, acc: 0.343750]\n",
            "36887: [discriminator loss: 0.662740, acc: 0.640625] [adversarial loss: 1.068963, acc: 0.234375]\n",
            "36888: [discriminator loss: 0.577190, acc: 0.679688] [adversarial loss: 1.045821, acc: 0.343750]\n",
            "36889: [discriminator loss: 0.569967, acc: 0.687500] [adversarial loss: 0.855212, acc: 0.468750]\n",
            "36890: [discriminator loss: 0.589226, acc: 0.687500] [adversarial loss: 1.275218, acc: 0.203125]\n",
            "36891: [discriminator loss: 0.653653, acc: 0.617188] [adversarial loss: 0.997392, acc: 0.359375]\n",
            "36892: [discriminator loss: 0.559984, acc: 0.757812] [adversarial loss: 1.041759, acc: 0.328125]\n",
            "36893: [discriminator loss: 0.636963, acc: 0.671875] [adversarial loss: 1.143343, acc: 0.234375]\n",
            "36894: [discriminator loss: 0.585838, acc: 0.656250] [adversarial loss: 0.910293, acc: 0.375000]\n",
            "36895: [discriminator loss: 0.613375, acc: 0.679688] [adversarial loss: 1.151705, acc: 0.203125]\n",
            "36896: [discriminator loss: 0.559727, acc: 0.679688] [adversarial loss: 1.036731, acc: 0.218750]\n",
            "36897: [discriminator loss: 0.585173, acc: 0.687500] [adversarial loss: 1.412157, acc: 0.187500]\n",
            "36898: [discriminator loss: 0.626409, acc: 0.609375] [adversarial loss: 0.737375, acc: 0.515625]\n",
            "36899: [discriminator loss: 0.588282, acc: 0.671875] [adversarial loss: 1.150149, acc: 0.171875]\n",
            "36900: [discriminator loss: 0.547861, acc: 0.710938] [adversarial loss: 1.201607, acc: 0.187500]\n",
            "36901: [discriminator loss: 0.647940, acc: 0.609375] [adversarial loss: 1.112562, acc: 0.218750]\n",
            "36902: [discriminator loss: 0.579218, acc: 0.726562] [adversarial loss: 0.862245, acc: 0.421875]\n",
            "36903: [discriminator loss: 0.635631, acc: 0.632812] [adversarial loss: 1.066175, acc: 0.250000]\n",
            "36904: [discriminator loss: 0.591358, acc: 0.695312] [adversarial loss: 1.071891, acc: 0.234375]\n",
            "36905: [discriminator loss: 0.614984, acc: 0.648438] [adversarial loss: 1.244024, acc: 0.140625]\n",
            "36906: [discriminator loss: 0.563274, acc: 0.695312] [adversarial loss: 1.000720, acc: 0.375000]\n",
            "36907: [discriminator loss: 0.571672, acc: 0.718750] [adversarial loss: 1.025137, acc: 0.328125]\n",
            "36908: [discriminator loss: 0.529773, acc: 0.765625] [adversarial loss: 0.989755, acc: 0.375000]\n",
            "36909: [discriminator loss: 0.596214, acc: 0.687500] [adversarial loss: 1.267190, acc: 0.171875]\n",
            "36910: [discriminator loss: 0.607895, acc: 0.656250] [adversarial loss: 0.817698, acc: 0.437500]\n",
            "36911: [discriminator loss: 0.545289, acc: 0.679688] [adversarial loss: 1.077533, acc: 0.281250]\n",
            "36912: [discriminator loss: 0.623694, acc: 0.632812] [adversarial loss: 0.961178, acc: 0.421875]\n",
            "36913: [discriminator loss: 0.569313, acc: 0.664062] [adversarial loss: 1.086904, acc: 0.328125]\n",
            "36914: [discriminator loss: 0.523901, acc: 0.765625] [adversarial loss: 0.944417, acc: 0.406250]\n",
            "36915: [discriminator loss: 0.597537, acc: 0.718750] [adversarial loss: 1.313506, acc: 0.171875]\n",
            "36916: [discriminator loss: 0.590216, acc: 0.664062] [adversarial loss: 0.890576, acc: 0.406250]\n",
            "36917: [discriminator loss: 0.570037, acc: 0.710938] [adversarial loss: 1.324932, acc: 0.203125]\n",
            "36918: [discriminator loss: 0.600717, acc: 0.664062] [adversarial loss: 0.591578, acc: 0.703125]\n",
            "36919: [discriminator loss: 0.593018, acc: 0.656250] [adversarial loss: 1.072827, acc: 0.312500]\n",
            "36920: [discriminator loss: 0.574495, acc: 0.664062] [adversarial loss: 1.381431, acc: 0.156250]\n",
            "36921: [discriminator loss: 0.598450, acc: 0.640625] [adversarial loss: 1.002258, acc: 0.328125]\n",
            "36922: [discriminator loss: 0.618224, acc: 0.679688] [adversarial loss: 1.135367, acc: 0.234375]\n",
            "36923: [discriminator loss: 0.587620, acc: 0.656250] [adversarial loss: 0.866087, acc: 0.500000]\n",
            "36924: [discriminator loss: 0.591397, acc: 0.648438] [adversarial loss: 1.136054, acc: 0.234375]\n",
            "36925: [discriminator loss: 0.600407, acc: 0.695312] [adversarial loss: 0.946005, acc: 0.437500]\n",
            "36926: [discriminator loss: 0.549442, acc: 0.671875] [adversarial loss: 1.020254, acc: 0.250000]\n",
            "36927: [discriminator loss: 0.563635, acc: 0.679688] [adversarial loss: 0.842708, acc: 0.500000]\n",
            "36928: [discriminator loss: 0.587440, acc: 0.703125] [adversarial loss: 1.094331, acc: 0.265625]\n",
            "36929: [discriminator loss: 0.598926, acc: 0.640625] [adversarial loss: 0.883477, acc: 0.390625]\n",
            "36930: [discriminator loss: 0.582064, acc: 0.703125] [adversarial loss: 1.110142, acc: 0.234375]\n",
            "36931: [discriminator loss: 0.654398, acc: 0.609375] [adversarial loss: 1.058791, acc: 0.343750]\n",
            "36932: [discriminator loss: 0.564518, acc: 0.742188] [adversarial loss: 0.969233, acc: 0.328125]\n",
            "36933: [discriminator loss: 0.592543, acc: 0.648438] [adversarial loss: 1.156610, acc: 0.265625]\n",
            "36934: [discriminator loss: 0.558866, acc: 0.671875] [adversarial loss: 1.067882, acc: 0.328125]\n",
            "36935: [discriminator loss: 0.570887, acc: 0.687500] [adversarial loss: 1.107303, acc: 0.343750]\n",
            "36936: [discriminator loss: 0.559986, acc: 0.687500] [adversarial loss: 1.093073, acc: 0.203125]\n",
            "36937: [discriminator loss: 0.561290, acc: 0.703125] [adversarial loss: 1.190808, acc: 0.187500]\n",
            "36938: [discriminator loss: 0.627290, acc: 0.656250] [adversarial loss: 0.943580, acc: 0.453125]\n",
            "36939: [discriminator loss: 0.587920, acc: 0.648438] [adversarial loss: 0.978786, acc: 0.296875]\n",
            "36940: [discriminator loss: 0.595748, acc: 0.656250] [adversarial loss: 0.892915, acc: 0.375000]\n",
            "36941: [discriminator loss: 0.553172, acc: 0.718750] [adversarial loss: 1.207961, acc: 0.250000]\n",
            "36942: [discriminator loss: 0.509643, acc: 0.757812] [adversarial loss: 0.805331, acc: 0.484375]\n",
            "36943: [discriminator loss: 0.548441, acc: 0.695312] [adversarial loss: 1.217603, acc: 0.218750]\n",
            "36944: [discriminator loss: 0.540142, acc: 0.742188] [adversarial loss: 0.857188, acc: 0.453125]\n",
            "36945: [discriminator loss: 0.561703, acc: 0.710938] [adversarial loss: 1.002259, acc: 0.343750]\n",
            "36946: [discriminator loss: 0.594474, acc: 0.679688] [adversarial loss: 1.077453, acc: 0.296875]\n",
            "36947: [discriminator loss: 0.590951, acc: 0.664062] [adversarial loss: 0.823806, acc: 0.484375]\n",
            "36948: [discriminator loss: 0.601922, acc: 0.625000] [adversarial loss: 1.344120, acc: 0.187500]\n",
            "36949: [discriminator loss: 0.633098, acc: 0.671875] [adversarial loss: 0.849772, acc: 0.468750]\n",
            "36950: [discriminator loss: 0.637716, acc: 0.656250] [adversarial loss: 1.094774, acc: 0.312500]\n",
            "36951: [discriminator loss: 0.630865, acc: 0.625000] [adversarial loss: 0.825338, acc: 0.500000]\n",
            "36952: [discriminator loss: 0.563512, acc: 0.726562] [adversarial loss: 1.237063, acc: 0.218750]\n",
            "36953: [discriminator loss: 0.572078, acc: 0.664062] [adversarial loss: 1.123469, acc: 0.250000]\n",
            "36954: [discriminator loss: 0.617582, acc: 0.609375] [adversarial loss: 1.024971, acc: 0.328125]\n",
            "36955: [discriminator loss: 0.599345, acc: 0.625000] [adversarial loss: 1.240702, acc: 0.218750]\n",
            "36956: [discriminator loss: 0.605112, acc: 0.625000] [adversarial loss: 0.938274, acc: 0.359375]\n",
            "36957: [discriminator loss: 0.584074, acc: 0.656250] [adversarial loss: 0.885908, acc: 0.406250]\n",
            "36958: [discriminator loss: 0.559496, acc: 0.671875] [adversarial loss: 1.324702, acc: 0.156250]\n",
            "36959: [discriminator loss: 0.623558, acc: 0.640625] [adversarial loss: 0.814862, acc: 0.500000]\n",
            "36960: [discriminator loss: 0.571137, acc: 0.679688] [adversarial loss: 1.095298, acc: 0.390625]\n",
            "36961: [discriminator loss: 0.619330, acc: 0.664062] [adversarial loss: 0.842560, acc: 0.453125]\n",
            "36962: [discriminator loss: 0.621816, acc: 0.695312] [adversarial loss: 1.326052, acc: 0.187500]\n",
            "36963: [discriminator loss: 0.612884, acc: 0.640625] [adversarial loss: 0.906239, acc: 0.390625]\n",
            "36964: [discriminator loss: 0.578798, acc: 0.718750] [adversarial loss: 1.001799, acc: 0.328125]\n",
            "36965: [discriminator loss: 0.602421, acc: 0.625000] [adversarial loss: 1.233277, acc: 0.187500]\n",
            "36966: [discriminator loss: 0.537829, acc: 0.734375] [adversarial loss: 0.734181, acc: 0.500000]\n",
            "36967: [discriminator loss: 0.648835, acc: 0.664062] [adversarial loss: 1.202526, acc: 0.187500]\n",
            "36968: [discriminator loss: 0.614387, acc: 0.687500] [adversarial loss: 0.854467, acc: 0.453125]\n",
            "36969: [discriminator loss: 0.588744, acc: 0.664062] [adversarial loss: 1.313221, acc: 0.265625]\n",
            "36970: [discriminator loss: 0.566403, acc: 0.710938] [adversarial loss: 0.802128, acc: 0.531250]\n",
            "36971: [discriminator loss: 0.638945, acc: 0.632812] [adversarial loss: 1.194348, acc: 0.203125]\n",
            "36972: [discriminator loss: 0.630542, acc: 0.648438] [adversarial loss: 0.844635, acc: 0.468750]\n",
            "36973: [discriminator loss: 0.532503, acc: 0.750000] [adversarial loss: 0.955751, acc: 0.312500]\n",
            "36974: [discriminator loss: 0.571381, acc: 0.687500] [adversarial loss: 1.197659, acc: 0.218750]\n",
            "36975: [discriminator loss: 0.589413, acc: 0.632812] [adversarial loss: 0.944976, acc: 0.421875]\n",
            "36976: [discriminator loss: 0.646833, acc: 0.601562] [adversarial loss: 1.320986, acc: 0.125000]\n",
            "36977: [discriminator loss: 0.592825, acc: 0.664062] [adversarial loss: 1.153556, acc: 0.203125]\n",
            "36978: [discriminator loss: 0.575885, acc: 0.710938] [adversarial loss: 0.943272, acc: 0.359375]\n",
            "36979: [discriminator loss: 0.583422, acc: 0.625000] [adversarial loss: 1.245740, acc: 0.218750]\n",
            "36980: [discriminator loss: 0.572386, acc: 0.664062] [adversarial loss: 0.899150, acc: 0.421875]\n",
            "36981: [discriminator loss: 0.591855, acc: 0.726562] [adversarial loss: 1.110939, acc: 0.328125]\n",
            "36982: [discriminator loss: 0.569773, acc: 0.679688] [adversarial loss: 0.975847, acc: 0.390625]\n",
            "36983: [discriminator loss: 0.572716, acc: 0.726562] [adversarial loss: 1.074955, acc: 0.281250]\n",
            "36984: [discriminator loss: 0.544685, acc: 0.726562] [adversarial loss: 0.914907, acc: 0.390625]\n",
            "36985: [discriminator loss: 0.607368, acc: 0.664062] [adversarial loss: 1.006292, acc: 0.390625]\n",
            "36986: [discriminator loss: 0.526079, acc: 0.757812] [adversarial loss: 1.263099, acc: 0.156250]\n",
            "36987: [discriminator loss: 0.535801, acc: 0.781250] [adversarial loss: 0.848326, acc: 0.453125]\n",
            "36988: [discriminator loss: 0.627872, acc: 0.656250] [adversarial loss: 1.062853, acc: 0.234375]\n",
            "36989: [discriminator loss: 0.582151, acc: 0.679688] [adversarial loss: 0.948137, acc: 0.328125]\n",
            "36990: [discriminator loss: 0.564658, acc: 0.703125] [adversarial loss: 1.276032, acc: 0.156250]\n",
            "36991: [discriminator loss: 0.538911, acc: 0.750000] [adversarial loss: 0.976691, acc: 0.375000]\n",
            "36992: [discriminator loss: 0.612042, acc: 0.687500] [adversarial loss: 1.053321, acc: 0.312500]\n",
            "36993: [discriminator loss: 0.591416, acc: 0.656250] [adversarial loss: 0.987463, acc: 0.453125]\n",
            "36994: [discriminator loss: 0.513605, acc: 0.765625] [adversarial loss: 0.986071, acc: 0.296875]\n",
            "36995: [discriminator loss: 0.580464, acc: 0.679688] [adversarial loss: 1.067064, acc: 0.250000]\n",
            "36996: [discriminator loss: 0.546269, acc: 0.703125] [adversarial loss: 1.216164, acc: 0.296875]\n",
            "36997: [discriminator loss: 0.619682, acc: 0.671875] [adversarial loss: 0.948358, acc: 0.359375]\n",
            "36998: [discriminator loss: 0.553918, acc: 0.695312] [adversarial loss: 1.263555, acc: 0.156250]\n",
            "36999: [discriminator loss: 0.580741, acc: 0.695312] [adversarial loss: 0.701710, acc: 0.625000]\n",
            "cgan_mnist  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
            "37000: [discriminator loss: 0.629652, acc: 0.703125] [adversarial loss: 1.548297, acc: 0.109375]\n",
            "37001: [discriminator loss: 0.571388, acc: 0.664062] [adversarial loss: 0.834681, acc: 0.453125]\n",
            "37002: [discriminator loss: 0.564965, acc: 0.687500] [adversarial loss: 1.195958, acc: 0.281250]\n",
            "37003: [discriminator loss: 0.580544, acc: 0.687500] [adversarial loss: 1.136520, acc: 0.203125]\n",
            "37004: [discriminator loss: 0.612693, acc: 0.640625] [adversarial loss: 1.177751, acc: 0.203125]\n",
            "37005: [discriminator loss: 0.644844, acc: 0.640625] [adversarial loss: 1.174923, acc: 0.265625]\n",
            "37006: [discriminator loss: 0.544438, acc: 0.726562] [adversarial loss: 1.022907, acc: 0.359375]\n",
            "37007: [discriminator loss: 0.556870, acc: 0.726562] [adversarial loss: 1.033505, acc: 0.312500]\n",
            "37008: [discriminator loss: 0.581080, acc: 0.664062] [adversarial loss: 0.954533, acc: 0.359375]\n",
            "37009: [discriminator loss: 0.525090, acc: 0.765625] [adversarial loss: 1.199790, acc: 0.281250]\n",
            "37010: [discriminator loss: 0.588581, acc: 0.695312] [adversarial loss: 0.863667, acc: 0.484375]\n",
            "37011: [discriminator loss: 0.631595, acc: 0.632812] [adversarial loss: 1.161968, acc: 0.281250]\n",
            "37012: [discriminator loss: 0.659119, acc: 0.617188] [adversarial loss: 1.071718, acc: 0.359375]\n",
            "37013: [discriminator loss: 0.522636, acc: 0.742188] [adversarial loss: 1.073636, acc: 0.296875]\n",
            "37014: [discriminator loss: 0.507152, acc: 0.765625] [adversarial loss: 1.085865, acc: 0.359375]\n",
            "37015: [discriminator loss: 0.584882, acc: 0.656250] [adversarial loss: 0.980842, acc: 0.343750]\n",
            "37016: [discriminator loss: 0.560796, acc: 0.734375] [adversarial loss: 0.958963, acc: 0.296875]\n",
            "37017: [discriminator loss: 0.489765, acc: 0.765625] [adversarial loss: 0.825493, acc: 0.500000]\n",
            "37018: [discriminator loss: 0.587396, acc: 0.671875] [adversarial loss: 1.262744, acc: 0.234375]\n",
            "37019: [discriminator loss: 0.589087, acc: 0.742188] [adversarial loss: 0.886455, acc: 0.453125]\n",
            "37020: [discriminator loss: 0.569179, acc: 0.671875] [adversarial loss: 1.084286, acc: 0.203125]\n",
            "37021: [discriminator loss: 0.522466, acc: 0.750000] [adversarial loss: 0.828056, acc: 0.484375]\n",
            "37022: [discriminator loss: 0.543482, acc: 0.718750] [adversarial loss: 1.119199, acc: 0.265625]\n",
            "37023: [discriminator loss: 0.584463, acc: 0.625000] [adversarial loss: 0.967365, acc: 0.421875]\n",
            "37024: [discriminator loss: 0.599354, acc: 0.625000] [adversarial loss: 1.183748, acc: 0.187500]\n",
            "37025: [discriminator loss: 0.631804, acc: 0.593750] [adversarial loss: 1.123168, acc: 0.234375]\n",
            "37026: [discriminator loss: 0.608421, acc: 0.656250] [adversarial loss: 1.120416, acc: 0.218750]\n",
            "37027: [discriminator loss: 0.568668, acc: 0.710938] [adversarial loss: 1.180108, acc: 0.218750]\n",
            "37028: [discriminator loss: 0.679576, acc: 0.617188] [adversarial loss: 0.777956, acc: 0.500000]\n",
            "37029: [discriminator loss: 0.586379, acc: 0.671875] [adversarial loss: 1.303531, acc: 0.171875]\n",
            "37030: [discriminator loss: 0.564527, acc: 0.679688] [adversarial loss: 0.975956, acc: 0.328125]\n",
            "37031: [discriminator loss: 0.594824, acc: 0.664062] [adversarial loss: 1.069445, acc: 0.359375]\n",
            "37032: [discriminator loss: 0.613795, acc: 0.656250] [adversarial loss: 1.017984, acc: 0.390625]\n",
            "37033: [discriminator loss: 0.581962, acc: 0.734375] [adversarial loss: 1.294613, acc: 0.187500]\n",
            "37034: [discriminator loss: 0.537634, acc: 0.726562] [adversarial loss: 1.096441, acc: 0.281250]\n",
            "37035: [discriminator loss: 0.540119, acc: 0.742188] [adversarial loss: 1.253537, acc: 0.234375]\n",
            "37036: [discriminator loss: 0.630957, acc: 0.625000] [adversarial loss: 1.000876, acc: 0.484375]\n",
            "37037: [discriminator loss: 0.563098, acc: 0.687500] [adversarial loss: 1.424686, acc: 0.093750]\n",
            "37038: [discriminator loss: 0.512395, acc: 0.695312] [adversarial loss: 0.933274, acc: 0.328125]\n",
            "37039: [discriminator loss: 0.648089, acc: 0.687500] [adversarial loss: 1.063165, acc: 0.281250]\n",
            "37040: [discriminator loss: 0.572977, acc: 0.695312] [adversarial loss: 1.038295, acc: 0.359375]\n",
            "37041: [discriminator loss: 0.661549, acc: 0.671875] [adversarial loss: 0.853989, acc: 0.437500]\n",
            "37042: [discriminator loss: 0.586688, acc: 0.679688] [adversarial loss: 1.313750, acc: 0.093750]\n",
            "37043: [discriminator loss: 0.619898, acc: 0.656250] [adversarial loss: 0.824446, acc: 0.484375]\n",
            "37044: [discriminator loss: 0.591192, acc: 0.664062] [adversarial loss: 1.272449, acc: 0.109375]\n",
            "37045: [discriminator loss: 0.675219, acc: 0.609375] [adversarial loss: 0.640132, acc: 0.625000]\n",
            "37046: [discriminator loss: 0.615936, acc: 0.609375] [adversarial loss: 1.199586, acc: 0.296875]\n",
            "37047: [discriminator loss: 0.618556, acc: 0.656250] [adversarial loss: 0.846791, acc: 0.406250]\n",
            "37048: [discriminator loss: 0.602431, acc: 0.687500] [adversarial loss: 1.034876, acc: 0.218750]\n",
            "37049: [discriminator loss: 0.577476, acc: 0.687500] [adversarial loss: 0.864404, acc: 0.390625]\n",
            "37050: [discriminator loss: 0.538298, acc: 0.757812] [adversarial loss: 1.309998, acc: 0.187500]\n",
            "37051: [discriminator loss: 0.555063, acc: 0.695312] [adversarial loss: 0.979591, acc: 0.375000]\n",
            "37052: [discriminator loss: 0.554875, acc: 0.687500] [adversarial loss: 1.423946, acc: 0.203125]\n",
            "37053: [discriminator loss: 0.576115, acc: 0.656250] [adversarial loss: 0.860749, acc: 0.468750]\n",
            "37054: [discriminator loss: 0.576996, acc: 0.687500] [adversarial loss: 1.260474, acc: 0.250000]\n",
            "37055: [discriminator loss: 0.592672, acc: 0.695312] [adversarial loss: 0.929608, acc: 0.437500]\n",
            "37056: [discriminator loss: 0.604735, acc: 0.679688] [adversarial loss: 1.152053, acc: 0.343750]\n",
            "37057: [discriminator loss: 0.609755, acc: 0.710938] [adversarial loss: 1.236632, acc: 0.171875]\n",
            "37058: [discriminator loss: 0.566572, acc: 0.718750] [adversarial loss: 1.029573, acc: 0.281250]\n",
            "37059: [discriminator loss: 0.542438, acc: 0.750000] [adversarial loss: 1.117066, acc: 0.187500]\n",
            "37060: [discriminator loss: 0.648705, acc: 0.609375] [adversarial loss: 1.078014, acc: 0.296875]\n",
            "37061: [discriminator loss: 0.611902, acc: 0.656250] [adversarial loss: 1.237228, acc: 0.187500]\n",
            "37062: [discriminator loss: 0.553926, acc: 0.703125] [adversarial loss: 0.934820, acc: 0.453125]\n",
            "37063: [discriminator loss: 0.539846, acc: 0.734375] [adversarial loss: 0.886755, acc: 0.468750]\n",
            "37064: [discriminator loss: 0.611646, acc: 0.648438] [adversarial loss: 1.099109, acc: 0.218750]\n",
            "37065: [discriminator loss: 0.607962, acc: 0.625000] [adversarial loss: 0.745176, acc: 0.578125]\n",
            "37066: [discriminator loss: 0.610666, acc: 0.687500] [adversarial loss: 1.493707, acc: 0.093750]\n",
            "37067: [discriminator loss: 0.648662, acc: 0.617188] [adversarial loss: 0.803505, acc: 0.484375]\n",
            "37068: [discriminator loss: 0.644600, acc: 0.648438] [adversarial loss: 1.280793, acc: 0.234375]\n",
            "37069: [discriminator loss: 0.560163, acc: 0.671875] [adversarial loss: 0.942698, acc: 0.359375]\n",
            "37070: [discriminator loss: 0.588109, acc: 0.640625] [adversarial loss: 1.128362, acc: 0.156250]\n",
            "37071: [discriminator loss: 0.608134, acc: 0.664062] [adversarial loss: 1.106885, acc: 0.281250]\n",
            "37072: [discriminator loss: 0.671617, acc: 0.617188] [adversarial loss: 0.884399, acc: 0.453125]\n",
            "37073: [discriminator loss: 0.599596, acc: 0.656250] [adversarial loss: 1.260640, acc: 0.187500]\n",
            "37074: [discriminator loss: 0.554160, acc: 0.710938] [adversarial loss: 1.053694, acc: 0.281250]\n",
            "37075: [discriminator loss: 0.634700, acc: 0.625000] [adversarial loss: 0.959126, acc: 0.343750]\n",
            "37076: [discriminator loss: 0.591950, acc: 0.656250] [adversarial loss: 1.128619, acc: 0.218750]\n",
            "37077: [discriminator loss: 0.492582, acc: 0.796875] [adversarial loss: 0.857728, acc: 0.500000]\n",
            "37078: [discriminator loss: 0.579711, acc: 0.742188] [adversarial loss: 1.064535, acc: 0.187500]\n",
            "37079: [discriminator loss: 0.601914, acc: 0.625000] [adversarial loss: 0.910620, acc: 0.359375]\n",
            "37080: [discriminator loss: 0.588195, acc: 0.687500] [adversarial loss: 1.134044, acc: 0.281250]\n",
            "37081: [discriminator loss: 0.588389, acc: 0.664062] [adversarial loss: 0.843618, acc: 0.468750]\n",
            "37082: [discriminator loss: 0.673130, acc: 0.609375] [adversarial loss: 1.366896, acc: 0.187500]\n",
            "37083: [discriminator loss: 0.599373, acc: 0.687500] [adversarial loss: 0.914003, acc: 0.421875]\n",
            "37084: [discriminator loss: 0.629308, acc: 0.664062] [adversarial loss: 1.080529, acc: 0.281250]\n",
            "37085: [discriminator loss: 0.561470, acc: 0.695312] [adversarial loss: 0.743526, acc: 0.593750]\n",
            "37086: [discriminator loss: 0.553205, acc: 0.765625] [adversarial loss: 1.245849, acc: 0.250000]\n",
            "37087: [discriminator loss: 0.577824, acc: 0.710938] [adversarial loss: 0.958804, acc: 0.421875]\n",
            "37088: [discriminator loss: 0.587447, acc: 0.679688] [adversarial loss: 0.952365, acc: 0.390625]\n",
            "37089: [discriminator loss: 0.537640, acc: 0.726562] [adversarial loss: 1.164564, acc: 0.218750]\n",
            "37090: [discriminator loss: 0.572723, acc: 0.679688] [adversarial loss: 0.954471, acc: 0.375000]\n",
            "37091: [discriminator loss: 0.609377, acc: 0.640625] [adversarial loss: 1.180684, acc: 0.234375]\n",
            "37092: [discriminator loss: 0.575080, acc: 0.695312] [adversarial loss: 0.827894, acc: 0.375000]\n",
            "37093: [discriminator loss: 0.605666, acc: 0.679688] [adversarial loss: 1.198947, acc: 0.250000]\n",
            "37094: [discriminator loss: 0.632660, acc: 0.617188] [adversarial loss: 0.704065, acc: 0.578125]\n",
            "37095: [discriminator loss: 0.564540, acc: 0.718750] [adversarial loss: 1.290506, acc: 0.218750]\n",
            "37096: [discriminator loss: 0.660819, acc: 0.578125] [adversarial loss: 1.011599, acc: 0.296875]\n",
            "37097: [discriminator loss: 0.579996, acc: 0.671875] [adversarial loss: 1.134832, acc: 0.312500]\n",
            "37098: [discriminator loss: 0.529588, acc: 0.757812] [adversarial loss: 1.065827, acc: 0.296875]\n",
            "37099: [discriminator loss: 0.571700, acc: 0.687500] [adversarial loss: 0.865274, acc: 0.421875]\n",
            "37100: [discriminator loss: 0.671232, acc: 0.593750] [adversarial loss: 1.148587, acc: 0.250000]\n",
            "37101: [discriminator loss: 0.544540, acc: 0.703125] [adversarial loss: 0.952996, acc: 0.312500]\n",
            "37102: [discriminator loss: 0.618629, acc: 0.703125] [adversarial loss: 1.168356, acc: 0.187500]\n",
            "37103: [discriminator loss: 0.576924, acc: 0.679688] [adversarial loss: 0.843211, acc: 0.453125]\n",
            "37104: [discriminator loss: 0.578199, acc: 0.710938] [adversarial loss: 1.132826, acc: 0.218750]\n",
            "37105: [discriminator loss: 0.592374, acc: 0.671875] [adversarial loss: 1.213453, acc: 0.171875]\n",
            "37106: [discriminator loss: 0.594926, acc: 0.687500] [adversarial loss: 0.862246, acc: 0.515625]\n",
            "37107: [discriminator loss: 0.609657, acc: 0.640625] [adversarial loss: 1.272005, acc: 0.156250]\n",
            "37108: [discriminator loss: 0.621769, acc: 0.593750] [adversarial loss: 0.720392, acc: 0.625000]\n",
            "37109: [discriminator loss: 0.628927, acc: 0.687500] [adversarial loss: 1.266755, acc: 0.156250]\n",
            "37110: [discriminator loss: 0.616821, acc: 0.632812] [adversarial loss: 1.015393, acc: 0.328125]\n",
            "37111: [discriminator loss: 0.607932, acc: 0.710938] [adversarial loss: 1.088452, acc: 0.203125]\n",
            "37112: [discriminator loss: 0.627633, acc: 0.671875] [adversarial loss: 1.304698, acc: 0.093750]\n",
            "37113: [discriminator loss: 0.565691, acc: 0.695312] [adversarial loss: 1.140820, acc: 0.250000]\n",
            "37114: [discriminator loss: 0.612002, acc: 0.671875] [adversarial loss: 0.774967, acc: 0.468750]\n",
            "37115: [discriminator loss: 0.646406, acc: 0.656250] [adversarial loss: 1.049085, acc: 0.328125]\n",
            "37116: [discriminator loss: 0.583199, acc: 0.710938] [adversarial loss: 1.033834, acc: 0.312500]\n",
            "37117: [discriminator loss: 0.556712, acc: 0.703125] [adversarial loss: 1.138944, acc: 0.171875]\n",
            "37118: [discriminator loss: 0.622129, acc: 0.671875] [adversarial loss: 1.002113, acc: 0.343750]\n",
            "37119: [discriminator loss: 0.559161, acc: 0.703125] [adversarial loss: 1.088778, acc: 0.234375]\n",
            "37120: [discriminator loss: 0.561246, acc: 0.703125] [adversarial loss: 1.050063, acc: 0.265625]\n",
            "37121: [discriminator loss: 0.531208, acc: 0.718750] [adversarial loss: 1.046860, acc: 0.312500]\n",
            "37122: [discriminator loss: 0.600375, acc: 0.648438] [adversarial loss: 1.068294, acc: 0.390625]\n",
            "37123: [discriminator loss: 0.538525, acc: 0.703125] [adversarial loss: 1.075188, acc: 0.375000]\n",
            "37124: [discriminator loss: 0.604854, acc: 0.593750] [adversarial loss: 1.048235, acc: 0.281250]\n",
            "37125: [discriminator loss: 0.537180, acc: 0.742188] [adversarial loss: 1.025482, acc: 0.328125]\n",
            "37126: [discriminator loss: 0.598875, acc: 0.679688] [adversarial loss: 0.986813, acc: 0.328125]\n",
            "37127: [discriminator loss: 0.623723, acc: 0.664062] [adversarial loss: 0.980428, acc: 0.390625]\n",
            "37128: [discriminator loss: 0.537819, acc: 0.726562] [adversarial loss: 0.876691, acc: 0.484375]\n",
            "37129: [discriminator loss: 0.558788, acc: 0.695312] [adversarial loss: 1.298827, acc: 0.281250]\n",
            "37130: [discriminator loss: 0.608114, acc: 0.718750] [adversarial loss: 0.853818, acc: 0.468750]\n",
            "37131: [discriminator loss: 0.616618, acc: 0.664062] [adversarial loss: 1.319411, acc: 0.218750]\n",
            "37132: [discriminator loss: 0.615388, acc: 0.648438] [adversarial loss: 0.894169, acc: 0.421875]\n",
            "37133: [discriminator loss: 0.561243, acc: 0.710938] [adversarial loss: 1.075776, acc: 0.281250]\n",
            "37134: [discriminator loss: 0.661456, acc: 0.617188] [adversarial loss: 0.828509, acc: 0.437500]\n",
            "37135: [discriminator loss: 0.586559, acc: 0.703125] [adversarial loss: 1.038172, acc: 0.312500]\n",
            "37136: [discriminator loss: 0.603451, acc: 0.656250] [adversarial loss: 1.214785, acc: 0.203125]\n",
            "37137: [discriminator loss: 0.566454, acc: 0.687500] [adversarial loss: 1.052508, acc: 0.296875]\n",
            "37138: [discriminator loss: 0.599318, acc: 0.679688] [adversarial loss: 1.050809, acc: 0.296875]\n",
            "37139: [discriminator loss: 0.565760, acc: 0.695312] [adversarial loss: 0.868970, acc: 0.437500]\n",
            "37140: [discriminator loss: 0.552716, acc: 0.718750] [adversarial loss: 0.997144, acc: 0.359375]\n",
            "37141: [discriminator loss: 0.552489, acc: 0.734375] [adversarial loss: 1.200034, acc: 0.171875]\n",
            "37142: [discriminator loss: 0.634852, acc: 0.640625] [adversarial loss: 0.783925, acc: 0.546875]\n",
            "37143: [discriminator loss: 0.609899, acc: 0.648438] [adversarial loss: 1.192348, acc: 0.203125]\n",
            "37144: [discriminator loss: 0.568999, acc: 0.703125] [adversarial loss: 0.815146, acc: 0.468750]\n",
            "37145: [discriminator loss: 0.617103, acc: 0.632812] [adversarial loss: 1.153985, acc: 0.171875]\n",
            "37146: [discriminator loss: 0.575784, acc: 0.687500] [adversarial loss: 1.168317, acc: 0.234375]\n",
            "37147: [discriminator loss: 0.570565, acc: 0.679688] [adversarial loss: 1.086724, acc: 0.250000]\n",
            "37148: [discriminator loss: 0.623604, acc: 0.609375] [adversarial loss: 0.956055, acc: 0.328125]\n",
            "37149: [discriminator loss: 0.563991, acc: 0.734375] [adversarial loss: 1.117395, acc: 0.250000]\n",
            "37150: [discriminator loss: 0.579844, acc: 0.687500] [adversarial loss: 0.984346, acc: 0.406250]\n",
            "37151: [discriminator loss: 0.611451, acc: 0.671875] [adversarial loss: 0.807764, acc: 0.421875]\n",
            "37152: [discriminator loss: 0.581779, acc: 0.687500] [adversarial loss: 1.204176, acc: 0.296875]\n",
            "37153: [discriminator loss: 0.683377, acc: 0.585938] [adversarial loss: 1.054211, acc: 0.281250]\n",
            "37154: [discriminator loss: 0.604803, acc: 0.718750] [adversarial loss: 1.243024, acc: 0.187500]\n",
            "37155: [discriminator loss: 0.640728, acc: 0.617188] [adversarial loss: 1.057721, acc: 0.312500]\n",
            "37156: [discriminator loss: 0.571930, acc: 0.703125] [adversarial loss: 1.026578, acc: 0.250000]\n",
            "37157: [discriminator loss: 0.599426, acc: 0.695312] [adversarial loss: 1.178361, acc: 0.250000]\n",
            "37158: [discriminator loss: 0.603152, acc: 0.671875] [adversarial loss: 0.775460, acc: 0.578125]\n",
            "37159: [discriminator loss: 0.608225, acc: 0.656250] [adversarial loss: 1.366889, acc: 0.171875]\n",
            "37160: [discriminator loss: 0.616042, acc: 0.648438] [adversarial loss: 0.868628, acc: 0.437500]\n",
            "37161: [discriminator loss: 0.585052, acc: 0.703125] [adversarial loss: 1.291993, acc: 0.171875]\n",
            "37162: [discriminator loss: 0.613179, acc: 0.648438] [adversarial loss: 1.054011, acc: 0.156250]\n",
            "37163: [discriminator loss: 0.635977, acc: 0.593750] [adversarial loss: 1.155555, acc: 0.281250]\n",
            "37164: [discriminator loss: 0.605396, acc: 0.687500] [adversarial loss: 1.271118, acc: 0.093750]\n",
            "37165: [discriminator loss: 0.554330, acc: 0.742188] [adversarial loss: 0.893645, acc: 0.421875]\n",
            "37166: [discriminator loss: 0.585746, acc: 0.718750] [adversarial loss: 1.190035, acc: 0.250000]\n",
            "37167: [discriminator loss: 0.585223, acc: 0.679688] [adversarial loss: 1.106765, acc: 0.250000]\n",
            "37168: [discriminator loss: 0.542028, acc: 0.695312] [adversarial loss: 1.029194, acc: 0.281250]\n",
            "37169: [discriminator loss: 0.571331, acc: 0.671875] [adversarial loss: 1.075220, acc: 0.328125]\n",
            "37170: [discriminator loss: 0.565878, acc: 0.695312] [adversarial loss: 1.149959, acc: 0.250000]\n",
            "37171: [discriminator loss: 0.530688, acc: 0.726562] [adversarial loss: 0.967350, acc: 0.453125]\n",
            "37172: [discriminator loss: 0.564309, acc: 0.687500] [adversarial loss: 1.072442, acc: 0.265625]\n",
            "37173: [discriminator loss: 0.595055, acc: 0.648438] [adversarial loss: 1.072564, acc: 0.250000]\n",
            "37174: [discriminator loss: 0.587547, acc: 0.648438] [adversarial loss: 1.065093, acc: 0.203125]\n",
            "37175: [discriminator loss: 0.624447, acc: 0.664062] [adversarial loss: 1.274747, acc: 0.093750]\n",
            "37176: [discriminator loss: 0.600327, acc: 0.671875] [adversarial loss: 0.984618, acc: 0.375000]\n",
            "37177: [discriminator loss: 0.552787, acc: 0.703125] [adversarial loss: 0.888869, acc: 0.406250]\n",
            "37178: [discriminator loss: 0.584548, acc: 0.640625] [adversarial loss: 1.013627, acc: 0.328125]\n",
            "37179: [discriminator loss: 0.589384, acc: 0.632812] [adversarial loss: 1.144235, acc: 0.234375]\n",
            "37180: [discriminator loss: 0.587797, acc: 0.679688] [adversarial loss: 0.878018, acc: 0.390625]\n",
            "37181: [discriminator loss: 0.567020, acc: 0.742188] [adversarial loss: 1.224161, acc: 0.171875]\n",
            "37182: [discriminator loss: 0.554800, acc: 0.734375] [adversarial loss: 0.820655, acc: 0.515625]\n",
            "37183: [discriminator loss: 0.659748, acc: 0.585938] [adversarial loss: 1.397485, acc: 0.140625]\n",
            "37184: [discriminator loss: 0.592152, acc: 0.695312] [adversarial loss: 0.910998, acc: 0.375000]\n",
            "37185: [discriminator loss: 0.592292, acc: 0.687500] [adversarial loss: 1.157337, acc: 0.281250]\n",
            "37186: [discriminator loss: 0.610202, acc: 0.640625] [adversarial loss: 1.170666, acc: 0.218750]\n",
            "37187: [discriminator loss: 0.615669, acc: 0.710938] [adversarial loss: 0.782176, acc: 0.468750]\n",
            "37188: [discriminator loss: 0.593552, acc: 0.664062] [adversarial loss: 1.082621, acc: 0.312500]\n",
            "37189: [discriminator loss: 0.605345, acc: 0.640625] [adversarial loss: 0.797654, acc: 0.484375]\n",
            "37190: [discriminator loss: 0.680063, acc: 0.648438] [adversarial loss: 1.202661, acc: 0.296875]\n",
            "37191: [discriminator loss: 0.565024, acc: 0.710938] [adversarial loss: 1.124898, acc: 0.328125]\n",
            "37192: [discriminator loss: 0.574726, acc: 0.710938] [adversarial loss: 0.902531, acc: 0.375000]\n",
            "37193: [discriminator loss: 0.584980, acc: 0.710938] [adversarial loss: 1.383011, acc: 0.109375]\n",
            "37194: [discriminator loss: 0.581469, acc: 0.703125] [adversarial loss: 0.830817, acc: 0.390625]\n",
            "37195: [discriminator loss: 0.570167, acc: 0.679688] [adversarial loss: 1.275771, acc: 0.140625]\n",
            "37196: [discriminator loss: 0.571677, acc: 0.679688] [adversarial loss: 1.065320, acc: 0.312500]\n",
            "37197: [discriminator loss: 0.604946, acc: 0.609375] [adversarial loss: 1.279486, acc: 0.187500]\n",
            "37198: [discriminator loss: 0.574033, acc: 0.687500] [adversarial loss: 1.020720, acc: 0.375000]\n",
            "37199: [discriminator loss: 0.600232, acc: 0.671875] [adversarial loss: 0.882757, acc: 0.421875]\n",
            "37200: [discriminator loss: 0.589351, acc: 0.734375] [adversarial loss: 0.953921, acc: 0.343750]\n",
            "37201: [discriminator loss: 0.680245, acc: 0.632812] [adversarial loss: 0.917808, acc: 0.328125]\n",
            "37202: [discriminator loss: 0.582457, acc: 0.695312] [adversarial loss: 0.921862, acc: 0.468750]\n",
            "37203: [discriminator loss: 0.630975, acc: 0.625000] [adversarial loss: 0.898548, acc: 0.312500]\n",
            "37204: [discriminator loss: 0.562355, acc: 0.718750] [adversarial loss: 1.337285, acc: 0.140625]\n",
            "37205: [discriminator loss: 0.704265, acc: 0.593750] [adversarial loss: 0.749606, acc: 0.453125]\n",
            "37206: [discriminator loss: 0.602380, acc: 0.648438] [adversarial loss: 1.207993, acc: 0.234375]\n",
            "37207: [discriminator loss: 0.628119, acc: 0.640625] [adversarial loss: 0.911309, acc: 0.375000]\n",
            "37208: [discriminator loss: 0.574767, acc: 0.656250] [adversarial loss: 1.280160, acc: 0.234375]\n",
            "37209: [discriminator loss: 0.655029, acc: 0.609375] [adversarial loss: 0.785808, acc: 0.484375]\n",
            "37210: [discriminator loss: 0.627671, acc: 0.664062] [adversarial loss: 1.114352, acc: 0.187500]\n",
            "37211: [discriminator loss: 0.617674, acc: 0.593750] [adversarial loss: 0.825525, acc: 0.437500]\n",
            "37212: [discriminator loss: 0.584817, acc: 0.718750] [adversarial loss: 1.033786, acc: 0.281250]\n",
            "37213: [discriminator loss: 0.560517, acc: 0.703125] [adversarial loss: 1.234168, acc: 0.218750]\n",
            "37214: [discriminator loss: 0.590832, acc: 0.703125] [adversarial loss: 0.973397, acc: 0.312500]\n",
            "37215: [discriminator loss: 0.607246, acc: 0.648438] [adversarial loss: 1.040218, acc: 0.281250]\n",
            "37216: [discriminator loss: 0.665428, acc: 0.609375] [adversarial loss: 1.077341, acc: 0.343750]\n",
            "37217: [discriminator loss: 0.579953, acc: 0.671875] [adversarial loss: 1.110976, acc: 0.218750]\n",
            "37218: [discriminator loss: 0.573492, acc: 0.671875] [adversarial loss: 0.875800, acc: 0.359375]\n",
            "37219: [discriminator loss: 0.621905, acc: 0.640625] [adversarial loss: 1.196734, acc: 0.265625]\n",
            "37220: [discriminator loss: 0.544786, acc: 0.703125] [adversarial loss: 0.956229, acc: 0.343750]\n",
            "37221: [discriminator loss: 0.633613, acc: 0.679688] [adversarial loss: 1.022251, acc: 0.328125]\n",
            "37222: [discriminator loss: 0.611792, acc: 0.625000] [adversarial loss: 0.911274, acc: 0.406250]\n",
            "37223: [discriminator loss: 0.587416, acc: 0.687500] [adversarial loss: 1.060306, acc: 0.375000]\n",
            "37224: [discriminator loss: 0.610424, acc: 0.664062] [adversarial loss: 0.889044, acc: 0.328125]\n",
            "37225: [discriminator loss: 0.594602, acc: 0.695312] [adversarial loss: 0.956597, acc: 0.375000]\n",
            "37226: [discriminator loss: 0.524047, acc: 0.703125] [adversarial loss: 1.064505, acc: 0.312500]\n",
            "37227: [discriminator loss: 0.568035, acc: 0.742188] [adversarial loss: 1.039912, acc: 0.281250]\n",
            "37228: [discriminator loss: 0.638053, acc: 0.648438] [adversarial loss: 1.234106, acc: 0.250000]\n",
            "37229: [discriminator loss: 0.676105, acc: 0.593750] [adversarial loss: 0.739391, acc: 0.609375]\n",
            "37230: [discriminator loss: 0.663397, acc: 0.601562] [adversarial loss: 1.177924, acc: 0.203125]\n",
            "37231: [discriminator loss: 0.554577, acc: 0.703125] [adversarial loss: 0.923714, acc: 0.328125]\n",
            "37232: [discriminator loss: 0.606634, acc: 0.656250] [adversarial loss: 1.213536, acc: 0.218750]\n",
            "37233: [discriminator loss: 0.525390, acc: 0.765625] [adversarial loss: 0.900495, acc: 0.390625]\n",
            "37234: [discriminator loss: 0.608753, acc: 0.664062] [adversarial loss: 1.350643, acc: 0.109375]\n",
            "37235: [discriminator loss: 0.585979, acc: 0.632812] [adversarial loss: 0.928516, acc: 0.343750]\n",
            "37236: [discriminator loss: 0.543742, acc: 0.695312] [adversarial loss: 1.017177, acc: 0.375000]\n",
            "37237: [discriminator loss: 0.508965, acc: 0.781250] [adversarial loss: 1.110467, acc: 0.203125]\n",
            "37238: [discriminator loss: 0.552142, acc: 0.703125] [adversarial loss: 1.041491, acc: 0.265625]\n",
            "37239: [discriminator loss: 0.531630, acc: 0.726562] [adversarial loss: 1.193016, acc: 0.218750]\n",
            "37240: [discriminator loss: 0.514736, acc: 0.750000] [adversarial loss: 0.945655, acc: 0.484375]\n",
            "37241: [discriminator loss: 0.569228, acc: 0.718750] [adversarial loss: 1.585477, acc: 0.156250]\n",
            "37242: [discriminator loss: 0.674268, acc: 0.617188] [adversarial loss: 0.744944, acc: 0.625000]\n",
            "37243: [discriminator loss: 0.656990, acc: 0.656250] [adversarial loss: 1.329005, acc: 0.109375]\n",
            "37244: [discriminator loss: 0.665659, acc: 0.585938] [adversarial loss: 0.923633, acc: 0.406250]\n",
            "37245: [discriminator loss: 0.624198, acc: 0.656250] [adversarial loss: 1.066493, acc: 0.250000]\n",
            "37246: [discriminator loss: 0.592438, acc: 0.664062] [adversarial loss: 0.877867, acc: 0.500000]\n",
            "37247: [discriminator loss: 0.533864, acc: 0.757812] [adversarial loss: 1.192765, acc: 0.218750]\n",
            "37248: [discriminator loss: 0.580185, acc: 0.710938] [adversarial loss: 1.039969, acc: 0.343750]\n",
            "37249: [discriminator loss: 0.582819, acc: 0.664062] [adversarial loss: 1.160459, acc: 0.171875]\n",
            "37250: [discriminator loss: 0.570404, acc: 0.656250] [adversarial loss: 0.910926, acc: 0.421875]\n",
            "37251: [discriminator loss: 0.560282, acc: 0.710938] [adversarial loss: 1.265097, acc: 0.203125]\n",
            "37252: [discriminator loss: 0.568558, acc: 0.695312] [adversarial loss: 0.903644, acc: 0.390625]\n",
            "37253: [discriminator loss: 0.594813, acc: 0.656250] [adversarial loss: 1.155772, acc: 0.218750]\n",
            "37254: [discriminator loss: 0.574262, acc: 0.710938] [adversarial loss: 1.204366, acc: 0.234375]\n",
            "37255: [discriminator loss: 0.599033, acc: 0.640625] [adversarial loss: 0.950049, acc: 0.359375]\n",
            "37256: [discriminator loss: 0.573057, acc: 0.710938] [adversarial loss: 1.059182, acc: 0.343750]\n",
            "37257: [discriminator loss: 0.619292, acc: 0.593750] [adversarial loss: 1.368300, acc: 0.125000]\n",
            "37258: [discriminator loss: 0.576087, acc: 0.734375] [adversarial loss: 0.889391, acc: 0.468750]\n",
            "37259: [discriminator loss: 0.596031, acc: 0.656250] [adversarial loss: 1.303822, acc: 0.156250]\n",
            "37260: [discriminator loss: 0.648814, acc: 0.632812] [adversarial loss: 0.836219, acc: 0.484375]\n",
            "37261: [discriminator loss: 0.609769, acc: 0.648438] [adversarial loss: 1.492269, acc: 0.156250]\n",
            "37262: [discriminator loss: 0.579030, acc: 0.710938] [adversarial loss: 0.978491, acc: 0.375000]\n",
            "37263: [discriminator loss: 0.595607, acc: 0.703125] [adversarial loss: 0.873564, acc: 0.468750]\n",
            "37264: [discriminator loss: 0.558956, acc: 0.734375] [adversarial loss: 1.260846, acc: 0.218750]\n",
            "37265: [discriminator loss: 0.570565, acc: 0.656250] [adversarial loss: 0.888785, acc: 0.343750]\n",
            "37266: [discriminator loss: 0.567130, acc: 0.703125] [adversarial loss: 1.093179, acc: 0.203125]\n",
            "37267: [discriminator loss: 0.602277, acc: 0.640625] [adversarial loss: 0.870385, acc: 0.453125]\n",
            "37268: [discriminator loss: 0.588896, acc: 0.656250] [adversarial loss: 1.240014, acc: 0.218750]\n",
            "37269: [discriminator loss: 0.612186, acc: 0.656250] [adversarial loss: 0.906412, acc: 0.390625]\n",
            "37270: [discriminator loss: 0.540312, acc: 0.742188] [adversarial loss: 1.115709, acc: 0.281250]\n",
            "37271: [discriminator loss: 0.569903, acc: 0.703125] [adversarial loss: 0.950275, acc: 0.421875]\n",
            "37272: [discriminator loss: 0.578549, acc: 0.742188] [adversarial loss: 1.127280, acc: 0.281250]\n",
            "37273: [discriminator loss: 0.492928, acc: 0.796875] [adversarial loss: 0.945275, acc: 0.406250]\n",
            "37274: [discriminator loss: 0.591272, acc: 0.648438] [adversarial loss: 1.164696, acc: 0.281250]\n",
            "37275: [discriminator loss: 0.578131, acc: 0.703125] [adversarial loss: 0.770130, acc: 0.515625]\n",
            "37276: [discriminator loss: 0.651361, acc: 0.609375] [adversarial loss: 1.391364, acc: 0.140625]\n",
            "37277: [discriminator loss: 0.645781, acc: 0.625000] [adversarial loss: 0.695128, acc: 0.562500]\n",
            "37278: [discriminator loss: 0.629142, acc: 0.632812] [adversarial loss: 1.177446, acc: 0.218750]\n",
            "37279: [discriminator loss: 0.589956, acc: 0.640625] [adversarial loss: 1.056270, acc: 0.328125]\n",
            "37280: [discriminator loss: 0.663050, acc: 0.640625] [adversarial loss: 1.018756, acc: 0.265625]\n",
            "37281: [discriminator loss: 0.576533, acc: 0.687500] [adversarial loss: 0.853525, acc: 0.468750]\n",
            "37282: [discriminator loss: 0.547336, acc: 0.710938] [adversarial loss: 1.011364, acc: 0.343750]\n",
            "37283: [discriminator loss: 0.578186, acc: 0.664062] [adversarial loss: 1.038146, acc: 0.343750]\n",
            "37284: [discriminator loss: 0.603005, acc: 0.695312] [adversarial loss: 0.982051, acc: 0.375000]\n",
            "37285: [discriminator loss: 0.562833, acc: 0.703125] [adversarial loss: 1.034928, acc: 0.265625]\n",
            "37286: [discriminator loss: 0.552211, acc: 0.703125] [adversarial loss: 1.026697, acc: 0.328125]\n",
            "37287: [discriminator loss: 0.632158, acc: 0.656250] [adversarial loss: 0.973244, acc: 0.359375]\n",
            "37288: [discriminator loss: 0.580513, acc: 0.679688] [adversarial loss: 1.175929, acc: 0.234375]\n",
            "37289: [discriminator loss: 0.524410, acc: 0.726562] [adversarial loss: 1.341115, acc: 0.109375]\n",
            "37290: [discriminator loss: 0.580454, acc: 0.718750] [adversarial loss: 1.261044, acc: 0.218750]\n",
            "37291: [discriminator loss: 0.585129, acc: 0.687500] [adversarial loss: 1.031513, acc: 0.296875]\n",
            "37292: [discriminator loss: 0.540347, acc: 0.726562] [adversarial loss: 1.466343, acc: 0.187500]\n",
            "37293: [discriminator loss: 0.617010, acc: 0.664062] [adversarial loss: 0.860963, acc: 0.375000]\n",
            "37294: [discriminator loss: 0.574207, acc: 0.726562] [adversarial loss: 1.127177, acc: 0.281250]\n",
            "37295: [discriminator loss: 0.559538, acc: 0.695312] [adversarial loss: 0.899279, acc: 0.500000]\n",
            "37296: [discriminator loss: 0.577127, acc: 0.742188] [adversarial loss: 1.583700, acc: 0.140625]\n",
            "37297: [discriminator loss: 0.617601, acc: 0.671875] [adversarial loss: 1.031325, acc: 0.406250]\n",
            "37298: [discriminator loss: 0.551985, acc: 0.726562] [adversarial loss: 1.159091, acc: 0.187500]\n",
            "37299: [discriminator loss: 0.629123, acc: 0.664062] [adversarial loss: 0.950894, acc: 0.406250]\n",
            "37300: [discriminator loss: 0.591937, acc: 0.671875] [adversarial loss: 1.067747, acc: 0.328125]\n",
            "37301: [discriminator loss: 0.556005, acc: 0.710938] [adversarial loss: 1.125729, acc: 0.250000]\n",
            "37302: [discriminator loss: 0.602882, acc: 0.625000] [adversarial loss: 0.944593, acc: 0.359375]\n",
            "37303: [discriminator loss: 0.538504, acc: 0.734375] [adversarial loss: 0.908200, acc: 0.578125]\n",
            "37304: [discriminator loss: 0.642601, acc: 0.625000] [adversarial loss: 1.041295, acc: 0.343750]\n",
            "37305: [discriminator loss: 0.600278, acc: 0.640625] [adversarial loss: 0.968510, acc: 0.328125]\n",
            "37306: [discriminator loss: 0.559230, acc: 0.703125] [adversarial loss: 1.221440, acc: 0.250000]\n",
            "37307: [discriminator loss: 0.535268, acc: 0.750000] [adversarial loss: 0.854153, acc: 0.406250]\n",
            "37308: [discriminator loss: 0.589513, acc: 0.671875] [adversarial loss: 1.101622, acc: 0.281250]\n",
            "37309: [discriminator loss: 0.595659, acc: 0.679688] [adversarial loss: 0.983322, acc: 0.296875]\n",
            "37310: [discriminator loss: 0.559019, acc: 0.710938] [adversarial loss: 1.097931, acc: 0.250000]\n",
            "37311: [discriminator loss: 0.637573, acc: 0.656250] [adversarial loss: 0.720468, acc: 0.515625]\n",
            "37312: [discriminator loss: 0.592585, acc: 0.679688] [adversarial loss: 1.470342, acc: 0.078125]\n",
            "37313: [discriminator loss: 0.627736, acc: 0.656250] [adversarial loss: 0.937110, acc: 0.390625]\n",
            "37314: [discriminator loss: 0.622722, acc: 0.648438] [adversarial loss: 1.251866, acc: 0.187500]\n",
            "37315: [discriminator loss: 0.585189, acc: 0.656250] [adversarial loss: 0.937093, acc: 0.421875]\n",
            "37316: [discriminator loss: 0.569913, acc: 0.734375] [adversarial loss: 1.082656, acc: 0.390625]\n",
            "37317: [discriminator loss: 0.634548, acc: 0.671875] [adversarial loss: 1.059428, acc: 0.343750]\n",
            "37318: [discriminator loss: 0.576691, acc: 0.695312] [adversarial loss: 0.970832, acc: 0.390625]\n",
            "37319: [discriminator loss: 0.540198, acc: 0.718750] [adversarial loss: 0.955655, acc: 0.343750]\n",
            "37320: [discriminator loss: 0.511772, acc: 0.789062] [adversarial loss: 1.228206, acc: 0.125000]\n",
            "37321: [discriminator loss: 0.599135, acc: 0.703125] [adversarial loss: 0.993566, acc: 0.328125]\n",
            "37322: [discriminator loss: 0.608313, acc: 0.656250] [adversarial loss: 1.191157, acc: 0.218750]\n",
            "37323: [discriminator loss: 0.602807, acc: 0.703125] [adversarial loss: 1.039935, acc: 0.421875]\n",
            "37324: [discriminator loss: 0.662175, acc: 0.640625] [adversarial loss: 0.842806, acc: 0.406250]\n",
            "37325: [discriminator loss: 0.637115, acc: 0.593750] [adversarial loss: 1.007626, acc: 0.328125]\n",
            "37326: [discriminator loss: 0.530690, acc: 0.718750] [adversarial loss: 1.029312, acc: 0.328125]\n",
            "37327: [discriminator loss: 0.623332, acc: 0.625000] [adversarial loss: 1.208034, acc: 0.203125]\n",
            "37328: [discriminator loss: 0.585427, acc: 0.703125] [adversarial loss: 0.993284, acc: 0.328125]\n",
            "37329: [discriminator loss: 0.559193, acc: 0.726562] [adversarial loss: 0.943469, acc: 0.375000]\n",
            "37330: [discriminator loss: 0.530007, acc: 0.726562] [adversarial loss: 1.394645, acc: 0.187500]\n",
            "37331: [discriminator loss: 0.515908, acc: 0.765625] [adversarial loss: 0.865229, acc: 0.453125]\n",
            "37332: [discriminator loss: 0.572194, acc: 0.695312] [adversarial loss: 1.278752, acc: 0.093750]\n",
            "37333: [discriminator loss: 0.644038, acc: 0.617188] [adversarial loss: 0.728174, acc: 0.562500]\n",
            "37334: [discriminator loss: 0.618710, acc: 0.625000] [adversarial loss: 1.205690, acc: 0.171875]\n",
            "37335: [discriminator loss: 0.625191, acc: 0.617188] [adversarial loss: 0.884719, acc: 0.437500]\n",
            "37336: [discriminator loss: 0.596881, acc: 0.679688] [adversarial loss: 1.142979, acc: 0.218750]\n",
            "37337: [discriminator loss: 0.562440, acc: 0.742188] [adversarial loss: 1.013413, acc: 0.281250]\n",
            "37338: [discriminator loss: 0.576954, acc: 0.695312] [adversarial loss: 1.233270, acc: 0.187500]\n",
            "37339: [discriminator loss: 0.559365, acc: 0.687500] [adversarial loss: 1.076987, acc: 0.343750]\n",
            "37340: [discriminator loss: 0.597438, acc: 0.671875] [adversarial loss: 1.153385, acc: 0.250000]\n",
            "37341: [discriminator loss: 0.555878, acc: 0.710938] [adversarial loss: 1.050575, acc: 0.359375]\n",
            "37342: [discriminator loss: 0.575844, acc: 0.664062] [adversarial loss: 1.144189, acc: 0.296875]\n",
            "37343: [discriminator loss: 0.597003, acc: 0.710938] [adversarial loss: 1.038255, acc: 0.281250]\n",
            "37344: [discriminator loss: 0.570606, acc: 0.656250] [adversarial loss: 1.292088, acc: 0.187500]\n",
            "37345: [discriminator loss: 0.591711, acc: 0.703125] [adversarial loss: 0.812096, acc: 0.484375]\n",
            "37346: [discriminator loss: 0.672925, acc: 0.593750] [adversarial loss: 1.231322, acc: 0.218750]\n",
            "37347: [discriminator loss: 0.638315, acc: 0.640625] [adversarial loss: 0.806853, acc: 0.453125]\n",
            "37348: [discriminator loss: 0.540481, acc: 0.750000] [adversarial loss: 1.207416, acc: 0.281250]\n",
            "37349: [discriminator loss: 0.562040, acc: 0.687500] [adversarial loss: 0.892805, acc: 0.453125]\n",
            "37350: [discriminator loss: 0.654798, acc: 0.609375] [adversarial loss: 1.053601, acc: 0.390625]\n",
            "37351: [discriminator loss: 0.561265, acc: 0.710938] [adversarial loss: 0.811861, acc: 0.484375]\n",
            "37352: [discriminator loss: 0.542474, acc: 0.703125] [adversarial loss: 1.232397, acc: 0.187500]\n",
            "37353: [discriminator loss: 0.580450, acc: 0.679688] [adversarial loss: 0.907619, acc: 0.375000]\n",
            "37354: [discriminator loss: 0.608694, acc: 0.648438] [adversarial loss: 0.995654, acc: 0.343750]\n",
            "37355: [discriminator loss: 0.575236, acc: 0.710938] [adversarial loss: 1.011584, acc: 0.234375]\n",
            "37356: [discriminator loss: 0.525188, acc: 0.734375] [adversarial loss: 0.913573, acc: 0.265625]\n",
            "37357: [discriminator loss: 0.590275, acc: 0.695312] [adversarial loss: 1.110758, acc: 0.203125]\n",
            "37358: [discriminator loss: 0.618310, acc: 0.695312] [adversarial loss: 0.878382, acc: 0.375000]\n",
            "37359: [discriminator loss: 0.544489, acc: 0.718750] [adversarial loss: 1.206270, acc: 0.140625]\n",
            "37360: [discriminator loss: 0.612930, acc: 0.671875] [adversarial loss: 0.833854, acc: 0.500000]\n",
            "37361: [discriminator loss: 0.543839, acc: 0.734375] [adversarial loss: 1.329445, acc: 0.265625]\n",
            "37362: [discriminator loss: 0.652855, acc: 0.625000] [adversarial loss: 0.836700, acc: 0.421875]\n",
            "37363: [discriminator loss: 0.611214, acc: 0.648438] [adversarial loss: 1.180650, acc: 0.234375]\n",
            "37364: [discriminator loss: 0.579265, acc: 0.632812] [adversarial loss: 0.817154, acc: 0.468750]\n",
            "37365: [discriminator loss: 0.571199, acc: 0.687500] [adversarial loss: 1.280497, acc: 0.140625]\n",
            "37366: [discriminator loss: 0.581655, acc: 0.664062] [adversarial loss: 0.904455, acc: 0.406250]\n",
            "37367: [discriminator loss: 0.576950, acc: 0.679688] [adversarial loss: 1.372170, acc: 0.156250]\n",
            "37368: [discriminator loss: 0.607256, acc: 0.601562] [adversarial loss: 0.954642, acc: 0.421875]\n",
            "37369: [discriminator loss: 0.576889, acc: 0.710938] [adversarial loss: 1.253201, acc: 0.234375]\n",
            "37370: [discriminator loss: 0.610427, acc: 0.703125] [adversarial loss: 1.211610, acc: 0.234375]\n",
            "37371: [discriminator loss: 0.566467, acc: 0.671875] [adversarial loss: 0.744354, acc: 0.562500]\n",
            "37372: [discriminator loss: 0.646356, acc: 0.617188] [adversarial loss: 1.363824, acc: 0.093750]\n",
            "37373: [discriminator loss: 0.614702, acc: 0.640625] [adversarial loss: 0.766677, acc: 0.500000]\n",
            "37374: [discriminator loss: 0.666718, acc: 0.609375] [adversarial loss: 1.201926, acc: 0.203125]\n",
            "37375: [discriminator loss: 0.552354, acc: 0.710938] [adversarial loss: 0.860261, acc: 0.453125]\n",
            "37376: [discriminator loss: 0.629012, acc: 0.632812] [adversarial loss: 1.071828, acc: 0.296875]\n",
            "37377: [discriminator loss: 0.572364, acc: 0.695312] [adversarial loss: 1.058269, acc: 0.375000]\n",
            "37378: [discriminator loss: 0.539507, acc: 0.765625] [adversarial loss: 1.056615, acc: 0.375000]\n",
            "37379: [discriminator loss: 0.536526, acc: 0.695312] [adversarial loss: 1.162802, acc: 0.234375]\n",
            "37380: [discriminator loss: 0.570295, acc: 0.695312] [adversarial loss: 1.229896, acc: 0.234375]\n",
            "37381: [discriminator loss: 0.610007, acc: 0.625000] [adversarial loss: 0.956042, acc: 0.406250]\n",
            "37382: [discriminator loss: 0.603449, acc: 0.664062] [adversarial loss: 1.215832, acc: 0.187500]\n",
            "37383: [discriminator loss: 0.553349, acc: 0.742188] [adversarial loss: 1.168121, acc: 0.281250]\n",
            "37384: [discriminator loss: 0.589213, acc: 0.679688] [adversarial loss: 1.137115, acc: 0.234375]\n",
            "37385: [discriminator loss: 0.634021, acc: 0.679688] [adversarial loss: 0.986264, acc: 0.421875]\n",
            "37386: [discriminator loss: 0.618122, acc: 0.664062] [adversarial loss: 1.028182, acc: 0.375000]\n",
            "37387: [discriminator loss: 0.507690, acc: 0.750000] [adversarial loss: 1.320987, acc: 0.218750]\n",
            "37388: [discriminator loss: 0.568727, acc: 0.664062] [adversarial loss: 0.885904, acc: 0.390625]\n",
            "37389: [discriminator loss: 0.637625, acc: 0.679688] [adversarial loss: 1.247036, acc: 0.156250]\n",
            "37390: [discriminator loss: 0.567940, acc: 0.695312] [adversarial loss: 0.777461, acc: 0.500000]\n",
            "37391: [discriminator loss: 0.610828, acc: 0.687500] [adversarial loss: 1.268968, acc: 0.234375]\n",
            "37392: [discriminator loss: 0.571263, acc: 0.695312] [adversarial loss: 1.019938, acc: 0.343750]\n",
            "37393: [discriminator loss: 0.570982, acc: 0.695312] [adversarial loss: 0.975833, acc: 0.328125]\n",
            "37394: [discriminator loss: 0.628306, acc: 0.640625] [adversarial loss: 1.238411, acc: 0.156250]\n",
            "37395: [discriminator loss: 0.578431, acc: 0.695312] [adversarial loss: 1.031813, acc: 0.343750]\n",
            "37396: [discriminator loss: 0.626674, acc: 0.656250] [adversarial loss: 1.137872, acc: 0.156250]\n",
            "37397: [discriminator loss: 0.615005, acc: 0.687500] [adversarial loss: 0.920789, acc: 0.390625]\n",
            "37398: [discriminator loss: 0.535704, acc: 0.726562] [adversarial loss: 0.851766, acc: 0.406250]\n",
            "37399: [discriminator loss: 0.571781, acc: 0.656250] [adversarial loss: 1.101120, acc: 0.328125]\n",
            "37400: [discriminator loss: 0.528079, acc: 0.757812] [adversarial loss: 1.195816, acc: 0.203125]\n",
            "37401: [discriminator loss: 0.543029, acc: 0.710938] [adversarial loss: 0.904838, acc: 0.406250]\n",
            "37402: [discriminator loss: 0.526856, acc: 0.726562] [adversarial loss: 1.092464, acc: 0.312500]\n",
            "37403: [discriminator loss: 0.628147, acc: 0.679688] [adversarial loss: 1.198776, acc: 0.218750]\n",
            "37404: [discriminator loss: 0.612916, acc: 0.632812] [adversarial loss: 0.883375, acc: 0.375000]\n",
            "37405: [discriminator loss: 0.532186, acc: 0.718750] [adversarial loss: 1.175834, acc: 0.265625]\n",
            "37406: [discriminator loss: 0.563218, acc: 0.648438] [adversarial loss: 0.984259, acc: 0.296875]\n",
            "37407: [discriminator loss: 0.559344, acc: 0.757812] [adversarial loss: 1.400658, acc: 0.250000]\n",
            "37408: [discriminator loss: 0.616740, acc: 0.679688] [adversarial loss: 0.790266, acc: 0.453125]\n",
            "37409: [discriminator loss: 0.540016, acc: 0.750000] [adversarial loss: 1.257640, acc: 0.203125]\n",
            "37410: [discriminator loss: 0.604780, acc: 0.695312] [adversarial loss: 0.937163, acc: 0.468750]\n",
            "37411: [discriminator loss: 0.627769, acc: 0.640625] [adversarial loss: 0.985718, acc: 0.390625]\n",
            "37412: [discriminator loss: 0.545871, acc: 0.726562] [adversarial loss: 1.031358, acc: 0.281250]\n",
            "37413: [discriminator loss: 0.571116, acc: 0.726562] [adversarial loss: 1.374427, acc: 0.187500]\n",
            "37414: [discriminator loss: 0.541714, acc: 0.726562] [adversarial loss: 1.029706, acc: 0.328125]\n",
            "37415: [discriminator loss: 0.560097, acc: 0.703125] [adversarial loss: 1.078259, acc: 0.265625]\n",
            "37416: [discriminator loss: 0.525734, acc: 0.718750] [adversarial loss: 1.063251, acc: 0.218750]\n",
            "37417: [discriminator loss: 0.586680, acc: 0.679688] [adversarial loss: 0.942631, acc: 0.453125]\n",
            "37418: [discriminator loss: 0.626254, acc: 0.632812] [adversarial loss: 1.056390, acc: 0.250000]\n",
            "37419: [discriminator loss: 0.541707, acc: 0.687500] [adversarial loss: 1.178889, acc: 0.296875]\n",
            "37420: [discriminator loss: 0.506584, acc: 0.742188] [adversarial loss: 0.660280, acc: 0.625000]\n",
            "37421: [discriminator loss: 0.682579, acc: 0.593750] [adversarial loss: 1.307353, acc: 0.187500]\n",
            "37422: [discriminator loss: 0.640707, acc: 0.664062] [adversarial loss: 0.690714, acc: 0.562500]\n",
            "37423: [discriminator loss: 0.628510, acc: 0.656250] [adversarial loss: 1.299842, acc: 0.125000]\n",
            "37424: [discriminator loss: 0.615305, acc: 0.609375] [adversarial loss: 0.914325, acc: 0.421875]\n",
            "37425: [discriminator loss: 0.629796, acc: 0.640625] [adversarial loss: 1.356304, acc: 0.125000]\n",
            "37426: [discriminator loss: 0.553671, acc: 0.718750] [adversarial loss: 0.984507, acc: 0.390625]\n",
            "37427: [discriminator loss: 0.578008, acc: 0.726562] [adversarial loss: 0.892472, acc: 0.437500]\n",
            "37428: [discriminator loss: 0.630682, acc: 0.679688] [adversarial loss: 1.271034, acc: 0.109375]\n",
            "37429: [discriminator loss: 0.533819, acc: 0.679688] [adversarial loss: 0.854235, acc: 0.531250]\n",
            "37430: [discriminator loss: 0.538135, acc: 0.718750] [adversarial loss: 1.229641, acc: 0.187500]\n",
            "37431: [discriminator loss: 0.560091, acc: 0.718750] [adversarial loss: 1.069085, acc: 0.281250]\n",
            "37432: [discriminator loss: 0.565279, acc: 0.726562] [adversarial loss: 1.115837, acc: 0.343750]\n",
            "37433: [discriminator loss: 0.535390, acc: 0.703125] [adversarial loss: 0.979803, acc: 0.406250]\n",
            "37434: [discriminator loss: 0.562319, acc: 0.695312] [adversarial loss: 1.199841, acc: 0.218750]\n",
            "37435: [discriminator loss: 0.619277, acc: 0.679688] [adversarial loss: 1.241339, acc: 0.265625]\n",
            "37436: [discriminator loss: 0.540382, acc: 0.726562] [adversarial loss: 0.976544, acc: 0.343750]\n",
            "37437: [discriminator loss: 0.548994, acc: 0.695312] [adversarial loss: 1.292439, acc: 0.218750]\n",
            "37438: [discriminator loss: 0.616676, acc: 0.625000] [adversarial loss: 1.026794, acc: 0.265625]\n",
            "37439: [discriminator loss: 0.602148, acc: 0.625000] [adversarial loss: 1.090806, acc: 0.281250]\n",
            "37440: [discriminator loss: 0.521296, acc: 0.765625] [adversarial loss: 0.984591, acc: 0.468750]\n",
            "37441: [discriminator loss: 0.605929, acc: 0.640625] [adversarial loss: 1.258458, acc: 0.234375]\n",
            "37442: [discriminator loss: 0.551412, acc: 0.726562] [adversarial loss: 0.989010, acc: 0.328125]\n",
            "37443: [discriminator loss: 0.550669, acc: 0.726562] [adversarial loss: 1.181080, acc: 0.234375]\n",
            "37444: [discriminator loss: 0.622465, acc: 0.632812] [adversarial loss: 0.853668, acc: 0.437500]\n",
            "37445: [discriminator loss: 0.560109, acc: 0.695312] [adversarial loss: 1.106752, acc: 0.234375]\n",
            "37446: [discriminator loss: 0.600876, acc: 0.664062] [adversarial loss: 0.977658, acc: 0.375000]\n",
            "37447: [discriminator loss: 0.611931, acc: 0.664062] [adversarial loss: 1.154208, acc: 0.187500]\n",
            "37448: [discriminator loss: 0.585691, acc: 0.695312] [adversarial loss: 1.168899, acc: 0.171875]\n",
            "37449: [discriminator loss: 0.624272, acc: 0.601562] [adversarial loss: 1.122137, acc: 0.265625]\n",
            "37450: [discriminator loss: 0.600595, acc: 0.695312] [adversarial loss: 1.017057, acc: 0.343750]\n",
            "37451: [discriminator loss: 0.578884, acc: 0.734375] [adversarial loss: 1.053249, acc: 0.281250]\n",
            "37452: [discriminator loss: 0.597607, acc: 0.656250] [adversarial loss: 1.149622, acc: 0.203125]\n",
            "37453: [discriminator loss: 0.529143, acc: 0.734375] [adversarial loss: 1.128009, acc: 0.218750]\n",
            "37454: [discriminator loss: 0.579744, acc: 0.656250] [adversarial loss: 0.889274, acc: 0.515625]\n",
            "37455: [discriminator loss: 0.608156, acc: 0.609375] [adversarial loss: 1.551141, acc: 0.109375]\n",
            "37456: [discriminator loss: 0.595317, acc: 0.671875] [adversarial loss: 1.021371, acc: 0.406250]\n",
            "37457: [discriminator loss: 0.538339, acc: 0.734375] [adversarial loss: 1.128783, acc: 0.265625]\n",
            "37458: [discriminator loss: 0.660419, acc: 0.671875] [adversarial loss: 1.291200, acc: 0.203125]\n",
            "37459: [discriminator loss: 0.549064, acc: 0.687500] [adversarial loss: 0.985072, acc: 0.359375]\n",
            "37460: [discriminator loss: 0.590533, acc: 0.695312] [adversarial loss: 0.934505, acc: 0.343750]\n",
            "37461: [discriminator loss: 0.556914, acc: 0.679688] [adversarial loss: 1.228155, acc: 0.187500]\n",
            "37462: [discriminator loss: 0.645085, acc: 0.656250] [adversarial loss: 0.819055, acc: 0.453125]\n",
            "37463: [discriminator loss: 0.546971, acc: 0.687500] [adversarial loss: 1.210326, acc: 0.218750]\n",
            "37464: [discriminator loss: 0.561351, acc: 0.679688] [adversarial loss: 0.814446, acc: 0.515625]\n",
            "37465: [discriminator loss: 0.665975, acc: 0.609375] [adversarial loss: 1.132686, acc: 0.203125]\n",
            "37466: [discriminator loss: 0.555849, acc: 0.726562] [adversarial loss: 1.129582, acc: 0.218750]\n",
            "37467: [discriminator loss: 0.580422, acc: 0.664062] [adversarial loss: 1.123879, acc: 0.250000]\n",
            "37468: [discriminator loss: 0.630472, acc: 0.656250] [adversarial loss: 0.949815, acc: 0.343750]\n",
            "37469: [discriminator loss: 0.534667, acc: 0.679688] [adversarial loss: 1.227410, acc: 0.125000]\n",
            "37470: [discriminator loss: 0.588856, acc: 0.703125] [adversarial loss: 1.182821, acc: 0.234375]\n",
            "37471: [discriminator loss: 0.569769, acc: 0.695312] [adversarial loss: 1.120667, acc: 0.250000]\n",
            "37472: [discriminator loss: 0.593209, acc: 0.664062] [adversarial loss: 1.187385, acc: 0.203125]\n",
            "37473: [discriminator loss: 0.589828, acc: 0.671875] [adversarial loss: 1.216634, acc: 0.218750]\n",
            "37474: [discriminator loss: 0.624174, acc: 0.648438] [adversarial loss: 0.876722, acc: 0.421875]\n",
            "37475: [discriminator loss: 0.551550, acc: 0.726562] [adversarial loss: 1.094775, acc: 0.234375]\n",
            "37476: [discriminator loss: 0.552627, acc: 0.734375] [adversarial loss: 1.018690, acc: 0.406250]\n",
            "37477: [discriminator loss: 0.610615, acc: 0.664062] [adversarial loss: 1.116009, acc: 0.218750]\n",
            "37478: [discriminator loss: 0.613163, acc: 0.664062] [adversarial loss: 0.790234, acc: 0.437500]\n",
            "37479: [discriminator loss: 0.618304, acc: 0.671875] [adversarial loss: 1.162384, acc: 0.343750]\n",
            "37480: [discriminator loss: 0.564660, acc: 0.710938] [adversarial loss: 0.722224, acc: 0.546875]\n",
            "37481: [discriminator loss: 0.630054, acc: 0.625000] [adversarial loss: 1.476632, acc: 0.125000]\n",
            "37482: [discriminator loss: 0.632443, acc: 0.656250] [adversarial loss: 0.931610, acc: 0.437500]\n",
            "37483: [discriminator loss: 0.567516, acc: 0.710938] [adversarial loss: 1.200793, acc: 0.203125]\n",
            "37484: [discriminator loss: 0.639327, acc: 0.656250] [adversarial loss: 0.986884, acc: 0.281250]\n",
            "37485: [discriminator loss: 0.525047, acc: 0.757812] [adversarial loss: 1.214950, acc: 0.250000]\n",
            "37486: [discriminator loss: 0.462353, acc: 0.781250] [adversarial loss: 1.072041, acc: 0.375000]\n",
            "37487: [discriminator loss: 0.587574, acc: 0.664062] [adversarial loss: 1.353663, acc: 0.171875]\n",
            "37488: [discriminator loss: 0.545235, acc: 0.742188] [adversarial loss: 1.197884, acc: 0.187500]\n",
            "37489: [discriminator loss: 0.605810, acc: 0.632812] [adversarial loss: 0.950568, acc: 0.343750]\n",
            "37490: [discriminator loss: 0.534227, acc: 0.742188] [adversarial loss: 1.209483, acc: 0.234375]\n",
            "37491: [discriminator loss: 0.506045, acc: 0.742188] [adversarial loss: 0.940701, acc: 0.375000]\n",
            "37492: [discriminator loss: 0.543306, acc: 0.679688] [adversarial loss: 1.042698, acc: 0.359375]\n",
            "37493: [discriminator loss: 0.564364, acc: 0.710938] [adversarial loss: 1.138473, acc: 0.296875]\n",
            "37494: [discriminator loss: 0.660912, acc: 0.625000] [adversarial loss: 1.005445, acc: 0.390625]\n",
            "37495: [discriminator loss: 0.599596, acc: 0.718750] [adversarial loss: 1.224887, acc: 0.234375]\n",
            "37496: [discriminator loss: 0.571387, acc: 0.710938] [adversarial loss: 0.746470, acc: 0.593750]\n",
            "37497: [discriminator loss: 0.626646, acc: 0.656250] [adversarial loss: 1.442438, acc: 0.125000]\n",
            "37498: [discriminator loss: 0.631027, acc: 0.601562] [adversarial loss: 0.882041, acc: 0.406250]\n",
            "37499: [discriminator loss: 0.566823, acc: 0.695312] [adversarial loss: 1.147763, acc: 0.296875]\n",
            "37500: [discriminator loss: 0.569202, acc: 0.687500] [adversarial loss: 1.065586, acc: 0.343750]\n",
            "37501: [discriminator loss: 0.560302, acc: 0.742188] [adversarial loss: 1.064859, acc: 0.296875]\n",
            "37502: [discriminator loss: 0.590116, acc: 0.695312] [adversarial loss: 1.089010, acc: 0.312500]\n",
            "37503: [discriminator loss: 0.614243, acc: 0.656250] [adversarial loss: 1.298109, acc: 0.234375]\n",
            "37504: [discriminator loss: 0.545373, acc: 0.750000] [adversarial loss: 0.889712, acc: 0.390625]\n",
            "37505: [discriminator loss: 0.580274, acc: 0.671875] [adversarial loss: 1.220038, acc: 0.187500]\n",
            "37506: [discriminator loss: 0.633283, acc: 0.664062] [adversarial loss: 0.918459, acc: 0.375000]\n",
            "37507: [discriminator loss: 0.569445, acc: 0.671875] [adversarial loss: 0.937894, acc: 0.390625]\n",
            "37508: [discriminator loss: 0.599393, acc: 0.656250] [adversarial loss: 1.142394, acc: 0.296875]\n",
            "37509: [discriminator loss: 0.635347, acc: 0.625000] [adversarial loss: 1.160909, acc: 0.265625]\n",
            "37510: [discriminator loss: 0.521652, acc: 0.757812] [adversarial loss: 0.965041, acc: 0.406250]\n",
            "37511: [discriminator loss: 0.521817, acc: 0.734375] [adversarial loss: 0.966503, acc: 0.328125]\n",
            "37512: [discriminator loss: 0.650331, acc: 0.617188] [adversarial loss: 1.178504, acc: 0.234375]\n",
            "37513: [discriminator loss: 0.564265, acc: 0.679688] [adversarial loss: 0.950449, acc: 0.359375]\n",
            "37514: [discriminator loss: 0.532990, acc: 0.726562] [adversarial loss: 1.114410, acc: 0.343750]\n",
            "37515: [discriminator loss: 0.601095, acc: 0.679688] [adversarial loss: 1.357131, acc: 0.187500]\n",
            "37516: [discriminator loss: 0.535164, acc: 0.734375] [adversarial loss: 1.021527, acc: 0.234375]\n",
            "37517: [discriminator loss: 0.634991, acc: 0.671875] [adversarial loss: 1.281867, acc: 0.109375]\n",
            "37518: [discriminator loss: 0.520961, acc: 0.750000] [adversarial loss: 0.982556, acc: 0.390625]\n",
            "37519: [discriminator loss: 0.574603, acc: 0.687500] [adversarial loss: 1.070521, acc: 0.296875]\n",
            "37520: [discriminator loss: 0.595885, acc: 0.726562] [adversarial loss: 0.833787, acc: 0.359375]\n",
            "37521: [discriminator loss: 0.506842, acc: 0.773438] [adversarial loss: 0.916286, acc: 0.359375]\n",
            "37522: [discriminator loss: 0.559029, acc: 0.695312] [adversarial loss: 1.380268, acc: 0.156250]\n",
            "37523: [discriminator loss: 0.567907, acc: 0.671875] [adversarial loss: 0.999701, acc: 0.343750]\n",
            "37524: [discriminator loss: 0.642575, acc: 0.664062] [adversarial loss: 1.211397, acc: 0.187500]\n",
            "37525: [discriminator loss: 0.665898, acc: 0.632812] [adversarial loss: 0.739251, acc: 0.546875]\n",
            "37526: [discriminator loss: 0.583906, acc: 0.703125] [adversarial loss: 1.349141, acc: 0.109375]\n",
            "37527: [discriminator loss: 0.548765, acc: 0.718750] [adversarial loss: 0.821529, acc: 0.515625]\n",
            "37528: [discriminator loss: 0.601636, acc: 0.664062] [adversarial loss: 1.237739, acc: 0.156250]\n",
            "37529: [discriminator loss: 0.535498, acc: 0.726562] [adversarial loss: 1.090637, acc: 0.296875]\n",
            "37530: [discriminator loss: 0.594715, acc: 0.679688] [adversarial loss: 1.157598, acc: 0.281250]\n",
            "37531: [discriminator loss: 0.571678, acc: 0.742188] [adversarial loss: 0.941075, acc: 0.343750]\n",
            "37532: [discriminator loss: 0.573573, acc: 0.679688] [adversarial loss: 1.116160, acc: 0.218750]\n",
            "37533: [discriminator loss: 0.569587, acc: 0.687500] [adversarial loss: 0.821573, acc: 0.468750]\n",
            "37534: [discriminator loss: 0.583833, acc: 0.710938] [adversarial loss: 0.873191, acc: 0.406250]\n",
            "37535: [discriminator loss: 0.555806, acc: 0.742188] [adversarial loss: 1.309162, acc: 0.156250]\n",
            "37536: [discriminator loss: 0.625324, acc: 0.625000] [adversarial loss: 0.782221, acc: 0.515625]\n",
            "37537: [discriminator loss: 0.610147, acc: 0.671875] [adversarial loss: 1.245625, acc: 0.218750]\n",
            "37538: [discriminator loss: 0.604386, acc: 0.656250] [adversarial loss: 0.895665, acc: 0.390625]\n",
            "37539: [discriminator loss: 0.594001, acc: 0.679688] [adversarial loss: 1.071822, acc: 0.312500]\n",
            "37540: [discriminator loss: 0.602478, acc: 0.664062] [adversarial loss: 1.014191, acc: 0.312500]\n",
            "37541: [discriminator loss: 0.593357, acc: 0.750000] [adversarial loss: 1.191220, acc: 0.312500]\n",
            "37542: [discriminator loss: 0.546384, acc: 0.742188] [adversarial loss: 0.914839, acc: 0.406250]\n",
            "37543: [discriminator loss: 0.601582, acc: 0.648438] [adversarial loss: 0.937898, acc: 0.296875]\n",
            "37544: [discriminator loss: 0.549073, acc: 0.710938] [adversarial loss: 1.208936, acc: 0.140625]\n",
            "37545: [discriminator loss: 0.521780, acc: 0.734375] [adversarial loss: 0.784435, acc: 0.546875]\n",
            "37546: [discriminator loss: 0.574071, acc: 0.710938] [adversarial loss: 1.032015, acc: 0.312500]\n",
            "37547: [discriminator loss: 0.665187, acc: 0.648438] [adversarial loss: 0.930393, acc: 0.390625]\n",
            "37548: [discriminator loss: 0.542256, acc: 0.750000] [adversarial loss: 0.942203, acc: 0.406250]\n",
            "37549: [discriminator loss: 0.540810, acc: 0.718750] [adversarial loss: 1.201469, acc: 0.265625]\n",
            "37550: [discriminator loss: 0.605853, acc: 0.664062] [adversarial loss: 0.926715, acc: 0.468750]\n",
            "37551: [discriminator loss: 0.599734, acc: 0.664062] [adversarial loss: 1.262654, acc: 0.203125]\n",
            "37552: [discriminator loss: 0.608328, acc: 0.625000] [adversarial loss: 0.916157, acc: 0.343750]\n",
            "37553: [discriminator loss: 0.614685, acc: 0.664062] [adversarial loss: 1.240466, acc: 0.234375]\n",
            "37554: [discriminator loss: 0.531233, acc: 0.726562] [adversarial loss: 1.141211, acc: 0.312500]\n",
            "37555: [discriminator loss: 0.553136, acc: 0.734375] [adversarial loss: 1.143131, acc: 0.375000]\n",
            "37556: [discriminator loss: 0.568836, acc: 0.679688] [adversarial loss: 1.387759, acc: 0.140625]\n",
            "37557: [discriminator loss: 0.563496, acc: 0.664062] [adversarial loss: 0.689056, acc: 0.562500]\n",
            "37558: [discriminator loss: 0.602962, acc: 0.687500] [adversarial loss: 1.410987, acc: 0.062500]\n",
            "37559: [discriminator loss: 0.585646, acc: 0.679688] [adversarial loss: 0.695382, acc: 0.578125]\n",
            "37560: [discriminator loss: 0.553087, acc: 0.679688] [adversarial loss: 1.207389, acc: 0.234375]\n",
            "37561: [discriminator loss: 0.547241, acc: 0.718750] [adversarial loss: 1.058601, acc: 0.296875]\n",
            "37562: [discriminator loss: 0.560630, acc: 0.695312] [adversarial loss: 1.307930, acc: 0.250000]\n",
            "37563: [discriminator loss: 0.532304, acc: 0.718750] [adversarial loss: 1.051839, acc: 0.281250]\n",
            "37564: [discriminator loss: 0.530830, acc: 0.734375] [adversarial loss: 0.923775, acc: 0.421875]\n",
            "37565: [discriminator loss: 0.506568, acc: 0.765625] [adversarial loss: 1.151169, acc: 0.265625]\n",
            "37566: [discriminator loss: 0.615437, acc: 0.664062] [adversarial loss: 1.151316, acc: 0.265625]\n",
            "37567: [discriminator loss: 0.545573, acc: 0.726562] [adversarial loss: 1.191390, acc: 0.250000]\n",
            "37568: [discriminator loss: 0.598798, acc: 0.679688] [adversarial loss: 1.308824, acc: 0.156250]\n",
            "37569: [discriminator loss: 0.619943, acc: 0.632812] [adversarial loss: 0.814573, acc: 0.609375]\n",
            "37570: [discriminator loss: 0.588383, acc: 0.703125] [adversarial loss: 1.415492, acc: 0.125000]\n",
            "37571: [discriminator loss: 0.537402, acc: 0.710938] [adversarial loss: 1.025880, acc: 0.218750]\n",
            "37572: [discriminator loss: 0.589867, acc: 0.609375] [adversarial loss: 1.314410, acc: 0.140625]\n",
            "37573: [discriminator loss: 0.644636, acc: 0.601562] [adversarial loss: 1.040526, acc: 0.421875]\n",
            "37574: [discriminator loss: 0.549551, acc: 0.703125] [adversarial loss: 1.247481, acc: 0.156250]\n",
            "37575: [discriminator loss: 0.621549, acc: 0.640625] [adversarial loss: 0.972656, acc: 0.390625]\n",
            "37576: [discriminator loss: 0.545832, acc: 0.695312] [adversarial loss: 1.115813, acc: 0.250000]\n",
            "37577: [discriminator loss: 0.657150, acc: 0.632812] [adversarial loss: 0.938556, acc: 0.390625]\n",
            "37578: [discriminator loss: 0.584881, acc: 0.703125] [adversarial loss: 1.030410, acc: 0.312500]\n",
            "37579: [discriminator loss: 0.550030, acc: 0.687500] [adversarial loss: 1.009664, acc: 0.375000]\n",
            "37580: [discriminator loss: 0.563970, acc: 0.687500] [adversarial loss: 1.105325, acc: 0.296875]\n",
            "37581: [discriminator loss: 0.531830, acc: 0.750000] [adversarial loss: 1.167355, acc: 0.187500]\n",
            "37582: [discriminator loss: 0.546615, acc: 0.734375] [adversarial loss: 1.105379, acc: 0.265625]\n",
            "37583: [discriminator loss: 0.571739, acc: 0.695312] [adversarial loss: 1.084815, acc: 0.328125]\n",
            "37584: [discriminator loss: 0.592173, acc: 0.695312] [adversarial loss: 0.989457, acc: 0.250000]\n",
            "37585: [discriminator loss: 0.584000, acc: 0.703125] [adversarial loss: 1.073575, acc: 0.328125]\n",
            "37586: [discriminator loss: 0.598614, acc: 0.671875] [adversarial loss: 1.017241, acc: 0.343750]\n",
            "37587: [discriminator loss: 0.574840, acc: 0.718750] [adversarial loss: 1.177482, acc: 0.250000]\n",
            "37588: [discriminator loss: 0.586272, acc: 0.664062] [adversarial loss: 0.858216, acc: 0.484375]\n",
            "37589: [discriminator loss: 0.569105, acc: 0.687500] [adversarial loss: 1.455675, acc: 0.203125]\n",
            "37590: [discriminator loss: 0.637700, acc: 0.625000] [adversarial loss: 0.696895, acc: 0.593750]\n",
            "37591: [discriminator loss: 0.685740, acc: 0.601562] [adversarial loss: 1.484009, acc: 0.078125]\n",
            "37592: [discriminator loss: 0.565804, acc: 0.671875] [adversarial loss: 1.109967, acc: 0.296875]\n",
            "37593: [discriminator loss: 0.583847, acc: 0.687500] [adversarial loss: 1.015894, acc: 0.343750]\n",
            "37594: [discriminator loss: 0.604012, acc: 0.664062] [adversarial loss: 1.101817, acc: 0.296875]\n",
            "37595: [discriminator loss: 0.601802, acc: 0.671875] [adversarial loss: 1.113579, acc: 0.390625]\n",
            "37596: [discriminator loss: 0.628680, acc: 0.640625] [adversarial loss: 1.050542, acc: 0.328125]\n",
            "37597: [discriminator loss: 0.657736, acc: 0.585938] [adversarial loss: 1.127579, acc: 0.359375]\n",
            "37598: [discriminator loss: 0.585547, acc: 0.679688] [adversarial loss: 1.172265, acc: 0.218750]\n",
            "37599: [discriminator loss: 0.539201, acc: 0.750000] [adversarial loss: 0.859481, acc: 0.437500]\n",
            "37600: [discriminator loss: 0.521428, acc: 0.734375] [adversarial loss: 1.230458, acc: 0.156250]\n",
            "37601: [discriminator loss: 0.581362, acc: 0.710938] [adversarial loss: 0.838605, acc: 0.406250]\n",
            "37602: [discriminator loss: 0.601447, acc: 0.671875] [adversarial loss: 1.224936, acc: 0.187500]\n",
            "37603: [discriminator loss: 0.627074, acc: 0.617188] [adversarial loss: 0.923637, acc: 0.343750]\n",
            "37604: [discriminator loss: 0.532660, acc: 0.742188] [adversarial loss: 1.290983, acc: 0.156250]\n",
            "37605: [discriminator loss: 0.596570, acc: 0.656250] [adversarial loss: 1.006529, acc: 0.250000]\n",
            "37606: [discriminator loss: 0.581711, acc: 0.671875] [adversarial loss: 1.097401, acc: 0.218750]\n",
            "37607: [discriminator loss: 0.546713, acc: 0.718750] [adversarial loss: 0.973231, acc: 0.468750]\n",
            "37608: [discriminator loss: 0.620206, acc: 0.656250] [adversarial loss: 1.107822, acc: 0.281250]\n",
            "37609: [discriminator loss: 0.605787, acc: 0.671875] [adversarial loss: 1.171662, acc: 0.203125]\n",
            "37610: [discriminator loss: 0.637587, acc: 0.648438] [adversarial loss: 1.113922, acc: 0.250000]\n",
            "37611: [discriminator loss: 0.628502, acc: 0.640625] [adversarial loss: 0.973712, acc: 0.328125]\n",
            "37612: [discriminator loss: 0.560215, acc: 0.734375] [adversarial loss: 1.049160, acc: 0.296875]\n",
            "37613: [discriminator loss: 0.584603, acc: 0.710938] [adversarial loss: 1.105865, acc: 0.234375]\n",
            "37614: [discriminator loss: 0.615731, acc: 0.710938] [adversarial loss: 1.034269, acc: 0.328125]\n",
            "37615: [discriminator loss: 0.545816, acc: 0.726562] [adversarial loss: 1.141726, acc: 0.234375]\n",
            "37616: [discriminator loss: 0.640599, acc: 0.617188] [adversarial loss: 0.899196, acc: 0.437500]\n",
            "37617: [discriminator loss: 0.607649, acc: 0.632812] [adversarial loss: 1.388026, acc: 0.156250]\n",
            "37618: [discriminator loss: 0.565668, acc: 0.679688] [adversarial loss: 0.756820, acc: 0.546875]\n",
            "37619: [discriminator loss: 0.615005, acc: 0.632812] [adversarial loss: 1.296854, acc: 0.187500]\n",
            "37620: [discriminator loss: 0.619361, acc: 0.617188] [adversarial loss: 0.905417, acc: 0.437500]\n",
            "37621: [discriminator loss: 0.602631, acc: 0.617188] [adversarial loss: 1.309868, acc: 0.156250]\n",
            "37622: [discriminator loss: 0.577169, acc: 0.656250] [adversarial loss: 1.004284, acc: 0.359375]\n",
            "37623: [discriminator loss: 0.620338, acc: 0.640625] [adversarial loss: 1.108732, acc: 0.234375]\n",
            "37624: [discriminator loss: 0.565211, acc: 0.664062] [adversarial loss: 0.994386, acc: 0.281250]\n",
            "37625: [discriminator loss: 0.569261, acc: 0.710938] [adversarial loss: 1.101155, acc: 0.265625]\n",
            "37626: [discriminator loss: 0.603449, acc: 0.625000] [adversarial loss: 1.068887, acc: 0.250000]\n",
            "37627: [discriminator loss: 0.616401, acc: 0.632812] [adversarial loss: 1.089123, acc: 0.250000]\n",
            "37628: [discriminator loss: 0.557176, acc: 0.710938] [adversarial loss: 0.926778, acc: 0.453125]\n",
            "37629: [discriminator loss: 0.575663, acc: 0.671875] [adversarial loss: 1.254017, acc: 0.203125]\n",
            "37630: [discriminator loss: 0.589024, acc: 0.664062] [adversarial loss: 0.912999, acc: 0.437500]\n",
            "37631: [discriminator loss: 0.534150, acc: 0.781250] [adversarial loss: 1.540797, acc: 0.125000]\n",
            "37632: [discriminator loss: 0.558187, acc: 0.726562] [adversarial loss: 1.026667, acc: 0.375000]\n",
            "37633: [discriminator loss: 0.583034, acc: 0.679688] [adversarial loss: 1.466385, acc: 0.109375]\n",
            "37634: [discriminator loss: 0.620607, acc: 0.648438] [adversarial loss: 0.849481, acc: 0.515625]\n",
            "37635: [discriminator loss: 0.651941, acc: 0.640625] [adversarial loss: 1.197385, acc: 0.187500]\n",
            "37636: [discriminator loss: 0.624025, acc: 0.625000] [adversarial loss: 1.011316, acc: 0.343750]\n",
            "37637: [discriminator loss: 0.522818, acc: 0.734375] [adversarial loss: 1.353495, acc: 0.140625]\n",
            "37638: [discriminator loss: 0.591222, acc: 0.710938] [adversarial loss: 1.033169, acc: 0.265625]\n",
            "37639: [discriminator loss: 0.501167, acc: 0.773438] [adversarial loss: 1.111089, acc: 0.203125]\n",
            "37640: [discriminator loss: 0.583051, acc: 0.671875] [adversarial loss: 0.944056, acc: 0.343750]\n",
            "37641: [discriminator loss: 0.626490, acc: 0.648438] [adversarial loss: 1.170357, acc: 0.203125]\n",
            "37642: [discriminator loss: 0.548140, acc: 0.750000] [adversarial loss: 0.885457, acc: 0.421875]\n",
            "37643: [discriminator loss: 0.611759, acc: 0.679688] [adversarial loss: 0.995814, acc: 0.390625]\n",
            "37644: [discriminator loss: 0.574681, acc: 0.648438] [adversarial loss: 1.041330, acc: 0.359375]\n",
            "37645: [discriminator loss: 0.577298, acc: 0.664062] [adversarial loss: 1.151094, acc: 0.203125]\n",
            "37646: [discriminator loss: 0.540417, acc: 0.687500] [adversarial loss: 0.798052, acc: 0.484375]\n",
            "37647: [discriminator loss: 0.578437, acc: 0.664062] [adversarial loss: 1.167487, acc: 0.218750]\n",
            "37648: [discriminator loss: 0.593851, acc: 0.632812] [adversarial loss: 1.050063, acc: 0.265625]\n",
            "37649: [discriminator loss: 0.593136, acc: 0.687500] [adversarial loss: 1.272111, acc: 0.218750]\n",
            "37650: [discriminator loss: 0.577962, acc: 0.687500] [adversarial loss: 1.039216, acc: 0.312500]\n",
            "37651: [discriminator loss: 0.645232, acc: 0.570312] [adversarial loss: 1.000448, acc: 0.359375]\n",
            "37652: [discriminator loss: 0.527232, acc: 0.703125] [adversarial loss: 0.946787, acc: 0.453125]\n",
            "37653: [discriminator loss: 0.576784, acc: 0.687500] [adversarial loss: 1.344832, acc: 0.093750]\n",
            "37654: [discriminator loss: 0.605633, acc: 0.671875] [adversarial loss: 0.798713, acc: 0.484375]\n",
            "37655: [discriminator loss: 0.640437, acc: 0.632812] [adversarial loss: 1.366497, acc: 0.140625]\n",
            "37656: [discriminator loss: 0.617820, acc: 0.695312] [adversarial loss: 0.933971, acc: 0.421875]\n",
            "37657: [discriminator loss: 0.622907, acc: 0.625000] [adversarial loss: 0.996288, acc: 0.375000]\n",
            "37658: [discriminator loss: 0.532823, acc: 0.765625] [adversarial loss: 0.996281, acc: 0.281250]\n",
            "37659: [discriminator loss: 0.567386, acc: 0.703125] [adversarial loss: 1.155677, acc: 0.250000]\n",
            "37660: [discriminator loss: 0.589663, acc: 0.710938] [adversarial loss: 1.184444, acc: 0.109375]\n",
            "37661: [discriminator loss: 0.629736, acc: 0.648438] [adversarial loss: 0.852003, acc: 0.437500]\n",
            "37662: [discriminator loss: 0.576319, acc: 0.679688] [adversarial loss: 1.212283, acc: 0.218750]\n",
            "37663: [discriminator loss: 0.545943, acc: 0.726562] [adversarial loss: 0.892281, acc: 0.437500]\n",
            "37664: [discriminator loss: 0.585534, acc: 0.648438] [adversarial loss: 1.261749, acc: 0.203125]\n",
            "37665: [discriminator loss: 0.652685, acc: 0.625000] [adversarial loss: 0.713203, acc: 0.640625]\n",
            "37666: [discriminator loss: 0.633903, acc: 0.640625] [adversarial loss: 1.224182, acc: 0.234375]\n",
            "37667: [discriminator loss: 0.648716, acc: 0.593750] [adversarial loss: 0.894119, acc: 0.437500]\n",
            "37668: [discriminator loss: 0.568783, acc: 0.757812] [adversarial loss: 1.143698, acc: 0.218750]\n",
            "37669: [discriminator loss: 0.519353, acc: 0.742188] [adversarial loss: 0.911098, acc: 0.453125]\n",
            "37670: [discriminator loss: 0.591401, acc: 0.648438] [adversarial loss: 1.154538, acc: 0.265625]\n",
            "37671: [discriminator loss: 0.619111, acc: 0.664062] [adversarial loss: 0.808285, acc: 0.468750]\n",
            "37672: [discriminator loss: 0.586713, acc: 0.710938] [adversarial loss: 1.224177, acc: 0.234375]\n",
            "37673: [discriminator loss: 0.619847, acc: 0.695312] [adversarial loss: 0.994226, acc: 0.343750]\n",
            "37674: [discriminator loss: 0.586589, acc: 0.687500] [adversarial loss: 1.050158, acc: 0.328125]\n",
            "37675: [discriminator loss: 0.569099, acc: 0.679688] [adversarial loss: 1.131266, acc: 0.265625]\n",
            "37676: [discriminator loss: 0.567210, acc: 0.703125] [adversarial loss: 1.038385, acc: 0.265625]\n",
            "37677: [discriminator loss: 0.576497, acc: 0.664062] [adversarial loss: 1.018794, acc: 0.359375]\n",
            "37678: [discriminator loss: 0.598436, acc: 0.648438] [adversarial loss: 1.106658, acc: 0.234375]\n",
            "37679: [discriminator loss: 0.545404, acc: 0.703125] [adversarial loss: 0.918967, acc: 0.406250]\n",
            "37680: [discriminator loss: 0.582334, acc: 0.664062] [adversarial loss: 1.138988, acc: 0.250000]\n",
            "37681: [discriminator loss: 0.610792, acc: 0.648438] [adversarial loss: 0.989117, acc: 0.406250]\n",
            "37682: [discriminator loss: 0.606725, acc: 0.679688] [adversarial loss: 1.136776, acc: 0.265625]\n",
            "37683: [discriminator loss: 0.592122, acc: 0.664062] [adversarial loss: 1.005536, acc: 0.406250]\n",
            "37684: [discriminator loss: 0.578477, acc: 0.671875] [adversarial loss: 1.020158, acc: 0.390625]\n",
            "37685: [discriminator loss: 0.555316, acc: 0.718750] [adversarial loss: 0.900043, acc: 0.312500]\n",
            "37686: [discriminator loss: 0.548714, acc: 0.703125] [adversarial loss: 1.020999, acc: 0.296875]\n",
            "37687: [discriminator loss: 0.565376, acc: 0.695312] [adversarial loss: 1.277024, acc: 0.203125]\n",
            "37688: [discriminator loss: 0.585499, acc: 0.718750] [adversarial loss: 0.730464, acc: 0.625000]\n",
            "37689: [discriminator loss: 0.610129, acc: 0.632812] [adversarial loss: 1.438465, acc: 0.203125]\n",
            "37690: [discriminator loss: 0.668377, acc: 0.632812] [adversarial loss: 0.741373, acc: 0.468750]\n",
            "37691: [discriminator loss: 0.687419, acc: 0.617188] [adversarial loss: 1.214628, acc: 0.156250]\n",
            "37692: [discriminator loss: 0.596294, acc: 0.671875] [adversarial loss: 1.065303, acc: 0.328125]\n",
            "37693: [discriminator loss: 0.628653, acc: 0.648438] [adversarial loss: 0.966942, acc: 0.484375]\n",
            "37694: [discriminator loss: 0.528955, acc: 0.718750] [adversarial loss: 0.997962, acc: 0.375000]\n",
            "37695: [discriminator loss: 0.563668, acc: 0.687500] [adversarial loss: 1.305023, acc: 0.171875]\n",
            "37696: [discriminator loss: 0.563857, acc: 0.726562] [adversarial loss: 0.916255, acc: 0.390625]\n",
            "37697: [discriminator loss: 0.565622, acc: 0.703125] [adversarial loss: 1.250734, acc: 0.265625]\n",
            "37698: [discriminator loss: 0.627059, acc: 0.656250] [adversarial loss: 0.889088, acc: 0.421875]\n",
            "37699: [discriminator loss: 0.609266, acc: 0.601562] [adversarial loss: 1.151322, acc: 0.203125]\n",
            "37700: [discriminator loss: 0.642132, acc: 0.648438] [adversarial loss: 1.010491, acc: 0.281250]\n",
            "37701: [discriminator loss: 0.602061, acc: 0.664062] [adversarial loss: 1.095143, acc: 0.359375]\n",
            "37702: [discriminator loss: 0.554188, acc: 0.664062] [adversarial loss: 0.975321, acc: 0.328125]\n",
            "37703: [discriminator loss: 0.583111, acc: 0.703125] [adversarial loss: 0.935548, acc: 0.390625]\n",
            "37704: [discriminator loss: 0.587641, acc: 0.656250] [adversarial loss: 0.897136, acc: 0.453125]\n",
            "37705: [discriminator loss: 0.569180, acc: 0.710938] [adversarial loss: 1.016184, acc: 0.312500]\n",
            "37706: [discriminator loss: 0.534912, acc: 0.726562] [adversarial loss: 1.030297, acc: 0.234375]\n",
            "37707: [discriminator loss: 0.655008, acc: 0.632812] [adversarial loss: 1.228322, acc: 0.234375]\n",
            "37708: [discriminator loss: 0.589178, acc: 0.703125] [adversarial loss: 0.685860, acc: 0.656250]\n",
            "37709: [discriminator loss: 0.610309, acc: 0.671875] [adversarial loss: 1.332625, acc: 0.156250]\n",
            "37710: [discriminator loss: 0.601348, acc: 0.640625] [adversarial loss: 1.022823, acc: 0.296875]\n",
            "37711: [discriminator loss: 0.534732, acc: 0.734375] [adversarial loss: 1.194573, acc: 0.265625]\n",
            "37712: [discriminator loss: 0.578409, acc: 0.710938] [adversarial loss: 0.838945, acc: 0.468750]\n",
            "37713: [discriminator loss: 0.530285, acc: 0.695312] [adversarial loss: 1.045356, acc: 0.265625]\n",
            "37714: [discriminator loss: 0.572690, acc: 0.671875] [adversarial loss: 1.214596, acc: 0.187500]\n",
            "37715: [discriminator loss: 0.623281, acc: 0.656250] [adversarial loss: 0.878390, acc: 0.468750]\n",
            "37716: [discriminator loss: 0.625112, acc: 0.671875] [adversarial loss: 1.044227, acc: 0.328125]\n",
            "37717: [discriminator loss: 0.571300, acc: 0.703125] [adversarial loss: 0.994586, acc: 0.359375]\n",
            "37718: [discriminator loss: 0.586897, acc: 0.687500] [adversarial loss: 1.203816, acc: 0.203125]\n",
            "37719: [discriminator loss: 0.645369, acc: 0.632812] [adversarial loss: 0.691594, acc: 0.531250]\n",
            "37720: [discriminator loss: 0.598143, acc: 0.695312] [adversarial loss: 1.235830, acc: 0.171875]\n",
            "37721: [discriminator loss: 0.652673, acc: 0.601562] [adversarial loss: 0.701481, acc: 0.593750]\n",
            "37722: [discriminator loss: 0.602808, acc: 0.679688] [adversarial loss: 1.278271, acc: 0.203125]\n",
            "37723: [discriminator loss: 0.633954, acc: 0.601562] [adversarial loss: 0.867288, acc: 0.406250]\n",
            "37724: [discriminator loss: 0.622573, acc: 0.664062] [adversarial loss: 1.114346, acc: 0.250000]\n",
            "37725: [discriminator loss: 0.601418, acc: 0.656250] [adversarial loss: 0.959477, acc: 0.328125]\n",
            "37726: [discriminator loss: 0.566952, acc: 0.679688] [adversarial loss: 1.071580, acc: 0.328125]\n",
            "37727: [discriminator loss: 0.592913, acc: 0.664062] [adversarial loss: 0.972368, acc: 0.343750]\n",
            "37728: [discriminator loss: 0.545122, acc: 0.679688] [adversarial loss: 1.121831, acc: 0.218750]\n",
            "37729: [discriminator loss: 0.650809, acc: 0.609375] [adversarial loss: 1.184379, acc: 0.234375]\n",
            "37730: [discriminator loss: 0.614111, acc: 0.617188] [adversarial loss: 0.778167, acc: 0.531250]\n",
            "37731: [discriminator loss: 0.593263, acc: 0.640625] [adversarial loss: 1.250754, acc: 0.187500]\n",
            "37732: [discriminator loss: 0.618862, acc: 0.671875] [adversarial loss: 0.957213, acc: 0.421875]\n",
            "37733: [discriminator loss: 0.560862, acc: 0.687500] [adversarial loss: 1.137927, acc: 0.218750]\n",
            "37734: [discriminator loss: 0.557331, acc: 0.695312] [adversarial loss: 0.941393, acc: 0.343750]\n",
            "37735: [discriminator loss: 0.588064, acc: 0.679688] [adversarial loss: 0.915812, acc: 0.390625]\n",
            "37736: [discriminator loss: 0.535498, acc: 0.750000] [adversarial loss: 0.970949, acc: 0.265625]\n",
            "37737: [discriminator loss: 0.623711, acc: 0.710938] [adversarial loss: 1.159943, acc: 0.187500]\n",
            "37738: [discriminator loss: 0.574592, acc: 0.695312] [adversarial loss: 0.928670, acc: 0.406250]\n",
            "37739: [discriminator loss: 0.587104, acc: 0.679688] [adversarial loss: 1.049344, acc: 0.265625]\n",
            "37740: [discriminator loss: 0.565686, acc: 0.679688] [adversarial loss: 0.815797, acc: 0.468750]\n",
            "37741: [discriminator loss: 0.582580, acc: 0.671875] [adversarial loss: 1.288244, acc: 0.109375]\n",
            "37742: [discriminator loss: 0.574025, acc: 0.664062] [adversarial loss: 0.938659, acc: 0.375000]\n",
            "37743: [discriminator loss: 0.540087, acc: 0.671875] [adversarial loss: 1.144467, acc: 0.203125]\n",
            "37744: [discriminator loss: 0.585095, acc: 0.679688] [adversarial loss: 1.073715, acc: 0.312500]\n",
            "37745: [discriminator loss: 0.557877, acc: 0.695312] [adversarial loss: 0.848476, acc: 0.390625]\n",
            "37746: [discriminator loss: 0.571221, acc: 0.695312] [adversarial loss: 0.944465, acc: 0.343750]\n",
            "37747: [discriminator loss: 0.541463, acc: 0.781250] [adversarial loss: 1.194709, acc: 0.171875]\n",
            "37748: [discriminator loss: 0.560932, acc: 0.687500] [adversarial loss: 0.928675, acc: 0.421875]\n",
            "37749: [discriminator loss: 0.495575, acc: 0.757812] [adversarial loss: 1.041979, acc: 0.296875]\n",
            "37750: [discriminator loss: 0.540373, acc: 0.664062] [adversarial loss: 1.123869, acc: 0.343750]\n",
            "37751: [discriminator loss: 0.514602, acc: 0.695312] [adversarial loss: 0.977960, acc: 0.390625]\n",
            "37752: [discriminator loss: 0.669843, acc: 0.648438] [adversarial loss: 1.338336, acc: 0.109375]\n",
            "37753: [discriminator loss: 0.578347, acc: 0.687500] [adversarial loss: 0.839164, acc: 0.375000]\n",
            "37754: [discriminator loss: 0.652487, acc: 0.625000] [adversarial loss: 1.287005, acc: 0.234375]\n",
            "37755: [discriminator loss: 0.632963, acc: 0.664062] [adversarial loss: 0.765965, acc: 0.453125]\n",
            "37756: [discriminator loss: 0.593941, acc: 0.718750] [adversarial loss: 1.250234, acc: 0.234375]\n",
            "37757: [discriminator loss: 0.599655, acc: 0.664062] [adversarial loss: 1.020403, acc: 0.343750]\n",
            "37758: [discriminator loss: 0.565814, acc: 0.664062] [adversarial loss: 1.084450, acc: 0.250000]\n",
            "37759: [discriminator loss: 0.575279, acc: 0.734375] [adversarial loss: 0.814209, acc: 0.421875]\n",
            "37760: [discriminator loss: 0.584710, acc: 0.671875] [adversarial loss: 1.014686, acc: 0.281250]\n",
            "37761: [discriminator loss: 0.587310, acc: 0.656250] [adversarial loss: 0.891544, acc: 0.406250]\n",
            "37762: [discriminator loss: 0.548245, acc: 0.703125] [adversarial loss: 1.035157, acc: 0.296875]\n",
            "37763: [discriminator loss: 0.582078, acc: 0.632812] [adversarial loss: 0.929331, acc: 0.343750]\n",
            "37764: [discriminator loss: 0.537292, acc: 0.750000] [adversarial loss: 1.203077, acc: 0.203125]\n",
            "37765: [discriminator loss: 0.577859, acc: 0.718750] [adversarial loss: 1.210943, acc: 0.187500]\n",
            "37766: [discriminator loss: 0.608253, acc: 0.679688] [adversarial loss: 1.056128, acc: 0.359375]\n",
            "37767: [discriminator loss: 0.601647, acc: 0.625000] [adversarial loss: 1.225914, acc: 0.250000]\n",
            "37768: [discriminator loss: 0.607057, acc: 0.664062] [adversarial loss: 0.699149, acc: 0.593750]\n",
            "37769: [discriminator loss: 0.592081, acc: 0.695312] [adversarial loss: 1.430957, acc: 0.140625]\n",
            "37770: [discriminator loss: 0.533096, acc: 0.742188] [adversarial loss: 0.873551, acc: 0.375000]\n",
            "37771: [discriminator loss: 0.573350, acc: 0.703125] [adversarial loss: 1.276108, acc: 0.171875]\n",
            "37772: [discriminator loss: 0.527305, acc: 0.750000] [adversarial loss: 1.012852, acc: 0.375000]\n",
            "37773: [discriminator loss: 0.591772, acc: 0.679688] [adversarial loss: 0.968601, acc: 0.312500]\n",
            "37774: [discriminator loss: 0.570963, acc: 0.695312] [adversarial loss: 1.086002, acc: 0.250000]\n",
            "37775: [discriminator loss: 0.606765, acc: 0.671875] [adversarial loss: 0.809172, acc: 0.515625]\n",
            "37776: [discriminator loss: 0.633561, acc: 0.648438] [adversarial loss: 1.122627, acc: 0.312500]\n",
            "37777: [discriminator loss: 0.621568, acc: 0.664062] [adversarial loss: 0.907325, acc: 0.421875]\n",
            "37778: [discriminator loss: 0.603150, acc: 0.656250] [adversarial loss: 1.127321, acc: 0.281250]\n",
            "37779: [discriminator loss: 0.528892, acc: 0.750000] [adversarial loss: 0.994001, acc: 0.343750]\n",
            "37780: [discriminator loss: 0.628005, acc: 0.625000] [adversarial loss: 1.029204, acc: 0.265625]\n",
            "37781: [discriminator loss: 0.608838, acc: 0.703125] [adversarial loss: 0.958757, acc: 0.359375]\n",
            "37782: [discriminator loss: 0.601448, acc: 0.664062] [adversarial loss: 0.893351, acc: 0.375000]\n",
            "37783: [discriminator loss: 0.630727, acc: 0.648438] [adversarial loss: 1.156425, acc: 0.234375]\n",
            "37784: [discriminator loss: 0.587310, acc: 0.664062] [adversarial loss: 0.959694, acc: 0.343750]\n",
            "37785: [discriminator loss: 0.623034, acc: 0.656250] [adversarial loss: 1.166813, acc: 0.218750]\n",
            "37786: [discriminator loss: 0.564921, acc: 0.687500] [adversarial loss: 0.940863, acc: 0.375000]\n",
            "37787: [discriminator loss: 0.590514, acc: 0.671875] [adversarial loss: 0.886586, acc: 0.500000]\n",
            "37788: [discriminator loss: 0.630852, acc: 0.656250] [adversarial loss: 1.015999, acc: 0.250000]\n",
            "37789: [discriminator loss: 0.588892, acc: 0.671875] [adversarial loss: 0.880549, acc: 0.437500]\n",
            "37790: [discriminator loss: 0.536016, acc: 0.742188] [adversarial loss: 1.167143, acc: 0.171875]\n",
            "37791: [discriminator loss: 0.606682, acc: 0.671875] [adversarial loss: 0.994118, acc: 0.406250]\n",
            "37792: [discriminator loss: 0.535921, acc: 0.726562] [adversarial loss: 1.147703, acc: 0.250000]\n",
            "37793: [discriminator loss: 0.534674, acc: 0.750000] [adversarial loss: 0.943901, acc: 0.359375]\n",
            "37794: [discriminator loss: 0.611644, acc: 0.656250] [adversarial loss: 1.008437, acc: 0.234375]\n",
            "37795: [discriminator loss: 0.552366, acc: 0.679688] [adversarial loss: 1.000988, acc: 0.328125]\n",
            "37796: [discriminator loss: 0.562238, acc: 0.726562] [adversarial loss: 1.273657, acc: 0.140625]\n",
            "37797: [discriminator loss: 0.548548, acc: 0.703125] [adversarial loss: 0.845962, acc: 0.468750]\n",
            "37798: [discriminator loss: 0.605600, acc: 0.640625] [adversarial loss: 1.303912, acc: 0.187500]\n",
            "37799: [discriminator loss: 0.691836, acc: 0.570312] [adversarial loss: 0.784625, acc: 0.515625]\n",
            "37800: [discriminator loss: 0.595506, acc: 0.671875] [adversarial loss: 1.108521, acc: 0.281250]\n",
            "37801: [discriminator loss: 0.588568, acc: 0.703125] [adversarial loss: 0.948115, acc: 0.296875]\n",
            "37802: [discriminator loss: 0.563098, acc: 0.648438] [adversarial loss: 0.994682, acc: 0.328125]\n",
            "37803: [discriminator loss: 0.640355, acc: 0.632812] [adversarial loss: 1.320219, acc: 0.140625]\n",
            "37804: [discriminator loss: 0.636330, acc: 0.679688] [adversarial loss: 0.933783, acc: 0.296875]\n",
            "37805: [discriminator loss: 0.503422, acc: 0.757812] [adversarial loss: 1.160593, acc: 0.187500]\n",
            "37806: [discriminator loss: 0.592718, acc: 0.687500] [adversarial loss: 1.153849, acc: 0.218750]\n",
            "37807: [discriminator loss: 0.563585, acc: 0.710938] [adversarial loss: 1.107304, acc: 0.203125]\n",
            "37808: [discriminator loss: 0.573881, acc: 0.695312] [adversarial loss: 1.076378, acc: 0.234375]\n",
            "37809: [discriminator loss: 0.631668, acc: 0.609375] [adversarial loss: 0.988330, acc: 0.312500]\n",
            "37810: [discriminator loss: 0.610014, acc: 0.640625] [adversarial loss: 1.160584, acc: 0.171875]\n",
            "37811: [discriminator loss: 0.569229, acc: 0.671875] [adversarial loss: 0.953902, acc: 0.375000]\n",
            "37812: [discriminator loss: 0.552227, acc: 0.742188] [adversarial loss: 0.772376, acc: 0.531250]\n",
            "37813: [discriminator loss: 0.635185, acc: 0.648438] [adversarial loss: 1.146327, acc: 0.265625]\n",
            "37814: [discriminator loss: 0.580945, acc: 0.671875] [adversarial loss: 0.739683, acc: 0.562500]\n",
            "37815: [discriminator loss: 0.637084, acc: 0.609375] [adversarial loss: 1.281834, acc: 0.140625]\n",
            "37816: [discriminator loss: 0.526039, acc: 0.734375] [adversarial loss: 0.878695, acc: 0.375000]\n",
            "37817: [discriminator loss: 0.595554, acc: 0.671875] [adversarial loss: 1.065734, acc: 0.281250]\n",
            "37818: [discriminator loss: 0.553556, acc: 0.773438] [adversarial loss: 0.980858, acc: 0.390625]\n",
            "37819: [discriminator loss: 0.574664, acc: 0.703125] [adversarial loss: 1.020668, acc: 0.328125]\n",
            "37820: [discriminator loss: 0.541674, acc: 0.757812] [adversarial loss: 1.082833, acc: 0.250000]\n",
            "37821: [discriminator loss: 0.516561, acc: 0.742188] [adversarial loss: 0.971613, acc: 0.390625]\n",
            "37822: [discriminator loss: 0.566790, acc: 0.679688] [adversarial loss: 1.446983, acc: 0.062500]\n",
            "37823: [discriminator loss: 0.642030, acc: 0.656250] [adversarial loss: 0.811014, acc: 0.468750]\n",
            "37824: [discriminator loss: 0.661401, acc: 0.609375] [adversarial loss: 1.451851, acc: 0.093750]\n",
            "37825: [discriminator loss: 0.607408, acc: 0.656250] [adversarial loss: 0.877327, acc: 0.421875]\n",
            "37826: [discriminator loss: 0.584808, acc: 0.695312] [adversarial loss: 1.069547, acc: 0.250000]\n",
            "37827: [discriminator loss: 0.612112, acc: 0.656250] [adversarial loss: 1.036431, acc: 0.359375]\n",
            "37828: [discriminator loss: 0.573395, acc: 0.710938] [adversarial loss: 1.045987, acc: 0.265625]\n",
            "37829: [discriminator loss: 0.537687, acc: 0.687500] [adversarial loss: 0.937204, acc: 0.437500]\n",
            "37830: [discriminator loss: 0.590585, acc: 0.679688] [adversarial loss: 1.024681, acc: 0.343750]\n",
            "37831: [discriminator loss: 0.639229, acc: 0.601562] [adversarial loss: 1.018690, acc: 0.406250]\n",
            "37832: [discriminator loss: 0.547754, acc: 0.687500] [adversarial loss: 1.179863, acc: 0.312500]\n",
            "37833: [discriminator loss: 0.613701, acc: 0.625000] [adversarial loss: 0.845912, acc: 0.406250]\n",
            "37834: [discriminator loss: 0.631869, acc: 0.625000] [adversarial loss: 1.149749, acc: 0.234375]\n",
            "37835: [discriminator loss: 0.593401, acc: 0.687500] [adversarial loss: 1.008297, acc: 0.296875]\n",
            "37836: [discriminator loss: 0.523734, acc: 0.765625] [adversarial loss: 0.973720, acc: 0.328125]\n",
            "37837: [discriminator loss: 0.599606, acc: 0.648438] [adversarial loss: 1.091472, acc: 0.281250]\n",
            "37838: [discriminator loss: 0.606728, acc: 0.710938] [adversarial loss: 1.062821, acc: 0.234375]\n",
            "37839: [discriminator loss: 0.615981, acc: 0.625000] [adversarial loss: 0.890158, acc: 0.359375]\n",
            "37840: [discriminator loss: 0.604810, acc: 0.664062] [adversarial loss: 1.182453, acc: 0.265625]\n",
            "37841: [discriminator loss: 0.605407, acc: 0.609375] [adversarial loss: 0.931199, acc: 0.390625]\n",
            "37842: [discriminator loss: 0.600928, acc: 0.617188] [adversarial loss: 1.238646, acc: 0.187500]\n",
            "37843: [discriminator loss: 0.657796, acc: 0.609375] [adversarial loss: 0.751736, acc: 0.515625]\n",
            "37844: [discriminator loss: 0.568508, acc: 0.703125] [adversarial loss: 1.169709, acc: 0.250000]\n",
            "37845: [discriminator loss: 0.596816, acc: 0.671875] [adversarial loss: 0.982195, acc: 0.359375]\n",
            "37846: [discriminator loss: 0.603992, acc: 0.671875] [adversarial loss: 0.989176, acc: 0.312500]\n",
            "37847: [discriminator loss: 0.598599, acc: 0.687500] [adversarial loss: 1.191900, acc: 0.218750]\n",
            "37848: [discriminator loss: 0.600742, acc: 0.679688] [adversarial loss: 0.768867, acc: 0.468750]\n",
            "37849: [discriminator loss: 0.654015, acc: 0.679688] [adversarial loss: 1.165287, acc: 0.218750]\n",
            "37850: [discriminator loss: 0.618659, acc: 0.664062] [adversarial loss: 0.969274, acc: 0.296875]\n",
            "37851: [discriminator loss: 0.537400, acc: 0.742188] [adversarial loss: 1.081310, acc: 0.375000]\n",
            "37852: [discriminator loss: 0.601739, acc: 0.632812] [adversarial loss: 1.028894, acc: 0.265625]\n",
            "37853: [discriminator loss: 0.575236, acc: 0.742188] [adversarial loss: 1.000932, acc: 0.281250]\n",
            "37854: [discriminator loss: 0.607522, acc: 0.679688] [adversarial loss: 1.030705, acc: 0.281250]\n",
            "37855: [discriminator loss: 0.580890, acc: 0.679688] [adversarial loss: 1.072209, acc: 0.359375]\n",
            "37856: [discriminator loss: 0.539150, acc: 0.718750] [adversarial loss: 1.111258, acc: 0.218750]\n",
            "37857: [discriminator loss: 0.632561, acc: 0.601562] [adversarial loss: 1.062979, acc: 0.343750]\n",
            "37858: [discriminator loss: 0.587744, acc: 0.679688] [adversarial loss: 1.251067, acc: 0.125000]\n",
            "37859: [discriminator loss: 0.590695, acc: 0.695312] [adversarial loss: 1.139507, acc: 0.296875]\n",
            "37860: [discriminator loss: 0.496158, acc: 0.765625] [adversarial loss: 1.076694, acc: 0.234375]\n",
            "37861: [discriminator loss: 0.655576, acc: 0.593750] [adversarial loss: 0.956210, acc: 0.250000]\n",
            "37862: [discriminator loss: 0.560746, acc: 0.710938] [adversarial loss: 0.821574, acc: 0.531250]\n",
            "37863: [discriminator loss: 0.628253, acc: 0.632812] [adversarial loss: 1.391735, acc: 0.140625]\n",
            "37864: [discriminator loss: 0.591047, acc: 0.664062] [adversarial loss: 0.998628, acc: 0.359375]\n",
            "37865: [discriminator loss: 0.611723, acc: 0.648438] [adversarial loss: 1.016544, acc: 0.359375]\n",
            "37866: [discriminator loss: 0.518978, acc: 0.703125] [adversarial loss: 0.813510, acc: 0.500000]\n",
            "37867: [discriminator loss: 0.567604, acc: 0.687500] [adversarial loss: 1.507244, acc: 0.125000]\n",
            "37868: [discriminator loss: 0.630868, acc: 0.640625] [adversarial loss: 0.886054, acc: 0.390625]\n",
            "37869: [discriminator loss: 0.659263, acc: 0.640625] [adversarial loss: 0.845513, acc: 0.484375]\n",
            "37870: [discriminator loss: 0.611268, acc: 0.679688] [adversarial loss: 1.168498, acc: 0.218750]\n",
            "37871: [discriminator loss: 0.593140, acc: 0.656250] [adversarial loss: 0.873510, acc: 0.406250]\n",
            "37872: [discriminator loss: 0.584368, acc: 0.625000] [adversarial loss: 1.086899, acc: 0.265625]\n",
            "37873: [discriminator loss: 0.561846, acc: 0.703125] [adversarial loss: 1.112706, acc: 0.218750]\n",
            "37874: [discriminator loss: 0.555640, acc: 0.734375] [adversarial loss: 0.886220, acc: 0.437500]\n",
            "37875: [discriminator loss: 0.574804, acc: 0.710938] [adversarial loss: 1.007884, acc: 0.375000]\n",
            "37876: [discriminator loss: 0.611274, acc: 0.664062] [adversarial loss: 1.144950, acc: 0.312500]\n",
            "37877: [discriminator loss: 0.502244, acc: 0.781250] [adversarial loss: 1.245010, acc: 0.265625]\n",
            "37878: [discriminator loss: 0.556246, acc: 0.710938] [adversarial loss: 0.926389, acc: 0.390625]\n",
            "37879: [discriminator loss: 0.525873, acc: 0.718750] [adversarial loss: 1.205159, acc: 0.203125]\n",
            "37880: [discriminator loss: 0.595201, acc: 0.687500] [adversarial loss: 1.232089, acc: 0.203125]\n",
            "37881: [discriminator loss: 0.515116, acc: 0.765625] [adversarial loss: 1.064830, acc: 0.312500]\n",
            "37882: [discriminator loss: 0.575762, acc: 0.757812] [adversarial loss: 1.082313, acc: 0.218750]\n",
            "37883: [discriminator loss: 0.588581, acc: 0.687500] [adversarial loss: 1.119364, acc: 0.296875]\n",
            "37884: [discriminator loss: 0.548868, acc: 0.726562] [adversarial loss: 0.936866, acc: 0.437500]\n",
            "37885: [discriminator loss: 0.514752, acc: 0.734375] [adversarial loss: 1.527693, acc: 0.078125]\n",
            "37886: [discriminator loss: 0.614475, acc: 0.679688] [adversarial loss: 1.067972, acc: 0.265625]\n",
            "37887: [discriminator loss: 0.562965, acc: 0.742188] [adversarial loss: 1.070594, acc: 0.328125]\n",
            "37888: [discriminator loss: 0.618585, acc: 0.601562] [adversarial loss: 1.014931, acc: 0.343750]\n",
            "37889: [discriminator loss: 0.561869, acc: 0.726562] [adversarial loss: 1.173129, acc: 0.234375]\n",
            "37890: [discriminator loss: 0.592278, acc: 0.664062] [adversarial loss: 0.739905, acc: 0.593750]\n",
            "37891: [discriminator loss: 0.611667, acc: 0.648438] [adversarial loss: 1.265826, acc: 0.218750]\n",
            "37892: [discriminator loss: 0.553769, acc: 0.703125] [adversarial loss: 0.802389, acc: 0.453125]\n",
            "37893: [discriminator loss: 0.583343, acc: 0.695312] [adversarial loss: 1.104979, acc: 0.265625]\n",
            "37894: [discriminator loss: 0.534109, acc: 0.695312] [adversarial loss: 0.807768, acc: 0.515625]\n",
            "37895: [discriminator loss: 0.591630, acc: 0.687500] [adversarial loss: 1.094635, acc: 0.218750]\n",
            "37896: [discriminator loss: 0.559628, acc: 0.703125] [adversarial loss: 1.069532, acc: 0.375000]\n",
            "37897: [discriminator loss: 0.546867, acc: 0.695312] [adversarial loss: 0.896073, acc: 0.406250]\n",
            "37898: [discriminator loss: 0.634461, acc: 0.609375] [adversarial loss: 0.963487, acc: 0.343750]\n",
            "37899: [discriminator loss: 0.624682, acc: 0.617188] [adversarial loss: 0.900844, acc: 0.359375]\n",
            "37900: [discriminator loss: 0.558338, acc: 0.695312] [adversarial loss: 1.182813, acc: 0.265625]\n",
            "37901: [discriminator loss: 0.641499, acc: 0.593750] [adversarial loss: 1.014186, acc: 0.312500]\n",
            "37902: [discriminator loss: 0.605226, acc: 0.664062] [adversarial loss: 1.039988, acc: 0.296875]\n",
            "37903: [discriminator loss: 0.606427, acc: 0.656250] [adversarial loss: 1.188868, acc: 0.218750]\n",
            "37904: [discriminator loss: 0.612271, acc: 0.671875] [adversarial loss: 1.064580, acc: 0.359375]\n",
            "37905: [discriminator loss: 0.558822, acc: 0.710938] [adversarial loss: 1.182019, acc: 0.250000]\n",
            "37906: [discriminator loss: 0.608834, acc: 0.632812] [adversarial loss: 0.923790, acc: 0.343750]\n",
            "37907: [discriminator loss: 0.591187, acc: 0.718750] [adversarial loss: 1.032347, acc: 0.375000]\n",
            "37908: [discriminator loss: 0.541468, acc: 0.734375] [adversarial loss: 0.966247, acc: 0.296875]\n",
            "37909: [discriminator loss: 0.607085, acc: 0.648438] [adversarial loss: 0.913194, acc: 0.421875]\n",
            "37910: [discriminator loss: 0.598828, acc: 0.656250] [adversarial loss: 1.267886, acc: 0.171875]\n",
            "37911: [discriminator loss: 0.586581, acc: 0.687500] [adversarial loss: 0.769386, acc: 0.531250]\n",
            "37912: [discriminator loss: 0.637071, acc: 0.585938] [adversarial loss: 1.400213, acc: 0.125000]\n",
            "37913: [discriminator loss: 0.569335, acc: 0.679688] [adversarial loss: 0.897946, acc: 0.406250]\n",
            "37914: [discriminator loss: 0.593451, acc: 0.656250] [adversarial loss: 1.339705, acc: 0.156250]\n",
            "37915: [discriminator loss: 0.634530, acc: 0.617188] [adversarial loss: 0.983638, acc: 0.484375]\n",
            "37916: [discriminator loss: 0.585165, acc: 0.695312] [adversarial loss: 1.170976, acc: 0.171875]\n",
            "37917: [discriminator loss: 0.635170, acc: 0.632812] [adversarial loss: 1.006510, acc: 0.296875]\n",
            "37918: [discriminator loss: 0.592879, acc: 0.695312] [adversarial loss: 1.142982, acc: 0.250000]\n",
            "37919: [discriminator loss: 0.567533, acc: 0.695312] [adversarial loss: 0.742392, acc: 0.515625]\n",
            "37920: [discriminator loss: 0.598980, acc: 0.640625] [adversarial loss: 1.256659, acc: 0.218750]\n",
            "37921: [discriminator loss: 0.569182, acc: 0.679688] [adversarial loss: 0.893870, acc: 0.359375]\n",
            "37922: [discriminator loss: 0.552578, acc: 0.695312] [adversarial loss: 1.056210, acc: 0.359375]\n",
            "37923: [discriminator loss: 0.536238, acc: 0.765625] [adversarial loss: 0.815620, acc: 0.500000]\n",
            "37924: [discriminator loss: 0.601908, acc: 0.679688] [adversarial loss: 1.276369, acc: 0.187500]\n",
            "37925: [discriminator loss: 0.575258, acc: 0.703125] [adversarial loss: 0.833069, acc: 0.453125]\n",
            "37926: [discriminator loss: 0.586981, acc: 0.710938] [adversarial loss: 1.177379, acc: 0.328125]\n",
            "37927: [discriminator loss: 0.530733, acc: 0.734375] [adversarial loss: 1.056203, acc: 0.312500]\n",
            "37928: [discriminator loss: 0.560783, acc: 0.687500] [adversarial loss: 1.092656, acc: 0.281250]\n",
            "37929: [discriminator loss: 0.581100, acc: 0.687500] [adversarial loss: 0.905727, acc: 0.421875]\n",
            "37930: [discriminator loss: 0.622824, acc: 0.656250] [adversarial loss: 1.189844, acc: 0.171875]\n",
            "37931: [discriminator loss: 0.599882, acc: 0.710938] [adversarial loss: 1.077481, acc: 0.296875]\n",
            "37932: [discriminator loss: 0.556554, acc: 0.695312] [adversarial loss: 1.156265, acc: 0.250000]\n",
            "37933: [discriminator loss: 0.580505, acc: 0.710938] [adversarial loss: 0.860600, acc: 0.500000]\n",
            "37934: [discriminator loss: 0.619450, acc: 0.648438] [adversarial loss: 1.303203, acc: 0.125000]\n",
            "37935: [discriminator loss: 0.575852, acc: 0.679688] [adversarial loss: 0.853727, acc: 0.359375]\n",
            "37936: [discriminator loss: 0.561763, acc: 0.726562] [adversarial loss: 1.199923, acc: 0.218750]\n",
            "37937: [discriminator loss: 0.574886, acc: 0.679688] [adversarial loss: 1.132702, acc: 0.250000]\n",
            "37938: [discriminator loss: 0.584440, acc: 0.718750] [adversarial loss: 0.860748, acc: 0.390625]\n",
            "37939: [discriminator loss: 0.631561, acc: 0.609375] [adversarial loss: 1.344058, acc: 0.171875]\n",
            "37940: [discriminator loss: 0.620626, acc: 0.632812] [adversarial loss: 0.812036, acc: 0.515625]\n",
            "37941: [discriminator loss: 0.629903, acc: 0.671875] [adversarial loss: 1.371330, acc: 0.187500]\n",
            "37942: [discriminator loss: 0.591502, acc: 0.656250] [adversarial loss: 0.907066, acc: 0.453125]\n",
            "37943: [discriminator loss: 0.602944, acc: 0.664062] [adversarial loss: 0.915817, acc: 0.421875]\n",
            "37944: [discriminator loss: 0.542036, acc: 0.750000] [adversarial loss: 1.199823, acc: 0.250000]\n",
            "37945: [discriminator loss: 0.551834, acc: 0.718750] [adversarial loss: 0.891736, acc: 0.359375]\n",
            "37946: [discriminator loss: 0.604539, acc: 0.664062] [adversarial loss: 1.048226, acc: 0.437500]\n",
            "37947: [discriminator loss: 0.612973, acc: 0.625000] [adversarial loss: 1.316206, acc: 0.171875]\n",
            "37948: [discriminator loss: 0.644836, acc: 0.617188] [adversarial loss: 0.908219, acc: 0.375000]\n",
            "37949: [discriminator loss: 0.576003, acc: 0.734375] [adversarial loss: 1.084363, acc: 0.312500]\n",
            "37950: [discriminator loss: 0.575203, acc: 0.703125] [adversarial loss: 0.953700, acc: 0.359375]\n",
            "37951: [discriminator loss: 0.531257, acc: 0.750000] [adversarial loss: 1.222926, acc: 0.234375]\n",
            "37952: [discriminator loss: 0.550121, acc: 0.687500] [adversarial loss: 1.228436, acc: 0.218750]\n",
            "37953: [discriminator loss: 0.580475, acc: 0.671875] [adversarial loss: 1.181599, acc: 0.281250]\n",
            "37954: [discriminator loss: 0.612434, acc: 0.648438] [adversarial loss: 1.278615, acc: 0.140625]\n",
            "37955: [discriminator loss: 0.566148, acc: 0.695312] [adversarial loss: 0.965751, acc: 0.421875]\n",
            "37956: [discriminator loss: 0.489378, acc: 0.781250] [adversarial loss: 1.067131, acc: 0.343750]\n",
            "37957: [discriminator loss: 0.503279, acc: 0.726562] [adversarial loss: 1.016246, acc: 0.296875]\n",
            "37958: [discriminator loss: 0.616991, acc: 0.671875] [adversarial loss: 0.904690, acc: 0.375000]\n",
            "37959: [discriminator loss: 0.575954, acc: 0.656250] [adversarial loss: 1.072632, acc: 0.343750]\n",
            "37960: [discriminator loss: 0.583016, acc: 0.695312] [adversarial loss: 1.007391, acc: 0.406250]\n",
            "37961: [discriminator loss: 0.609693, acc: 0.640625] [adversarial loss: 1.170233, acc: 0.203125]\n",
            "37962: [discriminator loss: 0.603823, acc: 0.710938] [adversarial loss: 1.079071, acc: 0.281250]\n",
            "37963: [discriminator loss: 0.599114, acc: 0.648438] [adversarial loss: 1.118399, acc: 0.250000]\n",
            "37964: [discriminator loss: 0.559866, acc: 0.710938] [adversarial loss: 1.074414, acc: 0.265625]\n",
            "37965: [discriminator loss: 0.632316, acc: 0.609375] [adversarial loss: 0.807016, acc: 0.406250]\n",
            "37966: [discriminator loss: 0.587111, acc: 0.671875] [adversarial loss: 1.261314, acc: 0.203125]\n",
            "37967: [discriminator loss: 0.573356, acc: 0.664062] [adversarial loss: 0.881719, acc: 0.421875]\n",
            "37968: [discriminator loss: 0.566134, acc: 0.671875] [adversarial loss: 1.354120, acc: 0.046875]\n",
            "37969: [discriminator loss: 0.577309, acc: 0.734375] [adversarial loss: 0.882601, acc: 0.343750]\n",
            "37970: [discriminator loss: 0.585509, acc: 0.710938] [adversarial loss: 1.184566, acc: 0.187500]\n",
            "37971: [discriminator loss: 0.682046, acc: 0.617188] [adversarial loss: 1.017507, acc: 0.359375]\n",
            "37972: [discriminator loss: 0.617067, acc: 0.671875] [adversarial loss: 1.025951, acc: 0.281250]\n",
            "37973: [discriminator loss: 0.621986, acc: 0.593750] [adversarial loss: 1.163593, acc: 0.218750]\n",
            "37974: [discriminator loss: 0.543549, acc: 0.734375] [adversarial loss: 1.149916, acc: 0.281250]\n",
            "37975: [discriminator loss: 0.579209, acc: 0.695312] [adversarial loss: 1.012836, acc: 0.359375]\n",
            "37976: [discriminator loss: 0.545941, acc: 0.710938] [adversarial loss: 1.370589, acc: 0.250000]\n",
            "37977: [discriminator loss: 0.640302, acc: 0.664062] [adversarial loss: 0.953719, acc: 0.484375]\n",
            "37978: [discriminator loss: 0.612794, acc: 0.695312] [adversarial loss: 1.152696, acc: 0.296875]\n",
            "37979: [discriminator loss: 0.616599, acc: 0.687500] [adversarial loss: 0.947817, acc: 0.375000]\n",
            "37980: [discriminator loss: 0.567566, acc: 0.718750] [adversarial loss: 1.212857, acc: 0.156250]\n",
            "37981: [discriminator loss: 0.632843, acc: 0.656250] [adversarial loss: 0.924394, acc: 0.437500]\n",
            "37982: [discriminator loss: 0.548509, acc: 0.687500] [adversarial loss: 1.062162, acc: 0.265625]\n",
            "37983: [discriminator loss: 0.546761, acc: 0.734375] [adversarial loss: 1.071446, acc: 0.265625]\n",
            "37984: [discriminator loss: 0.542691, acc: 0.734375] [adversarial loss: 1.092817, acc: 0.296875]\n",
            "37985: [discriminator loss: 0.624344, acc: 0.703125] [adversarial loss: 1.196330, acc: 0.281250]\n",
            "37986: [discriminator loss: 0.611629, acc: 0.687500] [adversarial loss: 0.931607, acc: 0.406250]\n",
            "37987: [discriminator loss: 0.678702, acc: 0.593750] [adversarial loss: 1.094982, acc: 0.218750]\n",
            "37988: [discriminator loss: 0.566665, acc: 0.671875] [adversarial loss: 0.743605, acc: 0.578125]\n",
            "37989: [discriminator loss: 0.608488, acc: 0.601562] [adversarial loss: 1.140650, acc: 0.234375]\n",
            "37990: [discriminator loss: 0.537786, acc: 0.710938] [adversarial loss: 0.894684, acc: 0.390625]\n",
            "37991: [discriminator loss: 0.588072, acc: 0.671875] [adversarial loss: 1.284007, acc: 0.156250]\n",
            "37992: [discriminator loss: 0.579765, acc: 0.726562] [adversarial loss: 1.016000, acc: 0.359375]\n",
            "37993: [discriminator loss: 0.602201, acc: 0.656250] [adversarial loss: 1.122472, acc: 0.312500]\n",
            "37994: [discriminator loss: 0.551164, acc: 0.679688] [adversarial loss: 1.077399, acc: 0.218750]\n",
            "37995: [discriminator loss: 0.558245, acc: 0.687500] [adversarial loss: 1.316829, acc: 0.203125]\n",
            "37996: [discriminator loss: 0.626802, acc: 0.609375] [adversarial loss: 0.954115, acc: 0.343750]\n",
            "37997: [discriminator loss: 0.576813, acc: 0.703125] [adversarial loss: 1.298576, acc: 0.171875]\n",
            "37998: [discriminator loss: 0.535985, acc: 0.757812] [adversarial loss: 1.103867, acc: 0.296875]\n",
            "37999: [discriminator loss: 0.596013, acc: 0.687500] [adversarial loss: 1.043905, acc: 0.359375]\n",
            "cgan_mnist  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
            "38000: [discriminator loss: 0.653610, acc: 0.562500] [adversarial loss: 1.205737, acc: 0.203125]\n",
            "38001: [discriminator loss: 0.614499, acc: 0.671875] [adversarial loss: 0.949000, acc: 0.359375]\n",
            "38002: [discriminator loss: 0.602301, acc: 0.625000] [adversarial loss: 1.236427, acc: 0.156250]\n",
            "38003: [discriminator loss: 0.617350, acc: 0.648438] [adversarial loss: 0.747857, acc: 0.593750]\n",
            "38004: [discriminator loss: 0.646086, acc: 0.601562] [adversarial loss: 1.263868, acc: 0.234375]\n",
            "38005: [discriminator loss: 0.595140, acc: 0.687500] [adversarial loss: 0.867183, acc: 0.437500]\n",
            "38006: [discriminator loss: 0.595102, acc: 0.687500] [adversarial loss: 0.985575, acc: 0.265625]\n",
            "38007: [discriminator loss: 0.612268, acc: 0.671875] [adversarial loss: 0.990983, acc: 0.296875]\n",
            "38008: [discriminator loss: 0.531379, acc: 0.750000] [adversarial loss: 1.127588, acc: 0.203125]\n",
            "38009: [discriminator loss: 0.567466, acc: 0.703125] [adversarial loss: 1.185505, acc: 0.171875]\n",
            "38010: [discriminator loss: 0.610977, acc: 0.695312] [adversarial loss: 0.936376, acc: 0.359375]\n",
            "38011: [discriminator loss: 0.594142, acc: 0.679688] [adversarial loss: 1.397237, acc: 0.140625]\n",
            "38012: [discriminator loss: 0.613820, acc: 0.640625] [adversarial loss: 1.001229, acc: 0.250000]\n",
            "38013: [discriminator loss: 0.537612, acc: 0.757812] [adversarial loss: 1.085983, acc: 0.296875]\n",
            "38014: [discriminator loss: 0.607856, acc: 0.679688] [adversarial loss: 1.239283, acc: 0.171875]\n",
            "38015: [discriminator loss: 0.512564, acc: 0.765625] [adversarial loss: 0.805076, acc: 0.406250]\n",
            "38016: [discriminator loss: 0.547424, acc: 0.742188] [adversarial loss: 1.097474, acc: 0.296875]\n",
            "38017: [discriminator loss: 0.584647, acc: 0.703125] [adversarial loss: 0.863577, acc: 0.359375]\n",
            "38018: [discriminator loss: 0.581053, acc: 0.671875] [adversarial loss: 0.933847, acc: 0.328125]\n",
            "38019: [discriminator loss: 0.591184, acc: 0.664062] [adversarial loss: 1.269322, acc: 0.203125]\n",
            "38020: [discriminator loss: 0.608479, acc: 0.648438] [adversarial loss: 0.893857, acc: 0.390625]\n",
            "38021: [discriminator loss: 0.622595, acc: 0.632812] [adversarial loss: 1.220707, acc: 0.250000]\n",
            "38022: [discriminator loss: 0.627322, acc: 0.687500] [adversarial loss: 0.976889, acc: 0.375000]\n",
            "38023: [discriminator loss: 0.598021, acc: 0.679688] [adversarial loss: 1.099836, acc: 0.265625]\n",
            "38024: [discriminator loss: 0.604886, acc: 0.632812] [adversarial loss: 1.098090, acc: 0.250000]\n",
            "38025: [discriminator loss: 0.585869, acc: 0.726562] [adversarial loss: 1.121537, acc: 0.171875]\n",
            "38026: [discriminator loss: 0.568490, acc: 0.710938] [adversarial loss: 0.939455, acc: 0.343750]\n",
            "38027: [discriminator loss: 0.586268, acc: 0.679688] [adversarial loss: 1.252741, acc: 0.093750]\n",
            "38028: [discriminator loss: 0.633917, acc: 0.648438] [adversarial loss: 0.999201, acc: 0.375000]\n",
            "38029: [discriminator loss: 0.565969, acc: 0.703125] [adversarial loss: 1.123971, acc: 0.281250]\n",
            "38030: [discriminator loss: 0.535064, acc: 0.750000] [adversarial loss: 1.097571, acc: 0.234375]\n",
            "38031: [discriminator loss: 0.540757, acc: 0.757812] [adversarial loss: 1.205331, acc: 0.250000]\n",
            "38032: [discriminator loss: 0.570642, acc: 0.695312] [adversarial loss: 1.043020, acc: 0.234375]\n",
            "38033: [discriminator loss: 0.556791, acc: 0.710938] [adversarial loss: 1.092966, acc: 0.187500]\n",
            "38034: [discriminator loss: 0.558408, acc: 0.742188] [adversarial loss: 0.785156, acc: 0.531250]\n",
            "38035: [discriminator loss: 0.584966, acc: 0.671875] [adversarial loss: 1.281911, acc: 0.203125]\n",
            "38036: [discriminator loss: 0.602685, acc: 0.656250] [adversarial loss: 0.733385, acc: 0.531250]\n",
            "38037: [discriminator loss: 0.610464, acc: 0.625000] [adversarial loss: 1.257169, acc: 0.187500]\n",
            "38038: [discriminator loss: 0.531207, acc: 0.703125] [adversarial loss: 0.908130, acc: 0.421875]\n",
            "38039: [discriminator loss: 0.599516, acc: 0.664062] [adversarial loss: 1.163289, acc: 0.250000]\n",
            "38040: [discriminator loss: 0.580937, acc: 0.703125] [adversarial loss: 0.950573, acc: 0.375000]\n",
            "38041: [discriminator loss: 0.570005, acc: 0.703125] [adversarial loss: 1.077919, acc: 0.296875]\n",
            "38042: [discriminator loss: 0.539813, acc: 0.726562] [adversarial loss: 1.168362, acc: 0.218750]\n",
            "38043: [discriminator loss: 0.634892, acc: 0.632812] [adversarial loss: 0.873760, acc: 0.406250]\n",
            "38044: [discriminator loss: 0.540291, acc: 0.718750] [adversarial loss: 1.139486, acc: 0.281250]\n",
            "38045: [discriminator loss: 0.638006, acc: 0.671875] [adversarial loss: 0.850689, acc: 0.421875]\n",
            "38046: [discriminator loss: 0.555605, acc: 0.726562] [adversarial loss: 1.190225, acc: 0.203125]\n",
            "38047: [discriminator loss: 0.576512, acc: 0.671875] [adversarial loss: 0.937652, acc: 0.328125]\n",
            "38048: [discriminator loss: 0.532767, acc: 0.726562] [adversarial loss: 0.934391, acc: 0.421875]\n",
            "38049: [discriminator loss: 0.590526, acc: 0.679688] [adversarial loss: 1.028495, acc: 0.296875]\n",
            "38050: [discriminator loss: 0.599748, acc: 0.671875] [adversarial loss: 1.131513, acc: 0.171875]\n",
            "38051: [discriminator loss: 0.556534, acc: 0.734375] [adversarial loss: 0.988391, acc: 0.296875]\n",
            "38052: [discriminator loss: 0.589891, acc: 0.687500] [adversarial loss: 1.167667, acc: 0.234375]\n",
            "38053: [discriminator loss: 0.534415, acc: 0.703125] [adversarial loss: 0.899771, acc: 0.453125]\n",
            "38054: [discriminator loss: 0.586618, acc: 0.664062] [adversarial loss: 1.045125, acc: 0.265625]\n",
            "38055: [discriminator loss: 0.568982, acc: 0.726562] [adversarial loss: 1.289783, acc: 0.156250]\n",
            "38056: [discriminator loss: 0.565940, acc: 0.664062] [adversarial loss: 1.082166, acc: 0.265625]\n",
            "38057: [discriminator loss: 0.554070, acc: 0.710938] [adversarial loss: 1.280653, acc: 0.203125]\n",
            "38058: [discriminator loss: 0.567369, acc: 0.703125] [adversarial loss: 1.110074, acc: 0.343750]\n",
            "38059: [discriminator loss: 0.561026, acc: 0.726562] [adversarial loss: 1.059856, acc: 0.296875]\n",
            "38060: [discriminator loss: 0.542045, acc: 0.671875] [adversarial loss: 0.931273, acc: 0.437500]\n",
            "38061: [discriminator loss: 0.592162, acc: 0.687500] [adversarial loss: 1.015219, acc: 0.296875]\n",
            "38062: [discriminator loss: 0.498680, acc: 0.789062] [adversarial loss: 1.285543, acc: 0.187500]\n",
            "38063: [discriminator loss: 0.592405, acc: 0.664062] [adversarial loss: 0.818158, acc: 0.437500]\n",
            "38064: [discriminator loss: 0.678545, acc: 0.640625] [adversarial loss: 1.265749, acc: 0.140625]\n",
            "38065: [discriminator loss: 0.656556, acc: 0.648438] [adversarial loss: 0.834193, acc: 0.437500]\n",
            "38066: [discriminator loss: 0.659448, acc: 0.617188] [adversarial loss: 1.257931, acc: 0.125000]\n",
            "38067: [discriminator loss: 0.581766, acc: 0.671875] [adversarial loss: 0.780190, acc: 0.546875]\n",
            "38068: [discriminator loss: 0.630251, acc: 0.632812] [adversarial loss: 1.331628, acc: 0.078125]\n",
            "38069: [discriminator loss: 0.572599, acc: 0.687500] [adversarial loss: 1.018097, acc: 0.312500]\n",
            "38070: [discriminator loss: 0.538780, acc: 0.695312] [adversarial loss: 0.944091, acc: 0.390625]\n",
            "38071: [discriminator loss: 0.599070, acc: 0.664062] [adversarial loss: 1.132864, acc: 0.125000]\n",
            "38072: [discriminator loss: 0.497067, acc: 0.796875] [adversarial loss: 0.966958, acc: 0.406250]\n",
            "38073: [discriminator loss: 0.601144, acc: 0.687500] [adversarial loss: 1.274195, acc: 0.203125]\n",
            "38074: [discriminator loss: 0.545448, acc: 0.679688] [adversarial loss: 1.087069, acc: 0.296875]\n",
            "38075: [discriminator loss: 0.639721, acc: 0.640625] [adversarial loss: 1.325575, acc: 0.109375]\n",
            "38076: [discriminator loss: 0.542121, acc: 0.726562] [adversarial loss: 0.815816, acc: 0.484375]\n",
            "38077: [discriminator loss: 0.549598, acc: 0.757812] [adversarial loss: 1.131365, acc: 0.312500]\n",
            "38078: [discriminator loss: 0.534025, acc: 0.718750] [adversarial loss: 0.980803, acc: 0.343750]\n",
            "38079: [discriminator loss: 0.590680, acc: 0.664062] [adversarial loss: 1.137900, acc: 0.203125]\n",
            "38080: [discriminator loss: 0.565255, acc: 0.671875] [adversarial loss: 0.954185, acc: 0.296875]\n",
            "38081: [discriminator loss: 0.585344, acc: 0.679688] [adversarial loss: 1.252203, acc: 0.171875]\n",
            "38082: [discriminator loss: 0.570638, acc: 0.664062] [adversarial loss: 1.055882, acc: 0.296875]\n",
            "38083: [discriminator loss: 0.584309, acc: 0.679688] [adversarial loss: 1.059910, acc: 0.187500]\n",
            "38084: [discriminator loss: 0.582130, acc: 0.734375] [adversarial loss: 1.140196, acc: 0.250000]\n",
            "38085: [discriminator loss: 0.583474, acc: 0.679688] [adversarial loss: 1.084769, acc: 0.281250]\n",
            "38086: [discriminator loss: 0.577461, acc: 0.640625] [adversarial loss: 0.821282, acc: 0.453125]\n",
            "38087: [discriminator loss: 0.513049, acc: 0.703125] [adversarial loss: 1.427949, acc: 0.093750]\n",
            "38088: [discriminator loss: 0.596528, acc: 0.687500] [adversarial loss: 0.935076, acc: 0.375000]\n",
            "38089: [discriminator loss: 0.578317, acc: 0.664062] [adversarial loss: 1.068441, acc: 0.312500]\n",
            "38090: [discriminator loss: 0.562080, acc: 0.687500] [adversarial loss: 0.990572, acc: 0.250000]\n",
            "38091: [discriminator loss: 0.575848, acc: 0.671875] [adversarial loss: 1.402807, acc: 0.140625]\n",
            "38092: [discriminator loss: 0.591177, acc: 0.640625] [adversarial loss: 1.255469, acc: 0.171875]\n",
            "38093: [discriminator loss: 0.575207, acc: 0.718750] [adversarial loss: 1.130191, acc: 0.281250]\n",
            "38094: [discriminator loss: 0.558105, acc: 0.695312] [adversarial loss: 0.821059, acc: 0.468750]\n",
            "38095: [discriminator loss: 0.605658, acc: 0.632812] [adversarial loss: 1.352406, acc: 0.187500]\n",
            "38096: [discriminator loss: 0.631912, acc: 0.687500] [adversarial loss: 0.809613, acc: 0.500000]\n",
            "38097: [discriminator loss: 0.584380, acc: 0.734375] [adversarial loss: 1.551813, acc: 0.093750]\n",
            "38098: [discriminator loss: 0.655062, acc: 0.632812] [adversarial loss: 0.958627, acc: 0.406250]\n",
            "38099: [discriminator loss: 0.626636, acc: 0.640625] [adversarial loss: 1.120352, acc: 0.312500]\n",
            "38100: [discriminator loss: 0.586361, acc: 0.671875] [adversarial loss: 1.102011, acc: 0.250000]\n",
            "38101: [discriminator loss: 0.583484, acc: 0.648438] [adversarial loss: 0.996452, acc: 0.328125]\n",
            "38102: [discriminator loss: 0.602588, acc: 0.679688] [adversarial loss: 1.007364, acc: 0.359375]\n",
            "38103: [discriminator loss: 0.536286, acc: 0.726562] [adversarial loss: 1.137370, acc: 0.203125]\n",
            "38104: [discriminator loss: 0.641674, acc: 0.632812] [adversarial loss: 1.175934, acc: 0.203125]\n",
            "38105: [discriminator loss: 0.570947, acc: 0.750000] [adversarial loss: 0.936454, acc: 0.390625]\n",
            "38106: [discriminator loss: 0.654258, acc: 0.625000] [adversarial loss: 1.098281, acc: 0.234375]\n",
            "38107: [discriminator loss: 0.585559, acc: 0.695312] [adversarial loss: 0.947636, acc: 0.375000]\n",
            "38108: [discriminator loss: 0.540872, acc: 0.750000] [adversarial loss: 1.238285, acc: 0.250000]\n",
            "38109: [discriminator loss: 0.574273, acc: 0.632812] [adversarial loss: 0.826609, acc: 0.453125]\n",
            "38110: [discriminator loss: 0.568005, acc: 0.679688] [adversarial loss: 1.227461, acc: 0.234375]\n",
            "38111: [discriminator loss: 0.597679, acc: 0.726562] [adversarial loss: 0.851647, acc: 0.546875]\n",
            "38112: [discriminator loss: 0.571114, acc: 0.710938] [adversarial loss: 1.140103, acc: 0.203125]\n",
            "38113: [discriminator loss: 0.578693, acc: 0.687500] [adversarial loss: 0.970052, acc: 0.406250]\n",
            "38114: [discriminator loss: 0.587728, acc: 0.734375] [adversarial loss: 1.344795, acc: 0.187500]\n",
            "38115: [discriminator loss: 0.585474, acc: 0.679688] [adversarial loss: 0.766615, acc: 0.609375]\n",
            "38116: [discriminator loss: 0.627713, acc: 0.632812] [adversarial loss: 1.448841, acc: 0.140625]\n",
            "38117: [discriminator loss: 0.581999, acc: 0.695312] [adversarial loss: 0.977896, acc: 0.312500]\n",
            "38118: [discriminator loss: 0.577431, acc: 0.703125] [adversarial loss: 1.151107, acc: 0.203125]\n",
            "38119: [discriminator loss: 0.565870, acc: 0.648438] [adversarial loss: 0.974565, acc: 0.328125]\n",
            "38120: [discriminator loss: 0.552102, acc: 0.710938] [adversarial loss: 1.159849, acc: 0.250000]\n",
            "38121: [discriminator loss: 0.563840, acc: 0.718750] [adversarial loss: 1.274323, acc: 0.250000]\n",
            "38122: [discriminator loss: 0.552250, acc: 0.679688] [adversarial loss: 0.882512, acc: 0.500000]\n",
            "38123: [discriminator loss: 0.614624, acc: 0.625000] [adversarial loss: 1.192812, acc: 0.203125]\n",
            "38124: [discriminator loss: 0.619387, acc: 0.656250] [adversarial loss: 0.911004, acc: 0.421875]\n",
            "38125: [discriminator loss: 0.546656, acc: 0.710938] [adversarial loss: 1.076639, acc: 0.171875]\n",
            "38126: [discriminator loss: 0.555014, acc: 0.710938] [adversarial loss: 1.259384, acc: 0.187500]\n",
            "38127: [discriminator loss: 0.556717, acc: 0.750000] [adversarial loss: 1.050606, acc: 0.359375]\n",
            "38128: [discriminator loss: 0.522397, acc: 0.757812] [adversarial loss: 1.070203, acc: 0.296875]\n",
            "38129: [discriminator loss: 0.597072, acc: 0.679688] [adversarial loss: 1.053987, acc: 0.343750]\n",
            "38130: [discriminator loss: 0.530918, acc: 0.718750] [adversarial loss: 1.241412, acc: 0.234375]\n",
            "38131: [discriminator loss: 0.666966, acc: 0.601562] [adversarial loss: 0.859731, acc: 0.453125]\n",
            "38132: [discriminator loss: 0.573918, acc: 0.671875] [adversarial loss: 1.152821, acc: 0.265625]\n",
            "38133: [discriminator loss: 0.519174, acc: 0.773438] [adversarial loss: 0.986542, acc: 0.281250]\n",
            "38134: [discriminator loss: 0.598635, acc: 0.656250] [adversarial loss: 1.312866, acc: 0.203125]\n",
            "38135: [discriminator loss: 0.570266, acc: 0.671875] [adversarial loss: 1.001153, acc: 0.390625]\n",
            "38136: [discriminator loss: 0.564720, acc: 0.703125] [adversarial loss: 1.243496, acc: 0.140625]\n",
            "38137: [discriminator loss: 0.556272, acc: 0.710938] [adversarial loss: 1.087126, acc: 0.312500]\n",
            "38138: [discriminator loss: 0.547817, acc: 0.687500] [adversarial loss: 1.021165, acc: 0.328125]\n",
            "38139: [discriminator loss: 0.603866, acc: 0.710938] [adversarial loss: 1.074871, acc: 0.343750]\n",
            "38140: [discriminator loss: 0.577860, acc: 0.679688] [adversarial loss: 1.115916, acc: 0.281250]\n",
            "38141: [discriminator loss: 0.624604, acc: 0.656250] [adversarial loss: 1.027888, acc: 0.312500]\n",
            "38142: [discriminator loss: 0.521269, acc: 0.742188] [adversarial loss: 0.878776, acc: 0.453125]\n",
            "38143: [discriminator loss: 0.606877, acc: 0.664062] [adversarial loss: 1.351036, acc: 0.156250]\n",
            "38144: [discriminator loss: 0.608945, acc: 0.648438] [adversarial loss: 0.932868, acc: 0.375000]\n",
            "38145: [discriminator loss: 0.617168, acc: 0.632812] [adversarial loss: 1.165601, acc: 0.218750]\n",
            "38146: [discriminator loss: 0.582224, acc: 0.671875] [adversarial loss: 1.083087, acc: 0.281250]\n",
            "38147: [discriminator loss: 0.576890, acc: 0.679688] [adversarial loss: 0.995198, acc: 0.250000]\n",
            "38148: [discriminator loss: 0.648237, acc: 0.640625] [adversarial loss: 1.019554, acc: 0.390625]\n",
            "38149: [discriminator loss: 0.562719, acc: 0.742188] [adversarial loss: 1.156251, acc: 0.234375]\n",
            "38150: [discriminator loss: 0.619262, acc: 0.632812] [adversarial loss: 0.883883, acc: 0.500000]\n",
            "38151: [discriminator loss: 0.607805, acc: 0.640625] [adversarial loss: 1.061742, acc: 0.265625]\n",
            "38152: [discriminator loss: 0.618592, acc: 0.664062] [adversarial loss: 0.979546, acc: 0.296875]\n",
            "38153: [discriminator loss: 0.551701, acc: 0.750000] [adversarial loss: 1.028052, acc: 0.328125]\n",
            "38154: [discriminator loss: 0.556847, acc: 0.718750] [adversarial loss: 1.166477, acc: 0.250000]\n",
            "38155: [discriminator loss: 0.499572, acc: 0.789062] [adversarial loss: 1.219739, acc: 0.218750]\n",
            "38156: [discriminator loss: 0.623010, acc: 0.679688] [adversarial loss: 0.936367, acc: 0.343750]\n",
            "38157: [discriminator loss: 0.631321, acc: 0.632812] [adversarial loss: 1.152800, acc: 0.218750]\n",
            "38158: [discriminator loss: 0.623640, acc: 0.671875] [adversarial loss: 0.956857, acc: 0.265625]\n",
            "38159: [discriminator loss: 0.545876, acc: 0.703125] [adversarial loss: 0.895861, acc: 0.312500]\n",
            "38160: [discriminator loss: 0.589231, acc: 0.687500] [adversarial loss: 0.892746, acc: 0.437500]\n",
            "38161: [discriminator loss: 0.553087, acc: 0.703125] [adversarial loss: 0.939430, acc: 0.343750]\n",
            "38162: [discriminator loss: 0.569625, acc: 0.695312] [adversarial loss: 1.120450, acc: 0.296875]\n",
            "38163: [discriminator loss: 0.596533, acc: 0.734375] [adversarial loss: 0.799467, acc: 0.437500]\n",
            "38164: [discriminator loss: 0.544082, acc: 0.742188] [adversarial loss: 1.235751, acc: 0.218750]\n",
            "38165: [discriminator loss: 0.622806, acc: 0.664062] [adversarial loss: 0.753943, acc: 0.546875]\n",
            "38166: [discriminator loss: 0.756929, acc: 0.570312] [adversarial loss: 1.165500, acc: 0.171875]\n",
            "38167: [discriminator loss: 0.653062, acc: 0.609375] [adversarial loss: 0.867124, acc: 0.406250]\n",
            "38168: [discriminator loss: 0.627687, acc: 0.625000] [adversarial loss: 1.280963, acc: 0.187500]\n",
            "38169: [discriminator loss: 0.549660, acc: 0.710938] [adversarial loss: 0.954152, acc: 0.375000]\n",
            "38170: [discriminator loss: 0.607052, acc: 0.703125] [adversarial loss: 1.202401, acc: 0.265625]\n",
            "38171: [discriminator loss: 0.583467, acc: 0.656250] [adversarial loss: 0.855574, acc: 0.437500]\n",
            "38172: [discriminator loss: 0.543718, acc: 0.687500] [adversarial loss: 1.004275, acc: 0.359375]\n",
            "38173: [discriminator loss: 0.593130, acc: 0.671875] [adversarial loss: 1.038110, acc: 0.328125]\n",
            "38174: [discriminator loss: 0.581840, acc: 0.687500] [adversarial loss: 1.253030, acc: 0.171875]\n",
            "38175: [discriminator loss: 0.556526, acc: 0.726562] [adversarial loss: 1.090092, acc: 0.218750]\n",
            "38176: [discriminator loss: 0.580477, acc: 0.679688] [adversarial loss: 0.967187, acc: 0.250000]\n",
            "38177: [discriminator loss: 0.597531, acc: 0.710938] [adversarial loss: 0.930807, acc: 0.281250]\n",
            "38178: [discriminator loss: 0.619682, acc: 0.632812] [adversarial loss: 1.034696, acc: 0.343750]\n",
            "38179: [discriminator loss: 0.590613, acc: 0.718750] [adversarial loss: 1.171907, acc: 0.312500]\n",
            "38180: [discriminator loss: 0.541453, acc: 0.718750] [adversarial loss: 0.895198, acc: 0.406250]\n",
            "38181: [discriminator loss: 0.568387, acc: 0.687500] [adversarial loss: 1.109473, acc: 0.234375]\n",
            "38182: [discriminator loss: 0.629593, acc: 0.664062] [adversarial loss: 0.908111, acc: 0.343750]\n",
            "38183: [discriminator loss: 0.607061, acc: 0.648438] [adversarial loss: 1.358669, acc: 0.140625]\n",
            "38184: [discriminator loss: 0.697618, acc: 0.554688] [adversarial loss: 0.912959, acc: 0.421875]\n",
            "38185: [discriminator loss: 0.606933, acc: 0.648438] [adversarial loss: 1.135995, acc: 0.203125]\n",
            "38186: [discriminator loss: 0.618685, acc: 0.656250] [adversarial loss: 1.314365, acc: 0.203125]\n",
            "38187: [discriminator loss: 0.577680, acc: 0.710938] [adversarial loss: 0.893320, acc: 0.406250]\n",
            "38188: [discriminator loss: 0.609010, acc: 0.625000] [adversarial loss: 1.091278, acc: 0.250000]\n",
            "38189: [discriminator loss: 0.630977, acc: 0.687500] [adversarial loss: 0.772055, acc: 0.484375]\n",
            "38190: [discriminator loss: 0.637390, acc: 0.617188] [adversarial loss: 1.392484, acc: 0.125000]\n",
            "38191: [discriminator loss: 0.629448, acc: 0.664062] [adversarial loss: 0.950924, acc: 0.500000]\n",
            "38192: [discriminator loss: 0.585266, acc: 0.656250] [adversarial loss: 1.272652, acc: 0.156250]\n",
            "38193: [discriminator loss: 0.640940, acc: 0.632812] [adversarial loss: 0.975219, acc: 0.437500]\n",
            "38194: [discriminator loss: 0.641080, acc: 0.671875] [adversarial loss: 1.166345, acc: 0.234375]\n",
            "38195: [discriminator loss: 0.628077, acc: 0.671875] [adversarial loss: 1.018905, acc: 0.343750]\n",
            "38196: [discriminator loss: 0.578357, acc: 0.671875] [adversarial loss: 0.960624, acc: 0.296875]\n",
            "38197: [discriminator loss: 0.586488, acc: 0.718750] [adversarial loss: 1.185006, acc: 0.265625]\n",
            "38198: [discriminator loss: 0.533261, acc: 0.679688] [adversarial loss: 1.022266, acc: 0.250000]\n",
            "38199: [discriminator loss: 0.647615, acc: 0.679688] [adversarial loss: 0.919588, acc: 0.375000]\n",
            "38200: [discriminator loss: 0.537335, acc: 0.765625] [adversarial loss: 1.059839, acc: 0.281250]\n",
            "38201: [discriminator loss: 0.547543, acc: 0.742188] [adversarial loss: 1.116948, acc: 0.203125]\n",
            "38202: [discriminator loss: 0.607849, acc: 0.695312] [adversarial loss: 0.977220, acc: 0.343750]\n",
            "38203: [discriminator loss: 0.585860, acc: 0.679688] [adversarial loss: 1.093399, acc: 0.234375]\n",
            "38204: [discriminator loss: 0.534755, acc: 0.734375] [adversarial loss: 1.349846, acc: 0.203125]\n",
            "38205: [discriminator loss: 0.577108, acc: 0.695312] [adversarial loss: 1.191290, acc: 0.171875]\n",
            "38206: [discriminator loss: 0.536588, acc: 0.718750] [adversarial loss: 1.168163, acc: 0.296875]\n",
            "38207: [discriminator loss: 0.583535, acc: 0.726562] [adversarial loss: 1.042808, acc: 0.187500]\n",
            "38208: [discriminator loss: 0.555372, acc: 0.703125] [adversarial loss: 0.890088, acc: 0.468750]\n",
            "38209: [discriminator loss: 0.529306, acc: 0.718750] [adversarial loss: 1.582807, acc: 0.093750]\n",
            "38210: [discriminator loss: 0.631437, acc: 0.656250] [adversarial loss: 0.766392, acc: 0.468750]\n",
            "38211: [discriminator loss: 0.600094, acc: 0.648438] [adversarial loss: 1.458695, acc: 0.109375]\n",
            "38212: [discriminator loss: 0.605395, acc: 0.617188] [adversarial loss: 0.909154, acc: 0.437500]\n",
            "38213: [discriminator loss: 0.535292, acc: 0.679688] [adversarial loss: 1.336180, acc: 0.218750]\n",
            "38214: [discriminator loss: 0.561417, acc: 0.695312] [adversarial loss: 0.998617, acc: 0.328125]\n",
            "38215: [discriminator loss: 0.623404, acc: 0.648438] [adversarial loss: 0.847168, acc: 0.390625]\n",
            "38216: [discriminator loss: 0.614769, acc: 0.671875] [adversarial loss: 1.183105, acc: 0.234375]\n",
            "38217: [discriminator loss: 0.560729, acc: 0.742188] [adversarial loss: 1.008147, acc: 0.328125]\n",
            "38218: [discriminator loss: 0.506904, acc: 0.773438] [adversarial loss: 1.173949, acc: 0.218750]\n",
            "38219: [discriminator loss: 0.617621, acc: 0.679688] [adversarial loss: 1.104575, acc: 0.265625]\n",
            "38220: [discriminator loss: 0.541185, acc: 0.726562] [adversarial loss: 0.946802, acc: 0.375000]\n",
            "38221: [discriminator loss: 0.631420, acc: 0.648438] [adversarial loss: 1.157863, acc: 0.250000]\n",
            "38222: [discriminator loss: 0.652408, acc: 0.640625] [adversarial loss: 0.893658, acc: 0.359375]\n",
            "38223: [discriminator loss: 0.635038, acc: 0.671875] [adversarial loss: 1.341758, acc: 0.140625]\n",
            "38224: [discriminator loss: 0.642336, acc: 0.617188] [adversarial loss: 0.938179, acc: 0.390625]\n",
            "38225: [discriminator loss: 0.622312, acc: 0.687500] [adversarial loss: 1.287342, acc: 0.171875]\n",
            "38226: [discriminator loss: 0.617597, acc: 0.617188] [adversarial loss: 0.971946, acc: 0.359375]\n",
            "38227: [discriminator loss: 0.594755, acc: 0.648438] [adversarial loss: 1.063326, acc: 0.281250]\n",
            "38228: [discriminator loss: 0.575205, acc: 0.710938] [adversarial loss: 0.786853, acc: 0.531250]\n",
            "38229: [discriminator loss: 0.608759, acc: 0.671875] [adversarial loss: 1.149056, acc: 0.250000]\n",
            "38230: [discriminator loss: 0.562058, acc: 0.656250] [adversarial loss: 0.977560, acc: 0.390625]\n",
            "38231: [discriminator loss: 0.589973, acc: 0.679688] [adversarial loss: 1.014365, acc: 0.406250]\n",
            "38232: [discriminator loss: 0.550785, acc: 0.750000] [adversarial loss: 1.025412, acc: 0.359375]\n",
            "38233: [discriminator loss: 0.519044, acc: 0.765625] [adversarial loss: 1.113703, acc: 0.296875]\n",
            "38234: [discriminator loss: 0.598729, acc: 0.656250] [adversarial loss: 1.315213, acc: 0.265625]\n",
            "38235: [discriminator loss: 0.589860, acc: 0.695312] [adversarial loss: 1.207124, acc: 0.281250]\n",
            "38236: [discriminator loss: 0.531826, acc: 0.726562] [adversarial loss: 1.076764, acc: 0.328125]\n",
            "38237: [discriminator loss: 0.615781, acc: 0.679688] [adversarial loss: 1.294351, acc: 0.187500]\n",
            "38238: [discriminator loss: 0.590682, acc: 0.687500] [adversarial loss: 0.871252, acc: 0.390625]\n",
            "38239: [discriminator loss: 0.667344, acc: 0.625000] [adversarial loss: 1.232083, acc: 0.234375]\n",
            "38240: [discriminator loss: 0.540581, acc: 0.726562] [adversarial loss: 0.907034, acc: 0.453125]\n",
            "38241: [discriminator loss: 0.573181, acc: 0.687500] [adversarial loss: 1.147669, acc: 0.234375]\n",
            "38242: [discriminator loss: 0.557354, acc: 0.679688] [adversarial loss: 1.005218, acc: 0.328125]\n",
            "38243: [discriminator loss: 0.593666, acc: 0.671875] [adversarial loss: 0.987945, acc: 0.359375]\n",
            "38244: [discriminator loss: 0.606464, acc: 0.640625] [adversarial loss: 0.972245, acc: 0.312500]\n",
            "38245: [discriminator loss: 0.621729, acc: 0.664062] [adversarial loss: 1.083221, acc: 0.312500]\n",
            "38246: [discriminator loss: 0.617564, acc: 0.632812] [adversarial loss: 0.952063, acc: 0.343750]\n",
            "38247: [discriminator loss: 0.524755, acc: 0.750000] [adversarial loss: 1.028638, acc: 0.343750]\n",
            "38248: [discriminator loss: 0.568548, acc: 0.734375] [adversarial loss: 1.153795, acc: 0.187500]\n",
            "38249: [discriminator loss: 0.543020, acc: 0.695312] [adversarial loss: 0.940467, acc: 0.390625]\n",
            "38250: [discriminator loss: 0.513036, acc: 0.750000] [adversarial loss: 1.216732, acc: 0.218750]\n",
            "38251: [discriminator loss: 0.567749, acc: 0.648438] [adversarial loss: 0.854502, acc: 0.359375]\n",
            "38252: [discriminator loss: 0.622256, acc: 0.664062] [adversarial loss: 1.194414, acc: 0.203125]\n",
            "38253: [discriminator loss: 0.634952, acc: 0.640625] [adversarial loss: 0.920729, acc: 0.390625]\n",
            "38254: [discriminator loss: 0.549654, acc: 0.695312] [adversarial loss: 1.139867, acc: 0.250000]\n",
            "38255: [discriminator loss: 0.587896, acc: 0.703125] [adversarial loss: 0.784620, acc: 0.484375]\n",
            "38256: [discriminator loss: 0.560530, acc: 0.687500] [adversarial loss: 1.240415, acc: 0.218750]\n",
            "38257: [discriminator loss: 0.621245, acc: 0.648438] [adversarial loss: 0.840868, acc: 0.453125]\n",
            "38258: [discriminator loss: 0.540340, acc: 0.703125] [adversarial loss: 1.298396, acc: 0.187500]\n",
            "38259: [discriminator loss: 0.578657, acc: 0.703125] [adversarial loss: 0.739179, acc: 0.625000]\n",
            "38260: [discriminator loss: 0.621914, acc: 0.648438] [adversarial loss: 1.294216, acc: 0.171875]\n",
            "38261: [discriminator loss: 0.572561, acc: 0.664062] [adversarial loss: 1.030257, acc: 0.359375]\n",
            "38262: [discriminator loss: 0.599116, acc: 0.648438] [adversarial loss: 0.872605, acc: 0.453125]\n",
            "38263: [discriminator loss: 0.552610, acc: 0.726562] [adversarial loss: 1.141041, acc: 0.359375]\n",
            "38264: [discriminator loss: 0.563727, acc: 0.781250] [adversarial loss: 1.004820, acc: 0.312500]\n",
            "38265: [discriminator loss: 0.602245, acc: 0.664062] [adversarial loss: 1.071949, acc: 0.250000]\n",
            "38266: [discriminator loss: 0.585811, acc: 0.742188] [adversarial loss: 1.065639, acc: 0.265625]\n",
            "38267: [discriminator loss: 0.585757, acc: 0.687500] [adversarial loss: 1.167690, acc: 0.187500]\n",
            "38268: [discriminator loss: 0.612065, acc: 0.664062] [adversarial loss: 1.036002, acc: 0.390625]\n",
            "38269: [discriminator loss: 0.626920, acc: 0.664062] [adversarial loss: 1.049937, acc: 0.375000]\n",
            "38270: [discriminator loss: 0.535116, acc: 0.703125] [adversarial loss: 0.971658, acc: 0.296875]\n",
            "38271: [discriminator loss: 0.577345, acc: 0.710938] [adversarial loss: 1.182281, acc: 0.187500]\n",
            "38272: [discriminator loss: 0.578459, acc: 0.656250] [adversarial loss: 1.086863, acc: 0.296875]\n",
            "38273: [discriminator loss: 0.584021, acc: 0.695312] [adversarial loss: 1.108973, acc: 0.265625]\n",
            "38274: [discriminator loss: 0.630575, acc: 0.640625] [adversarial loss: 1.128180, acc: 0.187500]\n",
            "38275: [discriminator loss: 0.596572, acc: 0.687500] [adversarial loss: 0.984841, acc: 0.312500]\n",
            "38276: [discriminator loss: 0.549353, acc: 0.734375] [adversarial loss: 1.148913, acc: 0.171875]\n",
            "38277: [discriminator loss: 0.573034, acc: 0.695312] [adversarial loss: 0.938918, acc: 0.421875]\n",
            "38278: [discriminator loss: 0.599054, acc: 0.695312] [adversarial loss: 1.552609, acc: 0.125000]\n",
            "38279: [discriminator loss: 0.583748, acc: 0.640625] [adversarial loss: 0.777458, acc: 0.484375]\n",
            "38280: [discriminator loss: 0.545521, acc: 0.726562] [adversarial loss: 1.293790, acc: 0.187500]\n",
            "38281: [discriminator loss: 0.547168, acc: 0.726562] [adversarial loss: 0.868814, acc: 0.500000]\n",
            "38282: [discriminator loss: 0.657835, acc: 0.593750] [adversarial loss: 1.204310, acc: 0.218750]\n",
            "38283: [discriminator loss: 0.537028, acc: 0.679688] [adversarial loss: 0.942408, acc: 0.500000]\n",
            "38284: [discriminator loss: 0.604738, acc: 0.664062] [adversarial loss: 1.071989, acc: 0.265625]\n",
            "38285: [discriminator loss: 0.591746, acc: 0.679688] [adversarial loss: 0.970628, acc: 0.343750]\n",
            "38286: [discriminator loss: 0.581424, acc: 0.679688] [adversarial loss: 1.238127, acc: 0.171875]\n",
            "38287: [discriminator loss: 0.636925, acc: 0.617188] [adversarial loss: 0.876500, acc: 0.421875]\n",
            "38288: [discriminator loss: 0.588227, acc: 0.656250] [adversarial loss: 1.166807, acc: 0.140625]\n",
            "38289: [discriminator loss: 0.547880, acc: 0.718750] [adversarial loss: 0.774742, acc: 0.468750]\n",
            "38290: [discriminator loss: 0.585678, acc: 0.679688] [adversarial loss: 1.221133, acc: 0.171875]\n",
            "38291: [discriminator loss: 0.562556, acc: 0.687500] [adversarial loss: 0.967409, acc: 0.390625]\n",
            "38292: [discriminator loss: 0.582458, acc: 0.703125] [adversarial loss: 1.156368, acc: 0.265625]\n",
            "38293: [discriminator loss: 0.565786, acc: 0.648438] [adversarial loss: 1.046242, acc: 0.281250]\n",
            "38294: [discriminator loss: 0.530416, acc: 0.710938] [adversarial loss: 1.284664, acc: 0.250000]\n",
            "38295: [discriminator loss: 0.629782, acc: 0.664062] [adversarial loss: 0.819240, acc: 0.421875]\n",
            "38296: [discriminator loss: 0.589775, acc: 0.695312] [adversarial loss: 1.075983, acc: 0.265625]\n",
            "38297: [discriminator loss: 0.562705, acc: 0.671875] [adversarial loss: 1.012109, acc: 0.296875]\n",
            "38298: [discriminator loss: 0.532231, acc: 0.765625] [adversarial loss: 0.889095, acc: 0.453125]\n",
            "38299: [discriminator loss: 0.570248, acc: 0.695312] [adversarial loss: 1.249799, acc: 0.218750]\n",
            "38300: [discriminator loss: 0.591802, acc: 0.703125] [adversarial loss: 0.738674, acc: 0.625000]\n",
            "38301: [discriminator loss: 0.575561, acc: 0.679688] [adversarial loss: 1.240713, acc: 0.140625]\n",
            "38302: [discriminator loss: 0.545242, acc: 0.710938] [adversarial loss: 0.881492, acc: 0.437500]\n",
            "38303: [discriminator loss: 0.621715, acc: 0.671875] [adversarial loss: 0.891627, acc: 0.406250]\n",
            "38304: [discriminator loss: 0.560896, acc: 0.718750] [adversarial loss: 1.097887, acc: 0.375000]\n",
            "38305: [discriminator loss: 0.530951, acc: 0.781250] [adversarial loss: 1.192302, acc: 0.296875]\n",
            "38306: [discriminator loss: 0.594416, acc: 0.648438] [adversarial loss: 1.087463, acc: 0.328125]\n",
            "38307: [discriminator loss: 0.609296, acc: 0.656250] [adversarial loss: 1.026617, acc: 0.296875]\n",
            "38308: [discriminator loss: 0.551516, acc: 0.710938] [adversarial loss: 1.017136, acc: 0.375000]\n",
            "38309: [discriminator loss: 0.571475, acc: 0.671875] [adversarial loss: 1.042809, acc: 0.343750]\n",
            "38310: [discriminator loss: 0.533580, acc: 0.734375] [adversarial loss: 1.214649, acc: 0.203125]\n",
            "38311: [discriminator loss: 0.544371, acc: 0.734375] [adversarial loss: 1.041399, acc: 0.312500]\n",
            "38312: [discriminator loss: 0.583515, acc: 0.734375] [adversarial loss: 1.185780, acc: 0.250000]\n",
            "38313: [discriminator loss: 0.575885, acc: 0.687500] [adversarial loss: 0.886046, acc: 0.453125]\n",
            "38314: [discriminator loss: 0.610663, acc: 0.695312] [adversarial loss: 1.085952, acc: 0.343750]\n",
            "38315: [discriminator loss: 0.644429, acc: 0.617188] [adversarial loss: 0.863232, acc: 0.406250]\n",
            "38316: [discriminator loss: 0.590337, acc: 0.695312] [adversarial loss: 1.301708, acc: 0.156250]\n",
            "38317: [discriminator loss: 0.540165, acc: 0.750000] [adversarial loss: 1.095692, acc: 0.375000]\n",
            "38318: [discriminator loss: 0.636785, acc: 0.632812] [adversarial loss: 1.004806, acc: 0.296875]\n",
            "38319: [discriminator loss: 0.626254, acc: 0.648438] [adversarial loss: 1.150145, acc: 0.203125]\n",
            "38320: [discriminator loss: 0.635290, acc: 0.671875] [adversarial loss: 0.926770, acc: 0.421875]\n",
            "38321: [discriminator loss: 0.562793, acc: 0.726562] [adversarial loss: 1.024701, acc: 0.312500]\n",
            "38322: [discriminator loss: 0.554296, acc: 0.710938] [adversarial loss: 0.971728, acc: 0.312500]\n",
            "38323: [discriminator loss: 0.582795, acc: 0.718750] [adversarial loss: 1.424852, acc: 0.171875]\n",
            "38324: [discriminator loss: 0.607279, acc: 0.601562] [adversarial loss: 0.677745, acc: 0.546875]\n",
            "38325: [discriminator loss: 0.604512, acc: 0.703125] [adversarial loss: 1.231393, acc: 0.140625]\n",
            "38326: [discriminator loss: 0.570449, acc: 0.656250] [adversarial loss: 0.978011, acc: 0.375000]\n",
            "38327: [discriminator loss: 0.560343, acc: 0.695312] [adversarial loss: 1.275518, acc: 0.281250]\n",
            "38328: [discriminator loss: 0.608443, acc: 0.656250] [adversarial loss: 0.936650, acc: 0.375000]\n",
            "38329: [discriminator loss: 0.546729, acc: 0.734375] [adversarial loss: 1.073858, acc: 0.328125]\n",
            "38330: [discriminator loss: 0.600164, acc: 0.671875] [adversarial loss: 1.058740, acc: 0.203125]\n",
            "38331: [discriminator loss: 0.614366, acc: 0.671875] [adversarial loss: 0.836143, acc: 0.406250]\n",
            "38332: [discriminator loss: 0.555397, acc: 0.734375] [adversarial loss: 0.869347, acc: 0.437500]\n",
            "38333: [discriminator loss: 0.544310, acc: 0.734375] [adversarial loss: 1.091982, acc: 0.359375]\n",
            "38334: [discriminator loss: 0.541240, acc: 0.734375] [adversarial loss: 1.159319, acc: 0.250000]\n",
            "38335: [discriminator loss: 0.553486, acc: 0.679688] [adversarial loss: 1.058139, acc: 0.328125]\n",
            "38336: [discriminator loss: 0.580645, acc: 0.718750] [adversarial loss: 1.363700, acc: 0.265625]\n",
            "38337: [discriminator loss: 0.597490, acc: 0.734375] [adversarial loss: 0.996441, acc: 0.296875]\n",
            "38338: [discriminator loss: 0.649508, acc: 0.617188] [adversarial loss: 1.047541, acc: 0.281250]\n",
            "38339: [discriminator loss: 0.562159, acc: 0.687500] [adversarial loss: 1.105255, acc: 0.296875]\n",
            "38340: [discriminator loss: 0.586797, acc: 0.695312] [adversarial loss: 0.908295, acc: 0.359375]\n",
            "38341: [discriminator loss: 0.636364, acc: 0.632812] [adversarial loss: 1.429290, acc: 0.171875]\n",
            "38342: [discriminator loss: 0.629309, acc: 0.625000] [adversarial loss: 0.831235, acc: 0.421875]\n",
            "38343: [discriminator loss: 0.621500, acc: 0.585938] [adversarial loss: 1.135731, acc: 0.265625]\n",
            "38344: [discriminator loss: 0.573784, acc: 0.687500] [adversarial loss: 1.046057, acc: 0.296875]\n",
            "38345: [discriminator loss: 0.561187, acc: 0.695312] [adversarial loss: 1.273082, acc: 0.234375]\n",
            "38346: [discriminator loss: 0.556607, acc: 0.757812] [adversarial loss: 1.017866, acc: 0.250000]\n",
            "38347: [discriminator loss: 0.567527, acc: 0.664062] [adversarial loss: 1.228101, acc: 0.218750]\n",
            "38348: [discriminator loss: 0.565481, acc: 0.718750] [adversarial loss: 1.055240, acc: 0.343750]\n",
            "38349: [discriminator loss: 0.559052, acc: 0.703125] [adversarial loss: 0.954833, acc: 0.328125]\n",
            "38350: [discriminator loss: 0.556516, acc: 0.757812] [adversarial loss: 1.125425, acc: 0.265625]\n",
            "38351: [discriminator loss: 0.511598, acc: 0.757812] [adversarial loss: 1.123099, acc: 0.281250]\n",
            "38352: [discriminator loss: 0.548539, acc: 0.734375] [adversarial loss: 1.417800, acc: 0.109375]\n",
            "38353: [discriminator loss: 0.575311, acc: 0.656250] [adversarial loss: 0.673802, acc: 0.593750]\n",
            "38354: [discriminator loss: 0.687048, acc: 0.585938] [adversarial loss: 1.474719, acc: 0.109375]\n",
            "38355: [discriminator loss: 0.565857, acc: 0.687500] [adversarial loss: 0.995924, acc: 0.390625]\n",
            "38356: [discriminator loss: 0.585818, acc: 0.718750] [adversarial loss: 1.110248, acc: 0.281250]\n",
            "38357: [discriminator loss: 0.606694, acc: 0.648438] [adversarial loss: 0.912167, acc: 0.343750]\n",
            "38358: [discriminator loss: 0.535905, acc: 0.734375] [adversarial loss: 1.364899, acc: 0.234375]\n",
            "38359: [discriminator loss: 0.559674, acc: 0.710938] [adversarial loss: 1.000561, acc: 0.328125]\n",
            "38360: [discriminator loss: 0.573099, acc: 0.664062] [adversarial loss: 1.103245, acc: 0.265625]\n",
            "38361: [discriminator loss: 0.624305, acc: 0.632812] [adversarial loss: 1.215586, acc: 0.203125]\n",
            "38362: [discriminator loss: 0.523940, acc: 0.718750] [adversarial loss: 0.954042, acc: 0.453125]\n",
            "38363: [discriminator loss: 0.618978, acc: 0.609375] [adversarial loss: 1.156798, acc: 0.281250]\n",
            "38364: [discriminator loss: 0.596896, acc: 0.656250] [adversarial loss: 0.934473, acc: 0.328125]\n",
            "38365: [discriminator loss: 0.598062, acc: 0.656250] [adversarial loss: 1.299017, acc: 0.218750]\n",
            "38366: [discriminator loss: 0.539353, acc: 0.703125] [adversarial loss: 1.109486, acc: 0.234375]\n",
            "38367: [discriminator loss: 0.554279, acc: 0.695312] [adversarial loss: 1.117455, acc: 0.281250]\n",
            "38368: [discriminator loss: 0.587555, acc: 0.687500] [adversarial loss: 0.891728, acc: 0.437500]\n",
            "38369: [discriminator loss: 0.566556, acc: 0.703125] [adversarial loss: 1.008874, acc: 0.359375]\n",
            "38370: [discriminator loss: 0.486777, acc: 0.796875] [adversarial loss: 1.134104, acc: 0.265625]\n",
            "38371: [discriminator loss: 0.538256, acc: 0.710938] [adversarial loss: 0.899045, acc: 0.406250]\n",
            "38372: [discriminator loss: 0.621474, acc: 0.625000] [adversarial loss: 1.129023, acc: 0.265625]\n",
            "38373: [discriminator loss: 0.600701, acc: 0.664062] [adversarial loss: 1.006995, acc: 0.359375]\n",
            "38374: [discriminator loss: 0.572677, acc: 0.687500] [adversarial loss: 0.893521, acc: 0.500000]\n",
            "38375: [discriminator loss: 0.584627, acc: 0.703125] [adversarial loss: 1.351266, acc: 0.187500]\n",
            "38376: [discriminator loss: 0.620896, acc: 0.671875] [adversarial loss: 0.839827, acc: 0.531250]\n",
            "38377: [discriminator loss: 0.599513, acc: 0.679688] [adversarial loss: 1.340616, acc: 0.171875]\n",
            "38378: [discriminator loss: 0.594960, acc: 0.679688] [adversarial loss: 0.869135, acc: 0.484375]\n",
            "38379: [discriminator loss: 0.678559, acc: 0.617188] [adversarial loss: 1.104446, acc: 0.234375]\n",
            "38380: [discriminator loss: 0.633013, acc: 0.625000] [adversarial loss: 1.085922, acc: 0.375000]\n",
            "38381: [discriminator loss: 0.561467, acc: 0.718750] [adversarial loss: 1.227001, acc: 0.203125]\n",
            "38382: [discriminator loss: 0.612190, acc: 0.664062] [adversarial loss: 0.992521, acc: 0.328125]\n",
            "38383: [discriminator loss: 0.580309, acc: 0.695312] [adversarial loss: 1.055107, acc: 0.265625]\n",
            "38384: [discriminator loss: 0.608047, acc: 0.679688] [adversarial loss: 0.945824, acc: 0.406250]\n",
            "38385: [discriminator loss: 0.594684, acc: 0.664062] [adversarial loss: 0.884138, acc: 0.359375]\n",
            "38386: [discriminator loss: 0.571360, acc: 0.703125] [adversarial loss: 0.882006, acc: 0.437500]\n",
            "38387: [discriminator loss: 0.608627, acc: 0.625000] [adversarial loss: 1.382661, acc: 0.203125]\n",
            "38388: [discriminator loss: 0.639628, acc: 0.640625] [adversarial loss: 0.757216, acc: 0.453125]\n",
            "38389: [discriminator loss: 0.628329, acc: 0.617188] [adversarial loss: 1.257674, acc: 0.171875]\n",
            "38390: [discriminator loss: 0.588971, acc: 0.679688] [adversarial loss: 0.959425, acc: 0.390625]\n",
            "38391: [discriminator loss: 0.577492, acc: 0.718750] [adversarial loss: 0.915543, acc: 0.359375]\n",
            "38392: [discriminator loss: 0.554868, acc: 0.757812] [adversarial loss: 0.924004, acc: 0.390625]\n",
            "38393: [discriminator loss: 0.585453, acc: 0.679688] [adversarial loss: 1.169263, acc: 0.187500]\n",
            "38394: [discriminator loss: 0.604135, acc: 0.632812] [adversarial loss: 0.997213, acc: 0.296875]\n",
            "38395: [discriminator loss: 0.611431, acc: 0.671875] [adversarial loss: 1.070602, acc: 0.281250]\n",
            "38396: [discriminator loss: 0.603381, acc: 0.679688] [adversarial loss: 1.070589, acc: 0.328125]\n",
            "38397: [discriminator loss: 0.514153, acc: 0.742188] [adversarial loss: 1.022914, acc: 0.281250]\n",
            "38398: [discriminator loss: 0.581676, acc: 0.648438] [adversarial loss: 1.123725, acc: 0.218750]\n",
            "38399: [discriminator loss: 0.581393, acc: 0.710938] [adversarial loss: 1.124667, acc: 0.203125]\n",
            "38400: [discriminator loss: 0.557389, acc: 0.687500] [adversarial loss: 1.089213, acc: 0.328125]\n",
            "38401: [discriminator loss: 0.641919, acc: 0.625000] [adversarial loss: 1.253831, acc: 0.093750]\n",
            "38402: [discriminator loss: 0.504750, acc: 0.781250] [adversarial loss: 1.108172, acc: 0.312500]\n",
            "38403: [discriminator loss: 0.633712, acc: 0.601562] [adversarial loss: 1.227530, acc: 0.125000]\n",
            "38404: [discriminator loss: 0.583025, acc: 0.710938] [adversarial loss: 0.934205, acc: 0.375000]\n",
            "38405: [discriminator loss: 0.650165, acc: 0.617188] [adversarial loss: 1.055260, acc: 0.250000]\n",
            "38406: [discriminator loss: 0.583512, acc: 0.695312] [adversarial loss: 0.942098, acc: 0.328125]\n",
            "38407: [discriminator loss: 0.622667, acc: 0.648438] [adversarial loss: 1.482673, acc: 0.156250]\n",
            "38408: [discriminator loss: 0.657784, acc: 0.601562] [adversarial loss: 0.777691, acc: 0.578125]\n",
            "38409: [discriminator loss: 0.516852, acc: 0.703125] [adversarial loss: 1.139737, acc: 0.203125]\n",
            "38410: [discriminator loss: 0.545292, acc: 0.718750] [adversarial loss: 0.990295, acc: 0.312500]\n",
            "38411: [discriminator loss: 0.604490, acc: 0.695312] [adversarial loss: 1.273500, acc: 0.218750]\n",
            "38412: [discriminator loss: 0.587153, acc: 0.664062] [adversarial loss: 0.964867, acc: 0.359375]\n",
            "38413: [discriminator loss: 0.512660, acc: 0.718750] [adversarial loss: 1.032692, acc: 0.312500]\n",
            "38414: [discriminator loss: 0.545859, acc: 0.765625] [adversarial loss: 1.004138, acc: 0.343750]\n",
            "38415: [discriminator loss: 0.611901, acc: 0.664062] [adversarial loss: 1.102312, acc: 0.296875]\n",
            "38416: [discriminator loss: 0.490720, acc: 0.765625] [adversarial loss: 1.133014, acc: 0.234375]\n",
            "38417: [discriminator loss: 0.670237, acc: 0.656250] [adversarial loss: 1.013742, acc: 0.328125]\n",
            "38418: [discriminator loss: 0.547094, acc: 0.687500] [adversarial loss: 0.971078, acc: 0.312500]\n",
            "38419: [discriminator loss: 0.644729, acc: 0.640625] [adversarial loss: 0.960150, acc: 0.343750]\n",
            "38420: [discriminator loss: 0.571822, acc: 0.703125] [adversarial loss: 1.127756, acc: 0.296875]\n",
            "38421: [discriminator loss: 0.584160, acc: 0.671875] [adversarial loss: 0.898297, acc: 0.390625]\n",
            "38422: [discriminator loss: 0.566972, acc: 0.734375] [adversarial loss: 1.435573, acc: 0.156250]\n",
            "38423: [discriminator loss: 0.520518, acc: 0.765625] [adversarial loss: 0.874202, acc: 0.437500]\n",
            "38424: [discriminator loss: 0.615194, acc: 0.703125] [adversarial loss: 1.397420, acc: 0.078125]\n",
            "38425: [discriminator loss: 0.600231, acc: 0.640625] [adversarial loss: 0.874020, acc: 0.390625]\n",
            "38426: [discriminator loss: 0.567528, acc: 0.703125] [adversarial loss: 1.351485, acc: 0.171875]\n",
            "38427: [discriminator loss: 0.562932, acc: 0.671875] [adversarial loss: 0.848438, acc: 0.453125]\n",
            "38428: [discriminator loss: 0.612605, acc: 0.671875] [adversarial loss: 1.144222, acc: 0.296875]\n",
            "38429: [discriminator loss: 0.593624, acc: 0.656250] [adversarial loss: 1.046628, acc: 0.312500]\n",
            "38430: [discriminator loss: 0.609199, acc: 0.679688] [adversarial loss: 1.001094, acc: 0.328125]\n",
            "38431: [discriminator loss: 0.550723, acc: 0.671875] [adversarial loss: 1.095743, acc: 0.343750]\n",
            "38432: [discriminator loss: 0.576634, acc: 0.687500] [adversarial loss: 1.271395, acc: 0.171875]\n",
            "38433: [discriminator loss: 0.623242, acc: 0.695312] [adversarial loss: 0.807393, acc: 0.484375]\n",
            "38434: [discriminator loss: 0.576887, acc: 0.695312] [adversarial loss: 1.344681, acc: 0.109375]\n",
            "38435: [discriminator loss: 0.643257, acc: 0.617188] [adversarial loss: 0.976961, acc: 0.281250]\n",
            "38436: [discriminator loss: 0.544646, acc: 0.742188] [adversarial loss: 1.009005, acc: 0.328125]\n",
            "38437: [discriminator loss: 0.533577, acc: 0.687500] [adversarial loss: 0.858330, acc: 0.343750]\n",
            "38438: [discriminator loss: 0.572523, acc: 0.656250] [adversarial loss: 1.396350, acc: 0.187500]\n",
            "38439: [discriminator loss: 0.627975, acc: 0.648438] [adversarial loss: 0.772006, acc: 0.546875]\n",
            "38440: [discriminator loss: 0.644454, acc: 0.625000] [adversarial loss: 1.192886, acc: 0.312500]\n",
            "38441: [discriminator loss: 0.519654, acc: 0.734375] [adversarial loss: 1.006827, acc: 0.437500]\n",
            "38442: [discriminator loss: 0.584393, acc: 0.687500] [adversarial loss: 1.160369, acc: 0.281250]\n",
            "38443: [discriminator loss: 0.539853, acc: 0.773438] [adversarial loss: 1.056077, acc: 0.281250]\n",
            "38444: [discriminator loss: 0.545705, acc: 0.703125] [adversarial loss: 1.172392, acc: 0.359375]\n",
            "38445: [discriminator loss: 0.565448, acc: 0.671875] [adversarial loss: 1.043283, acc: 0.312500]\n",
            "38446: [discriminator loss: 0.619243, acc: 0.617188] [adversarial loss: 1.074507, acc: 0.234375]\n",
            "38447: [discriminator loss: 0.627791, acc: 0.617188] [adversarial loss: 1.064730, acc: 0.343750]\n",
            "38448: [discriminator loss: 0.549621, acc: 0.734375] [adversarial loss: 0.930001, acc: 0.406250]\n",
            "38449: [discriminator loss: 0.534319, acc: 0.703125] [adversarial loss: 1.238187, acc: 0.281250]\n",
            "38450: [discriminator loss: 0.653371, acc: 0.609375] [adversarial loss: 1.115623, acc: 0.265625]\n",
            "38451: [discriminator loss: 0.557521, acc: 0.718750] [adversarial loss: 1.228012, acc: 0.187500]\n",
            "38452: [discriminator loss: 0.520605, acc: 0.757812] [adversarial loss: 0.987550, acc: 0.265625]\n",
            "38453: [discriminator loss: 0.685752, acc: 0.609375] [adversarial loss: 1.116416, acc: 0.281250]\n",
            "38454: [discriminator loss: 0.559319, acc: 0.750000] [adversarial loss: 1.037540, acc: 0.375000]\n",
            "38455: [discriminator loss: 0.613274, acc: 0.671875] [adversarial loss: 0.840719, acc: 0.406250]\n",
            "38456: [discriminator loss: 0.549876, acc: 0.726562] [adversarial loss: 1.203742, acc: 0.250000]\n",
            "38457: [discriminator loss: 0.628940, acc: 0.687500] [adversarial loss: 0.843177, acc: 0.437500]\n",
            "38458: [discriminator loss: 0.551881, acc: 0.703125] [adversarial loss: 1.177139, acc: 0.296875]\n",
            "38459: [discriminator loss: 0.649655, acc: 0.632812] [adversarial loss: 0.954488, acc: 0.421875]\n",
            "38460: [discriminator loss: 0.618392, acc: 0.640625] [adversarial loss: 1.011196, acc: 0.265625]\n",
            "38461: [discriminator loss: 0.612466, acc: 0.648438] [adversarial loss: 0.884160, acc: 0.437500]\n",
            "38462: [discriminator loss: 0.537130, acc: 0.750000] [adversarial loss: 1.327821, acc: 0.296875]\n",
            "38463: [discriminator loss: 0.495204, acc: 0.773438] [adversarial loss: 1.040524, acc: 0.265625]\n",
            "38464: [discriminator loss: 0.577340, acc: 0.679688] [adversarial loss: 1.214598, acc: 0.281250]\n",
            "38465: [discriminator loss: 0.677672, acc: 0.617188] [adversarial loss: 1.066589, acc: 0.281250]\n",
            "38466: [discriminator loss: 0.620527, acc: 0.601562] [adversarial loss: 0.988830, acc: 0.375000]\n",
            "38467: [discriminator loss: 0.573695, acc: 0.718750] [adversarial loss: 1.184308, acc: 0.296875]\n",
            "38468: [discriminator loss: 0.611402, acc: 0.695312] [adversarial loss: 0.988998, acc: 0.390625]\n",
            "38469: [discriminator loss: 0.659601, acc: 0.632812] [adversarial loss: 0.948012, acc: 0.421875]\n",
            "38470: [discriminator loss: 0.613472, acc: 0.671875] [adversarial loss: 1.028369, acc: 0.281250]\n",
            "38471: [discriminator loss: 0.582137, acc: 0.671875] [adversarial loss: 1.350121, acc: 0.171875]\n",
            "38472: [discriminator loss: 0.603600, acc: 0.625000] [adversarial loss: 0.931914, acc: 0.359375]\n",
            "38473: [discriminator loss: 0.598195, acc: 0.679688] [adversarial loss: 1.008756, acc: 0.218750]\n",
            "38474: [discriminator loss: 0.588305, acc: 0.726562] [adversarial loss: 0.969928, acc: 0.343750]\n",
            "38475: [discriminator loss: 0.584437, acc: 0.679688] [adversarial loss: 1.214559, acc: 0.140625]\n",
            "38476: [discriminator loss: 0.604361, acc: 0.664062] [adversarial loss: 0.767591, acc: 0.562500]\n",
            "38477: [discriminator loss: 0.545300, acc: 0.757812] [adversarial loss: 1.170144, acc: 0.218750]\n",
            "38478: [discriminator loss: 0.547483, acc: 0.710938] [adversarial loss: 1.065203, acc: 0.281250]\n",
            "38479: [discriminator loss: 0.531690, acc: 0.742188] [adversarial loss: 0.915149, acc: 0.421875]\n",
            "38480: [discriminator loss: 0.626836, acc: 0.625000] [adversarial loss: 1.019371, acc: 0.296875]\n",
            "38481: [discriminator loss: 0.574919, acc: 0.742188] [adversarial loss: 0.840758, acc: 0.421875]\n",
            "38482: [discriminator loss: 0.628594, acc: 0.640625] [adversarial loss: 1.318484, acc: 0.203125]\n",
            "38483: [discriminator loss: 0.583788, acc: 0.687500] [adversarial loss: 1.260447, acc: 0.296875]\n",
            "38484: [discriminator loss: 0.534771, acc: 0.679688] [adversarial loss: 1.182281, acc: 0.250000]\n",
            "38485: [discriminator loss: 0.588516, acc: 0.687500] [adversarial loss: 1.287004, acc: 0.234375]\n",
            "38486: [discriminator loss: 0.573983, acc: 0.648438] [adversarial loss: 0.932038, acc: 0.390625]\n",
            "38487: [discriminator loss: 0.622009, acc: 0.656250] [adversarial loss: 1.259743, acc: 0.218750]\n",
            "38488: [discriminator loss: 0.580473, acc: 0.679688] [adversarial loss: 0.969900, acc: 0.343750]\n",
            "38489: [discriminator loss: 0.556725, acc: 0.710938] [adversarial loss: 1.171908, acc: 0.234375]\n",
            "38490: [discriminator loss: 0.545676, acc: 0.718750] [adversarial loss: 1.062057, acc: 0.296875]\n",
            "38491: [discriminator loss: 0.639624, acc: 0.617188] [adversarial loss: 1.155512, acc: 0.265625]\n",
            "38492: [discriminator loss: 0.594747, acc: 0.679688] [adversarial loss: 0.909122, acc: 0.406250]\n",
            "38493: [discriminator loss: 0.584679, acc: 0.648438] [adversarial loss: 1.129432, acc: 0.250000]\n",
            "38494: [discriminator loss: 0.586706, acc: 0.664062] [adversarial loss: 1.041880, acc: 0.390625]\n",
            "38495: [discriminator loss: 0.600995, acc: 0.679688] [adversarial loss: 1.171457, acc: 0.234375]\n",
            "38496: [discriminator loss: 0.592655, acc: 0.695312] [adversarial loss: 0.962310, acc: 0.406250]\n",
            "38497: [discriminator loss: 0.579226, acc: 0.687500] [adversarial loss: 1.495210, acc: 0.078125]\n",
            "38498: [discriminator loss: 0.571419, acc: 0.664062] [adversarial loss: 0.792076, acc: 0.500000]\n",
            "38499: [discriminator loss: 0.545943, acc: 0.750000] [adversarial loss: 1.067993, acc: 0.328125]\n",
            "38500: [discriminator loss: 0.569636, acc: 0.687500] [adversarial loss: 0.886131, acc: 0.343750]\n",
            "38501: [discriminator loss: 0.593936, acc: 0.726562] [adversarial loss: 1.169509, acc: 0.265625]\n",
            "38502: [discriminator loss: 0.580749, acc: 0.718750] [adversarial loss: 0.923921, acc: 0.406250]\n",
            "38503: [discriminator loss: 0.610640, acc: 0.617188] [adversarial loss: 1.078419, acc: 0.281250]\n",
            "38504: [discriminator loss: 0.630463, acc: 0.640625] [adversarial loss: 1.114348, acc: 0.265625]\n",
            "38505: [discriminator loss: 0.625613, acc: 0.679688] [adversarial loss: 1.121254, acc: 0.250000]\n",
            "38506: [discriminator loss: 0.579807, acc: 0.695312] [adversarial loss: 0.991505, acc: 0.296875]\n",
            "38507: [discriminator loss: 0.548335, acc: 0.710938] [adversarial loss: 1.346663, acc: 0.218750]\n",
            "38508: [discriminator loss: 0.489784, acc: 0.734375] [adversarial loss: 0.906247, acc: 0.453125]\n",
            "38509: [discriminator loss: 0.625147, acc: 0.632812] [adversarial loss: 1.401831, acc: 0.156250]\n",
            "38510: [discriminator loss: 0.609676, acc: 0.695312] [adversarial loss: 0.970666, acc: 0.390625]\n",
            "38511: [discriminator loss: 0.632689, acc: 0.601562] [adversarial loss: 1.174381, acc: 0.250000]\n",
            "38512: [discriminator loss: 0.635507, acc: 0.617188] [adversarial loss: 0.859825, acc: 0.390625]\n",
            "38513: [discriminator loss: 0.535087, acc: 0.734375] [adversarial loss: 1.442378, acc: 0.171875]\n",
            "38514: [discriminator loss: 0.637964, acc: 0.640625] [adversarial loss: 0.950763, acc: 0.406250]\n",
            "38515: [discriminator loss: 0.619300, acc: 0.632812] [adversarial loss: 1.251691, acc: 0.218750]\n",
            "38516: [discriminator loss: 0.624925, acc: 0.687500] [adversarial loss: 1.241112, acc: 0.250000]\n",
            "38517: [discriminator loss: 0.576380, acc: 0.687500] [adversarial loss: 0.939194, acc: 0.375000]\n",
            "38518: [discriminator loss: 0.595703, acc: 0.617188] [adversarial loss: 1.160386, acc: 0.281250]\n",
            "38519: [discriminator loss: 0.597227, acc: 0.671875] [adversarial loss: 0.979916, acc: 0.312500]\n",
            "38520: [discriminator loss: 0.574264, acc: 0.687500] [adversarial loss: 1.127815, acc: 0.312500]\n",
            "38521: [discriminator loss: 0.607320, acc: 0.640625] [adversarial loss: 1.075865, acc: 0.343750]\n",
            "38522: [discriminator loss: 0.554599, acc: 0.742188] [adversarial loss: 1.219553, acc: 0.203125]\n",
            "38523: [discriminator loss: 0.589352, acc: 0.648438] [adversarial loss: 0.887951, acc: 0.375000]\n",
            "38524: [discriminator loss: 0.562813, acc: 0.742188] [adversarial loss: 1.281146, acc: 0.156250]\n",
            "38525: [discriminator loss: 0.591629, acc: 0.656250] [adversarial loss: 1.016750, acc: 0.281250]\n",
            "38526: [discriminator loss: 0.560055, acc: 0.695312] [adversarial loss: 0.970463, acc: 0.390625]\n",
            "38527: [discriminator loss: 0.579881, acc: 0.632812] [adversarial loss: 0.934818, acc: 0.406250]\n",
            "38528: [discriminator loss: 0.602104, acc: 0.695312] [adversarial loss: 1.077555, acc: 0.218750]\n",
            "38529: [discriminator loss: 0.594974, acc: 0.671875] [adversarial loss: 0.942281, acc: 0.390625]\n",
            "38530: [discriminator loss: 0.548675, acc: 0.703125] [adversarial loss: 1.280472, acc: 0.171875]\n",
            "38531: [discriminator loss: 0.568003, acc: 0.687500] [adversarial loss: 0.839135, acc: 0.437500]\n",
            "38532: [discriminator loss: 0.607522, acc: 0.664062] [adversarial loss: 1.232032, acc: 0.250000]\n",
            "38533: [discriminator loss: 0.564825, acc: 0.703125] [adversarial loss: 0.998479, acc: 0.343750]\n",
            "38534: [discriminator loss: 0.564699, acc: 0.671875] [adversarial loss: 1.141615, acc: 0.250000]\n",
            "38535: [discriminator loss: 0.610871, acc: 0.687500] [adversarial loss: 0.934721, acc: 0.406250]\n",
            "38536: [discriminator loss: 0.578167, acc: 0.718750] [adversarial loss: 1.541099, acc: 0.093750]\n",
            "38537: [discriminator loss: 0.625044, acc: 0.593750] [adversarial loss: 0.778698, acc: 0.531250]\n",
            "38538: [discriminator loss: 0.574090, acc: 0.687500] [adversarial loss: 1.209810, acc: 0.140625]\n",
            "38539: [discriminator loss: 0.548155, acc: 0.710938] [adversarial loss: 0.861807, acc: 0.421875]\n",
            "38540: [discriminator loss: 0.562181, acc: 0.710938] [adversarial loss: 1.294107, acc: 0.125000]\n",
            "38541: [discriminator loss: 0.578636, acc: 0.695312] [adversarial loss: 0.800735, acc: 0.468750]\n",
            "38542: [discriminator loss: 0.560661, acc: 0.710938] [adversarial loss: 1.084936, acc: 0.203125]\n",
            "38543: [discriminator loss: 0.569274, acc: 0.703125] [adversarial loss: 0.906739, acc: 0.421875]\n",
            "38544: [discriminator loss: 0.578119, acc: 0.742188] [adversarial loss: 0.938135, acc: 0.296875]\n",
            "38545: [discriminator loss: 0.551629, acc: 0.726562] [adversarial loss: 1.108967, acc: 0.281250]\n",
            "38546: [discriminator loss: 0.562331, acc: 0.703125] [adversarial loss: 0.776937, acc: 0.437500]\n",
            "38547: [discriminator loss: 0.570606, acc: 0.703125] [adversarial loss: 1.188662, acc: 0.187500]\n",
            "38548: [discriminator loss: 0.600494, acc: 0.625000] [adversarial loss: 0.883231, acc: 0.453125]\n",
            "38549: [discriminator loss: 0.563255, acc: 0.656250] [adversarial loss: 1.157059, acc: 0.250000]\n",
            "38550: [discriminator loss: 0.577968, acc: 0.671875] [adversarial loss: 0.991769, acc: 0.359375]\n",
            "38551: [discriminator loss: 0.606381, acc: 0.679688] [adversarial loss: 1.309854, acc: 0.156250]\n",
            "38552: [discriminator loss: 0.556316, acc: 0.710938] [adversarial loss: 1.221195, acc: 0.250000]\n",
            "38553: [discriminator loss: 0.621014, acc: 0.664062] [adversarial loss: 1.058751, acc: 0.359375]\n",
            "38554: [discriminator loss: 0.600835, acc: 0.664062] [adversarial loss: 1.189397, acc: 0.156250]\n",
            "38555: [discriminator loss: 0.623037, acc: 0.664062] [adversarial loss: 1.234225, acc: 0.187500]\n",
            "38556: [discriminator loss: 0.623936, acc: 0.648438] [adversarial loss: 1.018466, acc: 0.328125]\n",
            "38557: [discriminator loss: 0.603330, acc: 0.648438] [adversarial loss: 1.364105, acc: 0.125000]\n",
            "38558: [discriminator loss: 0.619639, acc: 0.656250] [adversarial loss: 0.739604, acc: 0.515625]\n",
            "38559: [discriminator loss: 0.542024, acc: 0.750000] [adversarial loss: 1.053371, acc: 0.343750]\n",
            "38560: [discriminator loss: 0.597840, acc: 0.656250] [adversarial loss: 1.077274, acc: 0.234375]\n",
            "38561: [discriminator loss: 0.541717, acc: 0.671875] [adversarial loss: 1.099513, acc: 0.218750]\n",
            "38562: [discriminator loss: 0.525854, acc: 0.773438] [adversarial loss: 1.088348, acc: 0.296875]\n",
            "38563: [discriminator loss: 0.584540, acc: 0.718750] [adversarial loss: 1.063551, acc: 0.296875]\n",
            "38564: [discriminator loss: 0.628847, acc: 0.625000] [adversarial loss: 0.982400, acc: 0.296875]\n",
            "38565: [discriminator loss: 0.572683, acc: 0.734375] [adversarial loss: 1.038372, acc: 0.281250]\n",
            "38566: [discriminator loss: 0.552130, acc: 0.703125] [adversarial loss: 0.970959, acc: 0.453125]\n",
            "38567: [discriminator loss: 0.608786, acc: 0.648438] [adversarial loss: 1.273126, acc: 0.187500]\n",
            "38568: [discriminator loss: 0.611509, acc: 0.671875] [adversarial loss: 0.771383, acc: 0.500000]\n",
            "38569: [discriminator loss: 0.589333, acc: 0.687500] [adversarial loss: 1.330285, acc: 0.109375]\n",
            "38570: [discriminator loss: 0.575467, acc: 0.656250] [adversarial loss: 0.757662, acc: 0.515625]\n",
            "38571: [discriminator loss: 0.598631, acc: 0.671875] [adversarial loss: 1.092933, acc: 0.281250]\n",
            "38572: [discriminator loss: 0.575781, acc: 0.671875] [adversarial loss: 0.994895, acc: 0.406250]\n",
            "38573: [discriminator loss: 0.543649, acc: 0.726562] [adversarial loss: 0.933379, acc: 0.390625]\n",
            "38574: [discriminator loss: 0.556708, acc: 0.679688] [adversarial loss: 1.096113, acc: 0.359375]\n",
            "38575: [discriminator loss: 0.568315, acc: 0.718750] [adversarial loss: 1.098707, acc: 0.328125]\n",
            "38576: [discriminator loss: 0.591842, acc: 0.695312] [adversarial loss: 1.187981, acc: 0.171875]\n",
            "38577: [discriminator loss: 0.572577, acc: 0.710938] [adversarial loss: 1.035992, acc: 0.312500]\n",
            "38578: [discriminator loss: 0.489416, acc: 0.781250] [adversarial loss: 0.952034, acc: 0.328125]\n",
            "38579: [discriminator loss: 0.553625, acc: 0.718750] [adversarial loss: 1.255172, acc: 0.250000]\n",
            "38580: [discriminator loss: 0.635512, acc: 0.625000] [adversarial loss: 0.826986, acc: 0.593750]\n",
            "38581: [discriminator loss: 0.598017, acc: 0.710938] [adversarial loss: 1.583161, acc: 0.125000]\n",
            "38582: [discriminator loss: 0.643640, acc: 0.625000] [adversarial loss: 0.876820, acc: 0.421875]\n",
            "38583: [discriminator loss: 0.619859, acc: 0.609375] [adversarial loss: 1.348126, acc: 0.171875]\n",
            "38584: [discriminator loss: 0.509413, acc: 0.757812] [adversarial loss: 0.955187, acc: 0.390625]\n",
            "38585: [discriminator loss: 0.548823, acc: 0.750000] [adversarial loss: 1.163490, acc: 0.281250]\n",
            "38586: [discriminator loss: 0.597742, acc: 0.664062] [adversarial loss: 0.911982, acc: 0.421875]\n",
            "38587: [discriminator loss: 0.648722, acc: 0.632812] [adversarial loss: 1.280849, acc: 0.171875]\n",
            "38588: [discriminator loss: 0.520271, acc: 0.703125] [adversarial loss: 1.082216, acc: 0.265625]\n",
            "38589: [discriminator loss: 0.583341, acc: 0.671875] [adversarial loss: 0.881067, acc: 0.375000]\n",
            "38590: [discriminator loss: 0.633052, acc: 0.648438] [adversarial loss: 1.352565, acc: 0.203125]\n",
            "38591: [discriminator loss: 0.597224, acc: 0.687500] [adversarial loss: 0.989255, acc: 0.265625]\n",
            "38592: [discriminator loss: 0.611527, acc: 0.648438] [adversarial loss: 1.114250, acc: 0.250000]\n",
            "38593: [discriminator loss: 0.573879, acc: 0.687500] [adversarial loss: 0.888717, acc: 0.437500]\n",
            "38594: [discriminator loss: 0.665664, acc: 0.562500] [adversarial loss: 1.011192, acc: 0.250000]\n",
            "38595: [discriminator loss: 0.548505, acc: 0.718750] [adversarial loss: 0.873435, acc: 0.453125]\n",
            "38596: [discriminator loss: 0.532001, acc: 0.718750] [adversarial loss: 1.068327, acc: 0.265625]\n",
            "38597: [discriminator loss: 0.571169, acc: 0.656250] [adversarial loss: 1.126731, acc: 0.250000]\n",
            "38598: [discriminator loss: 0.629447, acc: 0.671875] [adversarial loss: 1.299496, acc: 0.203125]\n",
            "38599: [discriminator loss: 0.600945, acc: 0.625000] [adversarial loss: 0.743382, acc: 0.562500]\n",
            "38600: [discriminator loss: 0.650091, acc: 0.625000] [adversarial loss: 1.522056, acc: 0.062500]\n",
            "38601: [discriminator loss: 0.602741, acc: 0.671875] [adversarial loss: 0.972600, acc: 0.437500]\n",
            "38602: [discriminator loss: 0.570173, acc: 0.726562] [adversarial loss: 1.098298, acc: 0.203125]\n",
            "38603: [discriminator loss: 0.567143, acc: 0.687500] [adversarial loss: 0.844786, acc: 0.421875]\n",
            "38604: [discriminator loss: 0.553801, acc: 0.726562] [adversarial loss: 1.300495, acc: 0.171875]\n",
            "38605: [discriminator loss: 0.518499, acc: 0.718750] [adversarial loss: 1.024045, acc: 0.312500]\n",
            "38606: [discriminator loss: 0.557181, acc: 0.734375] [adversarial loss: 1.201546, acc: 0.171875]\n",
            "38607: [discriminator loss: 0.571411, acc: 0.710938] [adversarial loss: 0.985506, acc: 0.437500]\n",
            "38608: [discriminator loss: 0.525717, acc: 0.726562] [adversarial loss: 1.459399, acc: 0.078125]\n",
            "38609: [discriminator loss: 0.566114, acc: 0.679688] [adversarial loss: 0.899429, acc: 0.390625]\n",
            "38610: [discriminator loss: 0.645146, acc: 0.609375] [adversarial loss: 1.053570, acc: 0.296875]\n",
            "38611: [discriminator loss: 0.553337, acc: 0.703125] [adversarial loss: 0.989875, acc: 0.312500]\n",
            "38612: [discriminator loss: 0.554096, acc: 0.734375] [adversarial loss: 1.065583, acc: 0.343750]\n",
            "38613: [discriminator loss: 0.572756, acc: 0.679688] [adversarial loss: 1.189450, acc: 0.343750]\n",
            "38614: [discriminator loss: 0.588037, acc: 0.656250] [adversarial loss: 0.972208, acc: 0.343750]\n",
            "38615: [discriminator loss: 0.556581, acc: 0.734375] [adversarial loss: 1.222054, acc: 0.234375]\n",
            "38616: [discriminator loss: 0.609655, acc: 0.632812] [adversarial loss: 0.931664, acc: 0.390625]\n",
            "38617: [discriminator loss: 0.605234, acc: 0.640625] [adversarial loss: 1.057364, acc: 0.375000]\n",
            "38618: [discriminator loss: 0.608400, acc: 0.632812] [adversarial loss: 1.109530, acc: 0.281250]\n",
            "38619: [discriminator loss: 0.618508, acc: 0.671875] [adversarial loss: 1.657658, acc: 0.109375]\n",
            "38620: [discriminator loss: 0.660919, acc: 0.585938] [adversarial loss: 0.802778, acc: 0.453125]\n",
            "38621: [discriminator loss: 0.572746, acc: 0.718750] [adversarial loss: 1.087897, acc: 0.250000]\n",
            "38622: [discriminator loss: 0.534671, acc: 0.757812] [adversarial loss: 0.986641, acc: 0.453125]\n",
            "38623: [discriminator loss: 0.535514, acc: 0.765625] [adversarial loss: 1.014601, acc: 0.281250]\n",
            "38624: [discriminator loss: 0.571474, acc: 0.687500] [adversarial loss: 1.170729, acc: 0.296875]\n",
            "38625: [discriminator loss: 0.574284, acc: 0.664062] [adversarial loss: 1.175702, acc: 0.187500]\n",
            "38626: [discriminator loss: 0.608720, acc: 0.687500] [adversarial loss: 1.021192, acc: 0.328125]\n",
            "38627: [discriminator loss: 0.604847, acc: 0.671875] [adversarial loss: 1.231751, acc: 0.218750]\n",
            "38628: [discriminator loss: 0.577605, acc: 0.656250] [adversarial loss: 0.980805, acc: 0.281250]\n",
            "38629: [discriminator loss: 0.576564, acc: 0.695312] [adversarial loss: 0.970175, acc: 0.406250]\n",
            "38630: [discriminator loss: 0.554089, acc: 0.718750] [adversarial loss: 1.035197, acc: 0.375000]\n",
            "38631: [discriminator loss: 0.597262, acc: 0.648438] [adversarial loss: 0.790266, acc: 0.625000]\n",
            "38632: [discriminator loss: 0.599922, acc: 0.656250] [adversarial loss: 1.329381, acc: 0.062500]\n",
            "38633: [discriminator loss: 0.609508, acc: 0.695312] [adversarial loss: 0.940336, acc: 0.453125]\n",
            "38634: [discriminator loss: 0.547188, acc: 0.718750] [adversarial loss: 1.234779, acc: 0.093750]\n",
            "38635: [discriminator loss: 0.585429, acc: 0.695312] [adversarial loss: 0.908514, acc: 0.390625]\n",
            "38636: [discriminator loss: 0.515083, acc: 0.757812] [adversarial loss: 1.137280, acc: 0.218750]\n",
            "38637: [discriminator loss: 0.645740, acc: 0.570312] [adversarial loss: 0.982586, acc: 0.375000]\n",
            "38638: [discriminator loss: 0.596838, acc: 0.671875] [adversarial loss: 1.252079, acc: 0.171875]\n",
            "38639: [discriminator loss: 0.584902, acc: 0.664062] [adversarial loss: 0.728772, acc: 0.609375]\n",
            "38640: [discriminator loss: 0.596986, acc: 0.687500] [adversarial loss: 1.367876, acc: 0.156250]\n",
            "38641: [discriminator loss: 0.592388, acc: 0.640625] [adversarial loss: 1.010994, acc: 0.359375]\n",
            "38642: [discriminator loss: 0.564016, acc: 0.726562] [adversarial loss: 0.962148, acc: 0.328125]\n",
            "38643: [discriminator loss: 0.587717, acc: 0.703125] [adversarial loss: 1.074114, acc: 0.265625]\n",
            "38644: [discriminator loss: 0.558976, acc: 0.710938] [adversarial loss: 0.934174, acc: 0.421875]\n",
            "38645: [discriminator loss: 0.502263, acc: 0.734375] [adversarial loss: 1.272627, acc: 0.171875]\n",
            "38646: [discriminator loss: 0.599242, acc: 0.648438] [adversarial loss: 0.908390, acc: 0.390625]\n",
            "38647: [discriminator loss: 0.598951, acc: 0.687500] [adversarial loss: 1.207773, acc: 0.156250]\n",
            "38648: [discriminator loss: 0.551871, acc: 0.703125] [adversarial loss: 1.036408, acc: 0.390625]\n",
            "38649: [discriminator loss: 0.603096, acc: 0.664062] [adversarial loss: 1.095992, acc: 0.328125]\n",
            "38650: [discriminator loss: 0.525583, acc: 0.726562] [adversarial loss: 1.143449, acc: 0.281250]\n",
            "38651: [discriminator loss: 0.638085, acc: 0.656250] [adversarial loss: 0.953970, acc: 0.296875]\n",
            "38652: [discriminator loss: 0.546320, acc: 0.789062] [adversarial loss: 1.404899, acc: 0.093750]\n",
            "38653: [discriminator loss: 0.564878, acc: 0.679688] [adversarial loss: 1.085503, acc: 0.343750]\n",
            "38654: [discriminator loss: 0.556251, acc: 0.656250] [adversarial loss: 1.051069, acc: 0.390625]\n",
            "38655: [discriminator loss: 0.570274, acc: 0.687500] [adversarial loss: 1.057507, acc: 0.312500]\n",
            "38656: [discriminator loss: 0.535897, acc: 0.742188] [adversarial loss: 0.988440, acc: 0.421875]\n",
            "38657: [discriminator loss: 0.569831, acc: 0.695312] [adversarial loss: 1.081799, acc: 0.281250]\n",
            "38658: [discriminator loss: 0.570797, acc: 0.726562] [adversarial loss: 1.298680, acc: 0.218750]\n",
            "38659: [discriminator loss: 0.533807, acc: 0.710938] [adversarial loss: 1.021912, acc: 0.265625]\n",
            "38660: [discriminator loss: 0.626792, acc: 0.679688] [adversarial loss: 1.317066, acc: 0.171875]\n",
            "38661: [discriminator loss: 0.626486, acc: 0.687500] [adversarial loss: 1.030643, acc: 0.343750]\n",
            "38662: [discriminator loss: 0.597923, acc: 0.664062] [adversarial loss: 0.978428, acc: 0.375000]\n",
            "38663: [discriminator loss: 0.580135, acc: 0.679688] [adversarial loss: 1.036922, acc: 0.312500]\n",
            "38664: [discriminator loss: 0.573928, acc: 0.671875] [adversarial loss: 1.089384, acc: 0.187500]\n",
            "38665: [discriminator loss: 0.573165, acc: 0.671875] [adversarial loss: 1.493659, acc: 0.109375]\n",
            "38666: [discriminator loss: 0.534451, acc: 0.703125] [adversarial loss: 1.034808, acc: 0.421875]\n",
            "38667: [discriminator loss: 0.522216, acc: 0.742188] [adversarial loss: 1.238420, acc: 0.281250]\n",
            "38668: [discriminator loss: 0.623489, acc: 0.640625] [adversarial loss: 0.978531, acc: 0.437500]\n",
            "38669: [discriminator loss: 0.593837, acc: 0.679688] [adversarial loss: 1.326336, acc: 0.218750]\n",
            "38670: [discriminator loss: 0.582451, acc: 0.671875] [adversarial loss: 0.982394, acc: 0.312500]\n",
            "38671: [discriminator loss: 0.636415, acc: 0.601562] [adversarial loss: 1.265895, acc: 0.218750]\n",
            "38672: [discriminator loss: 0.560569, acc: 0.718750] [adversarial loss: 0.854386, acc: 0.484375]\n",
            "38673: [discriminator loss: 0.625753, acc: 0.664062] [adversarial loss: 1.343854, acc: 0.218750]\n",
            "38674: [discriminator loss: 0.576949, acc: 0.718750] [adversarial loss: 0.797888, acc: 0.484375]\n",
            "38675: [discriminator loss: 0.486201, acc: 0.742188] [adversarial loss: 1.263192, acc: 0.234375]\n",
            "38676: [discriminator loss: 0.550684, acc: 0.742188] [adversarial loss: 1.022123, acc: 0.281250]\n",
            "38677: [discriminator loss: 0.585209, acc: 0.718750] [adversarial loss: 1.064531, acc: 0.187500]\n",
            "38678: [discriminator loss: 0.592521, acc: 0.671875] [adversarial loss: 1.183039, acc: 0.250000]\n",
            "38679: [discriminator loss: 0.596399, acc: 0.695312] [adversarial loss: 1.231641, acc: 0.234375]\n",
            "38680: [discriminator loss: 0.631220, acc: 0.640625] [adversarial loss: 1.264022, acc: 0.156250]\n",
            "38681: [discriminator loss: 0.527124, acc: 0.710938] [adversarial loss: 0.830785, acc: 0.484375]\n",
            "38682: [discriminator loss: 0.564669, acc: 0.710938] [adversarial loss: 1.317160, acc: 0.109375]\n",
            "38683: [discriminator loss: 0.606831, acc: 0.632812] [adversarial loss: 0.932642, acc: 0.453125]\n",
            "38684: [discriminator loss: 0.571005, acc: 0.695312] [adversarial loss: 1.416853, acc: 0.093750]\n",
            "38685: [discriminator loss: 0.649059, acc: 0.609375] [adversarial loss: 0.909696, acc: 0.484375]\n",
            "38686: [discriminator loss: 0.631063, acc: 0.617188] [adversarial loss: 1.220616, acc: 0.125000]\n",
            "38687: [discriminator loss: 0.653814, acc: 0.625000] [adversarial loss: 0.943751, acc: 0.468750]\n",
            "38688: [discriminator loss: 0.620900, acc: 0.648438] [adversarial loss: 1.201452, acc: 0.140625]\n",
            "38689: [discriminator loss: 0.566180, acc: 0.679688] [adversarial loss: 1.073040, acc: 0.343750]\n",
            "38690: [discriminator loss: 0.593649, acc: 0.687500] [adversarial loss: 1.128182, acc: 0.265625]\n",
            "38691: [discriminator loss: 0.527086, acc: 0.718750] [adversarial loss: 0.999843, acc: 0.390625]\n",
            "38692: [discriminator loss: 0.595003, acc: 0.726562] [adversarial loss: 1.237829, acc: 0.125000]\n",
            "38693: [discriminator loss: 0.583013, acc: 0.687500] [adversarial loss: 0.692189, acc: 0.562500]\n",
            "38694: [discriminator loss: 0.576408, acc: 0.726562] [adversarial loss: 1.266936, acc: 0.156250]\n",
            "38695: [discriminator loss: 0.615912, acc: 0.609375] [adversarial loss: 0.951709, acc: 0.328125]\n",
            "38696: [discriminator loss: 0.644234, acc: 0.640625] [adversarial loss: 1.174961, acc: 0.218750]\n",
            "38697: [discriminator loss: 0.650294, acc: 0.632812] [adversarial loss: 0.857649, acc: 0.421875]\n",
            "38698: [discriminator loss: 0.543622, acc: 0.710938] [adversarial loss: 1.195048, acc: 0.281250]\n",
            "38699: [discriminator loss: 0.620161, acc: 0.632812] [adversarial loss: 1.021233, acc: 0.312500]\n",
            "38700: [discriminator loss: 0.574602, acc: 0.710938] [adversarial loss: 1.041109, acc: 0.296875]\n",
            "38701: [discriminator loss: 0.522478, acc: 0.742188] [adversarial loss: 1.133486, acc: 0.218750]\n",
            "38702: [discriminator loss: 0.597436, acc: 0.687500] [adversarial loss: 0.850147, acc: 0.375000]\n",
            "38703: [discriminator loss: 0.588686, acc: 0.695312] [adversarial loss: 1.265527, acc: 0.203125]\n",
            "38704: [discriminator loss: 0.575598, acc: 0.695312] [adversarial loss: 1.075247, acc: 0.234375]\n",
            "38705: [discriminator loss: 0.619794, acc: 0.625000] [adversarial loss: 0.948819, acc: 0.484375]\n",
            "38706: [discriminator loss: 0.539675, acc: 0.750000] [adversarial loss: 1.281821, acc: 0.203125]\n",
            "38707: [discriminator loss: 0.590283, acc: 0.664062] [adversarial loss: 0.994358, acc: 0.250000]\n",
            "38708: [discriminator loss: 0.562080, acc: 0.687500] [adversarial loss: 1.296662, acc: 0.171875]\n",
            "38709: [discriminator loss: 0.568167, acc: 0.664062] [adversarial loss: 0.898752, acc: 0.375000]\n",
            "38710: [discriminator loss: 0.616392, acc: 0.648438] [adversarial loss: 1.331653, acc: 0.140625]\n",
            "38711: [discriminator loss: 0.598202, acc: 0.687500] [adversarial loss: 1.048152, acc: 0.250000]\n",
            "38712: [discriminator loss: 0.603021, acc: 0.671875] [adversarial loss: 0.998679, acc: 0.359375]\n",
            "38713: [discriminator loss: 0.594414, acc: 0.671875] [adversarial loss: 1.088934, acc: 0.234375]\n",
            "38714: [discriminator loss: 0.589610, acc: 0.703125] [adversarial loss: 0.995056, acc: 0.390625]\n",
            "38715: [discriminator loss: 0.579453, acc: 0.703125] [adversarial loss: 1.372134, acc: 0.109375]\n",
            "38716: [discriminator loss: 0.532527, acc: 0.742188] [adversarial loss: 1.068415, acc: 0.296875]\n",
            "38717: [discriminator loss: 0.564130, acc: 0.687500] [adversarial loss: 1.181811, acc: 0.234375]\n",
            "38718: [discriminator loss: 0.640069, acc: 0.656250] [adversarial loss: 1.193065, acc: 0.281250]\n",
            "38719: [discriminator loss: 0.552840, acc: 0.726562] [adversarial loss: 0.816473, acc: 0.468750]\n",
            "38720: [discriminator loss: 0.597109, acc: 0.687500] [adversarial loss: 1.281137, acc: 0.187500]\n",
            "38721: [discriminator loss: 0.653846, acc: 0.617188] [adversarial loss: 0.846078, acc: 0.546875]\n",
            "38722: [discriminator loss: 0.579444, acc: 0.710938] [adversarial loss: 1.235243, acc: 0.265625]\n",
            "38723: [discriminator loss: 0.567479, acc: 0.710938] [adversarial loss: 0.837291, acc: 0.484375]\n",
            "38724: [discriminator loss: 0.592919, acc: 0.664062] [adversarial loss: 1.236738, acc: 0.156250]\n",
            "38725: [discriminator loss: 0.596965, acc: 0.671875] [adversarial loss: 0.984308, acc: 0.343750]\n",
            "38726: [discriminator loss: 0.597951, acc: 0.695312] [adversarial loss: 1.110851, acc: 0.187500]\n",
            "38727: [discriminator loss: 0.537720, acc: 0.750000] [adversarial loss: 1.115139, acc: 0.328125]\n",
            "38728: [discriminator loss: 0.580909, acc: 0.625000] [adversarial loss: 1.089115, acc: 0.265625]\n",
            "38729: [discriminator loss: 0.551097, acc: 0.757812] [adversarial loss: 0.904904, acc: 0.421875]\n",
            "38730: [discriminator loss: 0.559614, acc: 0.695312] [adversarial loss: 1.292488, acc: 0.171875]\n",
            "38731: [discriminator loss: 0.569022, acc: 0.695312] [adversarial loss: 0.831779, acc: 0.468750]\n",
            "38732: [discriminator loss: 0.606087, acc: 0.664062] [adversarial loss: 1.587611, acc: 0.093750]\n",
            "38733: [discriminator loss: 0.641803, acc: 0.648438] [adversarial loss: 0.947097, acc: 0.390625]\n",
            "38734: [discriminator loss: 0.560131, acc: 0.710938] [adversarial loss: 1.057438, acc: 0.343750]\n",
            "38735: [discriminator loss: 0.562263, acc: 0.687500] [adversarial loss: 1.100854, acc: 0.343750]\n",
            "38736: [discriminator loss: 0.575671, acc: 0.679688] [adversarial loss: 1.233941, acc: 0.187500]\n",
            "38737: [discriminator loss: 0.540313, acc: 0.671875] [adversarial loss: 0.993759, acc: 0.375000]\n",
            "38738: [discriminator loss: 0.578873, acc: 0.687500] [adversarial loss: 1.134059, acc: 0.281250]\n",
            "38739: [discriminator loss: 0.551200, acc: 0.734375] [adversarial loss: 0.962177, acc: 0.359375]\n",
            "38740: [discriminator loss: 0.582981, acc: 0.656250] [adversarial loss: 1.143641, acc: 0.265625]\n",
            "38741: [discriminator loss: 0.534953, acc: 0.742188] [adversarial loss: 1.050967, acc: 0.296875]\n",
            "38742: [discriminator loss: 0.620467, acc: 0.625000] [adversarial loss: 0.967626, acc: 0.359375]\n",
            "38743: [discriminator loss: 0.547743, acc: 0.742188] [adversarial loss: 0.983180, acc: 0.406250]\n",
            "38744: [discriminator loss: 0.565564, acc: 0.640625] [adversarial loss: 1.378244, acc: 0.203125]\n",
            "38745: [discriminator loss: 0.681288, acc: 0.554688] [adversarial loss: 0.917763, acc: 0.375000]\n",
            "38746: [discriminator loss: 0.529968, acc: 0.710938] [adversarial loss: 1.160279, acc: 0.218750]\n",
            "38747: [discriminator loss: 0.666464, acc: 0.656250] [adversarial loss: 0.790270, acc: 0.484375]\n",
            "38748: [discriminator loss: 0.625373, acc: 0.609375] [adversarial loss: 1.210094, acc: 0.171875]\n",
            "38749: [discriminator loss: 0.670577, acc: 0.593750] [adversarial loss: 0.784344, acc: 0.500000]\n",
            "38750: [discriminator loss: 0.650209, acc: 0.656250] [adversarial loss: 1.112863, acc: 0.328125]\n",
            "38751: [discriminator loss: 0.568676, acc: 0.703125] [adversarial loss: 1.178663, acc: 0.156250]\n",
            "38752: [discriminator loss: 0.578513, acc: 0.703125] [adversarial loss: 1.240808, acc: 0.156250]\n",
            "38753: [discriminator loss: 0.548942, acc: 0.718750] [adversarial loss: 1.091983, acc: 0.312500]\n",
            "38754: [discriminator loss: 0.512835, acc: 0.781250] [adversarial loss: 1.237138, acc: 0.265625]\n",
            "38755: [discriminator loss: 0.594606, acc: 0.617188] [adversarial loss: 1.031576, acc: 0.281250]\n",
            "38756: [discriminator loss: 0.546950, acc: 0.734375] [adversarial loss: 0.977593, acc: 0.312500]\n",
            "38757: [discriminator loss: 0.647656, acc: 0.648438] [adversarial loss: 0.942302, acc: 0.406250]\n",
            "38758: [discriminator loss: 0.587459, acc: 0.679688] [adversarial loss: 1.221035, acc: 0.218750]\n",
            "38759: [discriminator loss: 0.578459, acc: 0.656250] [adversarial loss: 0.944328, acc: 0.359375]\n",
            "38760: [discriminator loss: 0.612372, acc: 0.617188] [adversarial loss: 1.135658, acc: 0.234375]\n",
            "38761: [discriminator loss: 0.545672, acc: 0.726562] [adversarial loss: 0.825532, acc: 0.453125]\n",
            "38762: [discriminator loss: 0.612689, acc: 0.664062] [adversarial loss: 1.441060, acc: 0.187500]\n",
            "38763: [discriminator loss: 0.551689, acc: 0.703125] [adversarial loss: 0.956301, acc: 0.406250]\n",
            "38764: [discriminator loss: 0.635277, acc: 0.609375] [adversarial loss: 1.274253, acc: 0.140625]\n",
            "38765: [discriminator loss: 0.598714, acc: 0.664062] [adversarial loss: 0.820799, acc: 0.406250]\n",
            "38766: [discriminator loss: 0.636161, acc: 0.640625] [adversarial loss: 1.393826, acc: 0.156250]\n",
            "38767: [discriminator loss: 0.599333, acc: 0.687500] [adversarial loss: 0.904782, acc: 0.421875]\n",
            "38768: [discriminator loss: 0.610443, acc: 0.703125] [adversarial loss: 1.217580, acc: 0.140625]\n",
            "38769: [discriminator loss: 0.604082, acc: 0.648438] [adversarial loss: 0.885598, acc: 0.406250]\n",
            "38770: [discriminator loss: 0.606906, acc: 0.640625] [adversarial loss: 1.039100, acc: 0.343750]\n",
            "38771: [discriminator loss: 0.584219, acc: 0.687500] [adversarial loss: 1.026312, acc: 0.343750]\n",
            "38772: [discriminator loss: 0.499515, acc: 0.750000] [adversarial loss: 0.960672, acc: 0.296875]\n",
            "38773: [discriminator loss: 0.568657, acc: 0.695312] [adversarial loss: 0.887061, acc: 0.515625]\n",
            "38774: [discriminator loss: 0.597573, acc: 0.648438] [adversarial loss: 0.718600, acc: 0.593750]\n",
            "38775: [discriminator loss: 0.623404, acc: 0.609375] [adversarial loss: 1.092454, acc: 0.312500]\n",
            "38776: [discriminator loss: 0.553987, acc: 0.734375] [adversarial loss: 1.064828, acc: 0.250000]\n",
            "38777: [discriminator loss: 0.696113, acc: 0.585938] [adversarial loss: 1.175054, acc: 0.343750]\n",
            "38778: [discriminator loss: 0.594865, acc: 0.671875] [adversarial loss: 1.252503, acc: 0.187500]\n",
            "38779: [discriminator loss: 0.543210, acc: 0.695312] [adversarial loss: 1.035218, acc: 0.281250]\n",
            "38780: [discriminator loss: 0.609272, acc: 0.648438] [adversarial loss: 1.139555, acc: 0.296875]\n",
            "38781: [discriminator loss: 0.579386, acc: 0.710938] [adversarial loss: 1.161187, acc: 0.234375]\n",
            "38782: [discriminator loss: 0.538437, acc: 0.703125] [adversarial loss: 1.053238, acc: 0.390625]\n",
            "38783: [discriminator loss: 0.627060, acc: 0.625000] [adversarial loss: 1.160891, acc: 0.203125]\n",
            "38784: [discriminator loss: 0.581081, acc: 0.679688] [adversarial loss: 1.095605, acc: 0.343750]\n",
            "38785: [discriminator loss: 0.558928, acc: 0.726562] [adversarial loss: 0.846216, acc: 0.375000]\n",
            "38786: [discriminator loss: 0.575140, acc: 0.664062] [adversarial loss: 1.358638, acc: 0.187500]\n",
            "38787: [discriminator loss: 0.607085, acc: 0.671875] [adversarial loss: 0.787097, acc: 0.468750]\n",
            "38788: [discriminator loss: 0.612857, acc: 0.625000] [adversarial loss: 1.201144, acc: 0.265625]\n",
            "38789: [discriminator loss: 0.660967, acc: 0.617188] [adversarial loss: 0.969549, acc: 0.390625]\n",
            "38790: [discriminator loss: 0.601598, acc: 0.679688] [adversarial loss: 1.138452, acc: 0.234375]\n",
            "38791: [discriminator loss: 0.585790, acc: 0.726562] [adversarial loss: 0.951136, acc: 0.343750]\n",
            "38792: [discriminator loss: 0.588715, acc: 0.671875] [adversarial loss: 1.129016, acc: 0.187500]\n",
            "38793: [discriminator loss: 0.571781, acc: 0.718750] [adversarial loss: 1.003005, acc: 0.234375]\n",
            "38794: [discriminator loss: 0.574926, acc: 0.695312] [adversarial loss: 1.102494, acc: 0.281250]\n",
            "38795: [discriminator loss: 0.631039, acc: 0.648438] [adversarial loss: 1.035796, acc: 0.234375]\n",
            "38796: [discriminator loss: 0.554376, acc: 0.710938] [adversarial loss: 0.903030, acc: 0.375000]\n",
            "38797: [discriminator loss: 0.610360, acc: 0.679688] [adversarial loss: 1.102787, acc: 0.296875]\n",
            "38798: [discriminator loss: 0.540811, acc: 0.734375] [adversarial loss: 0.958505, acc: 0.359375]\n",
            "38799: [discriminator loss: 0.583652, acc: 0.664062] [adversarial loss: 1.010088, acc: 0.375000]\n",
            "38800: [discriminator loss: 0.541524, acc: 0.734375] [adversarial loss: 0.947622, acc: 0.390625]\n",
            "38801: [discriminator loss: 0.655488, acc: 0.648438] [adversarial loss: 1.181530, acc: 0.250000]\n",
            "38802: [discriminator loss: 0.585025, acc: 0.664062] [adversarial loss: 0.778720, acc: 0.531250]\n",
            "38803: [discriminator loss: 0.587431, acc: 0.648438] [adversarial loss: 0.976691, acc: 0.312500]\n",
            "38804: [discriminator loss: 0.581852, acc: 0.679688] [adversarial loss: 0.985693, acc: 0.328125]\n",
            "38805: [discriminator loss: 0.660569, acc: 0.679688] [adversarial loss: 1.252057, acc: 0.250000]\n",
            "38806: [discriminator loss: 0.566022, acc: 0.671875] [adversarial loss: 1.137101, acc: 0.328125]\n",
            "38807: [discriminator loss: 0.609343, acc: 0.632812] [adversarial loss: 1.274081, acc: 0.125000]\n",
            "38808: [discriminator loss: 0.546723, acc: 0.695312] [adversarial loss: 0.867871, acc: 0.500000]\n",
            "38809: [discriminator loss: 0.581515, acc: 0.695312] [adversarial loss: 1.356215, acc: 0.156250]\n",
            "38810: [discriminator loss: 0.599789, acc: 0.648438] [adversarial loss: 0.973295, acc: 0.390625]\n",
            "38811: [discriminator loss: 0.575300, acc: 0.695312] [adversarial loss: 1.027608, acc: 0.375000]\n",
            "38812: [discriminator loss: 0.583291, acc: 0.687500] [adversarial loss: 1.104254, acc: 0.250000]\n",
            "38813: [discriminator loss: 0.571813, acc: 0.687500] [adversarial loss: 1.002335, acc: 0.421875]\n",
            "38814: [discriminator loss: 0.641402, acc: 0.593750] [adversarial loss: 1.042218, acc: 0.390625]\n",
            "38815: [discriminator loss: 0.592958, acc: 0.687500] [adversarial loss: 0.956309, acc: 0.406250]\n",
            "38816: [discriminator loss: 0.610007, acc: 0.718750] [adversarial loss: 0.953207, acc: 0.390625]\n",
            "38817: [discriminator loss: 0.611482, acc: 0.703125] [adversarial loss: 1.368831, acc: 0.140625]\n",
            "38818: [discriminator loss: 0.575983, acc: 0.703125] [adversarial loss: 0.988789, acc: 0.359375]\n",
            "38819: [discriminator loss: 0.574564, acc: 0.664062] [adversarial loss: 1.043512, acc: 0.312500]\n",
            "38820: [discriminator loss: 0.600061, acc: 0.664062] [adversarial loss: 0.961415, acc: 0.328125]\n",
            "38821: [discriminator loss: 0.547486, acc: 0.710938] [adversarial loss: 1.119510, acc: 0.140625]\n",
            "38822: [discriminator loss: 0.615815, acc: 0.648438] [adversarial loss: 0.906473, acc: 0.437500]\n",
            "38823: [discriminator loss: 0.575928, acc: 0.710938] [adversarial loss: 1.409964, acc: 0.187500]\n",
            "38824: [discriminator loss: 0.606237, acc: 0.640625] [adversarial loss: 1.284092, acc: 0.281250]\n",
            "38825: [discriminator loss: 0.524963, acc: 0.750000] [adversarial loss: 1.215515, acc: 0.343750]\n",
            "38826: [discriminator loss: 0.586710, acc: 0.687500] [adversarial loss: 0.889643, acc: 0.328125]\n",
            "38827: [discriminator loss: 0.582587, acc: 0.671875] [adversarial loss: 1.115727, acc: 0.281250]\n",
            "38828: [discriminator loss: 0.586354, acc: 0.671875] [adversarial loss: 0.936771, acc: 0.421875]\n",
            "38829: [discriminator loss: 0.535393, acc: 0.703125] [adversarial loss: 1.042510, acc: 0.312500]\n",
            "38830: [discriminator loss: 0.599420, acc: 0.640625] [adversarial loss: 1.189390, acc: 0.218750]\n",
            "38831: [discriminator loss: 0.508573, acc: 0.765625] [adversarial loss: 0.883038, acc: 0.421875]\n",
            "38832: [discriminator loss: 0.554311, acc: 0.710938] [adversarial loss: 1.420541, acc: 0.140625]\n",
            "38833: [discriminator loss: 0.577258, acc: 0.726562] [adversarial loss: 1.004382, acc: 0.328125]\n",
            "38834: [discriminator loss: 0.631587, acc: 0.609375] [adversarial loss: 1.341629, acc: 0.234375]\n",
            "38835: [discriminator loss: 0.623868, acc: 0.632812] [adversarial loss: 0.912641, acc: 0.343750]\n",
            "38836: [discriminator loss: 0.528336, acc: 0.734375] [adversarial loss: 1.091976, acc: 0.328125]\n",
            "38837: [discriminator loss: 0.603010, acc: 0.710938] [adversarial loss: 1.004883, acc: 0.343750]\n",
            "38838: [discriminator loss: 0.663617, acc: 0.578125] [adversarial loss: 1.131354, acc: 0.250000]\n",
            "38839: [discriminator loss: 0.592595, acc: 0.679688] [adversarial loss: 1.074993, acc: 0.312500]\n",
            "38840: [discriminator loss: 0.600459, acc: 0.687500] [adversarial loss: 1.031489, acc: 0.328125]\n",
            "38841: [discriminator loss: 0.571446, acc: 0.750000] [adversarial loss: 1.015301, acc: 0.328125]\n",
            "38842: [discriminator loss: 0.615349, acc: 0.656250] [adversarial loss: 0.886802, acc: 0.296875]\n",
            "38843: [discriminator loss: 0.532142, acc: 0.710938] [adversarial loss: 1.297199, acc: 0.109375]\n",
            "38844: [discriminator loss: 0.609376, acc: 0.640625] [adversarial loss: 0.821295, acc: 0.437500]\n",
            "38845: [discriminator loss: 0.675341, acc: 0.632812] [adversarial loss: 1.306024, acc: 0.125000]\n",
            "38846: [discriminator loss: 0.592517, acc: 0.671875] [adversarial loss: 0.835679, acc: 0.453125]\n",
            "38847: [discriminator loss: 0.553798, acc: 0.664062] [adversarial loss: 1.305815, acc: 0.156250]\n",
            "38848: [discriminator loss: 0.614166, acc: 0.632812] [adversarial loss: 0.784297, acc: 0.515625]\n",
            "38849: [discriminator loss: 0.561983, acc: 0.695312] [adversarial loss: 1.203171, acc: 0.234375]\n",
            "38850: [discriminator loss: 0.579781, acc: 0.664062] [adversarial loss: 0.915128, acc: 0.343750]\n",
            "38851: [discriminator loss: 0.675367, acc: 0.593750] [adversarial loss: 1.285598, acc: 0.140625]\n",
            "38852: [discriminator loss: 0.572547, acc: 0.656250] [adversarial loss: 0.847696, acc: 0.500000]\n",
            "38853: [discriminator loss: 0.603100, acc: 0.632812] [adversarial loss: 1.145689, acc: 0.296875]\n",
            "38854: [discriminator loss: 0.571101, acc: 0.648438] [adversarial loss: 0.912239, acc: 0.359375]\n",
            "38855: [discriminator loss: 0.552006, acc: 0.710938] [adversarial loss: 0.829332, acc: 0.468750]\n",
            "38856: [discriminator loss: 0.596373, acc: 0.734375] [adversarial loss: 0.836748, acc: 0.359375]\n",
            "38857: [discriminator loss: 0.544623, acc: 0.750000] [adversarial loss: 1.198080, acc: 0.281250]\n",
            "38858: [discriminator loss: 0.584489, acc: 0.687500] [adversarial loss: 1.282070, acc: 0.265625]\n",
            "38859: [discriminator loss: 0.582916, acc: 0.664062] [adversarial loss: 0.984579, acc: 0.359375]\n",
            "38860: [discriminator loss: 0.611634, acc: 0.687500] [adversarial loss: 1.504188, acc: 0.109375]\n",
            "38861: [discriminator loss: 0.590092, acc: 0.656250] [adversarial loss: 0.747209, acc: 0.531250]\n",
            "38862: [discriminator loss: 0.694870, acc: 0.593750] [adversarial loss: 1.478560, acc: 0.125000]\n",
            "38863: [discriminator loss: 0.675767, acc: 0.554688] [adversarial loss: 0.994191, acc: 0.359375]\n",
            "38864: [discriminator loss: 0.567819, acc: 0.703125] [adversarial loss: 1.209807, acc: 0.250000]\n",
            "38865: [discriminator loss: 0.556236, acc: 0.750000] [adversarial loss: 1.160493, acc: 0.234375]\n",
            "38866: [discriminator loss: 0.632508, acc: 0.664062] [adversarial loss: 0.892166, acc: 0.406250]\n",
            "38867: [discriminator loss: 0.526797, acc: 0.726562] [adversarial loss: 1.118880, acc: 0.296875]\n",
            "38868: [discriminator loss: 0.561773, acc: 0.687500] [adversarial loss: 0.729683, acc: 0.562500]\n",
            "38869: [discriminator loss: 0.642233, acc: 0.640625] [adversarial loss: 1.235146, acc: 0.187500]\n",
            "38870: [discriminator loss: 0.600396, acc: 0.664062] [adversarial loss: 0.919099, acc: 0.343750]\n",
            "38871: [discriminator loss: 0.564873, acc: 0.671875] [adversarial loss: 1.116770, acc: 0.281250]\n",
            "38872: [discriminator loss: 0.557185, acc: 0.679688] [adversarial loss: 0.953007, acc: 0.390625]\n",
            "38873: [discriminator loss: 0.543304, acc: 0.718750] [adversarial loss: 1.211196, acc: 0.250000]\n",
            "38874: [discriminator loss: 0.618833, acc: 0.687500] [adversarial loss: 1.131204, acc: 0.328125]\n",
            "38875: [discriminator loss: 0.606384, acc: 0.671875] [adversarial loss: 1.099388, acc: 0.218750]\n",
            "38876: [discriminator loss: 0.605367, acc: 0.656250] [adversarial loss: 1.322726, acc: 0.140625]\n",
            "38877: [discriminator loss: 0.610003, acc: 0.671875] [adversarial loss: 0.926220, acc: 0.531250]\n",
            "38878: [discriminator loss: 0.624444, acc: 0.695312] [adversarial loss: 1.103815, acc: 0.312500]\n",
            "38879: [discriminator loss: 0.560128, acc: 0.687500] [adversarial loss: 0.843505, acc: 0.453125]\n",
            "38880: [discriminator loss: 0.647417, acc: 0.632812] [adversarial loss: 0.974198, acc: 0.359375]\n",
            "38881: [discriminator loss: 0.622256, acc: 0.656250] [adversarial loss: 1.245914, acc: 0.156250]\n",
            "38882: [discriminator loss: 0.596004, acc: 0.640625] [adversarial loss: 0.990915, acc: 0.265625]\n",
            "38883: [discriminator loss: 0.570142, acc: 0.664062] [adversarial loss: 1.106580, acc: 0.234375]\n",
            "38884: [discriminator loss: 0.630515, acc: 0.656250] [adversarial loss: 1.000265, acc: 0.328125]\n",
            "38885: [discriminator loss: 0.530725, acc: 0.664062] [adversarial loss: 0.917318, acc: 0.390625]\n",
            "38886: [discriminator loss: 0.509813, acc: 0.742188] [adversarial loss: 0.990236, acc: 0.375000]\n",
            "38887: [discriminator loss: 0.605643, acc: 0.671875] [adversarial loss: 1.025012, acc: 0.312500]\n",
            "38888: [discriminator loss: 0.587352, acc: 0.726562] [adversarial loss: 0.817994, acc: 0.421875]\n",
            "38889: [discriminator loss: 0.584757, acc: 0.671875] [adversarial loss: 1.112536, acc: 0.250000]\n",
            "38890: [discriminator loss: 0.585444, acc: 0.648438] [adversarial loss: 0.933655, acc: 0.359375]\n",
            "38891: [discriminator loss: 0.614772, acc: 0.664062] [adversarial loss: 1.425970, acc: 0.093750]\n",
            "38892: [discriminator loss: 0.581427, acc: 0.726562] [adversarial loss: 0.778794, acc: 0.593750]\n",
            "38893: [discriminator loss: 0.650976, acc: 0.632812] [adversarial loss: 1.267474, acc: 0.171875]\n",
            "38894: [discriminator loss: 0.602904, acc: 0.617188] [adversarial loss: 1.061143, acc: 0.343750]\n",
            "38895: [discriminator loss: 0.587378, acc: 0.679688] [adversarial loss: 1.172505, acc: 0.250000]\n",
            "38896: [discriminator loss: 0.573893, acc: 0.679688] [adversarial loss: 0.941263, acc: 0.468750]\n",
            "38897: [discriminator loss: 0.528703, acc: 0.757812] [adversarial loss: 1.403948, acc: 0.171875]\n",
            "38898: [discriminator loss: 0.589945, acc: 0.687500] [adversarial loss: 0.981961, acc: 0.328125]\n",
            "38899: [discriminator loss: 0.585892, acc: 0.648438] [adversarial loss: 1.324349, acc: 0.203125]\n",
            "38900: [discriminator loss: 0.603548, acc: 0.656250] [adversarial loss: 1.075245, acc: 0.281250]\n",
            "38901: [discriminator loss: 0.539681, acc: 0.750000] [adversarial loss: 0.863688, acc: 0.500000]\n",
            "38902: [discriminator loss: 0.622481, acc: 0.593750] [adversarial loss: 1.463212, acc: 0.140625]\n",
            "38903: [discriminator loss: 0.557621, acc: 0.703125] [adversarial loss: 1.023659, acc: 0.406250]\n",
            "38904: [discriminator loss: 0.662815, acc: 0.601562] [adversarial loss: 1.029093, acc: 0.375000]\n",
            "38905: [discriminator loss: 0.561171, acc: 0.726562] [adversarial loss: 1.009972, acc: 0.296875]\n",
            "38906: [discriminator loss: 0.553784, acc: 0.679688] [adversarial loss: 1.004196, acc: 0.359375]\n",
            "38907: [discriminator loss: 0.536255, acc: 0.750000] [adversarial loss: 1.161796, acc: 0.312500]\n",
            "38908: [discriminator loss: 0.588111, acc: 0.632812] [adversarial loss: 1.123034, acc: 0.281250]\n",
            "38909: [discriminator loss: 0.586533, acc: 0.671875] [adversarial loss: 1.071558, acc: 0.343750]\n",
            "38910: [discriminator loss: 0.617210, acc: 0.570312] [adversarial loss: 1.215284, acc: 0.203125]\n",
            "38911: [discriminator loss: 0.670683, acc: 0.625000] [adversarial loss: 1.056104, acc: 0.250000]\n",
            "38912: [discriminator loss: 0.528758, acc: 0.742188] [adversarial loss: 1.009273, acc: 0.421875]\n",
            "38913: [discriminator loss: 0.553397, acc: 0.765625] [adversarial loss: 1.275905, acc: 0.281250]\n",
            "38914: [discriminator loss: 0.609007, acc: 0.679688] [adversarial loss: 1.054097, acc: 0.359375]\n",
            "38915: [discriminator loss: 0.527463, acc: 0.718750] [adversarial loss: 1.071347, acc: 0.312500]\n",
            "38916: [discriminator loss: 0.534353, acc: 0.757812] [adversarial loss: 0.972639, acc: 0.328125]\n",
            "38917: [discriminator loss: 0.655216, acc: 0.632812] [adversarial loss: 0.839359, acc: 0.500000]\n",
            "38918: [discriminator loss: 0.573779, acc: 0.703125] [adversarial loss: 1.329116, acc: 0.156250]\n",
            "38919: [discriminator loss: 0.614123, acc: 0.687500] [adversarial loss: 0.965429, acc: 0.328125]\n",
            "38920: [discriminator loss: 0.560641, acc: 0.726562] [adversarial loss: 1.211932, acc: 0.171875]\n",
            "38921: [discriminator loss: 0.650760, acc: 0.625000] [adversarial loss: 0.962197, acc: 0.265625]\n",
            "38922: [discriminator loss: 0.547107, acc: 0.710938] [adversarial loss: 1.206912, acc: 0.265625]\n",
            "38923: [discriminator loss: 0.568251, acc: 0.710938] [adversarial loss: 1.061997, acc: 0.218750]\n",
            "38924: [discriminator loss: 0.555920, acc: 0.703125] [adversarial loss: 1.064958, acc: 0.265625]\n",
            "38925: [discriminator loss: 0.517250, acc: 0.750000] [adversarial loss: 1.050435, acc: 0.296875]\n",
            "38926: [discriminator loss: 0.572493, acc: 0.679688] [adversarial loss: 1.075683, acc: 0.359375]\n",
            "38927: [discriminator loss: 0.581338, acc: 0.703125] [adversarial loss: 1.139927, acc: 0.187500]\n",
            "38928: [discriminator loss: 0.568110, acc: 0.742188] [adversarial loss: 1.204965, acc: 0.234375]\n",
            "38929: [discriminator loss: 0.541200, acc: 0.750000] [adversarial loss: 1.058207, acc: 0.250000]\n",
            "38930: [discriminator loss: 0.575513, acc: 0.718750] [adversarial loss: 1.089431, acc: 0.312500]\n",
            "38931: [discriminator loss: 0.580801, acc: 0.703125] [adversarial loss: 0.893922, acc: 0.421875]\n",
            "38932: [discriminator loss: 0.591556, acc: 0.648438] [adversarial loss: 1.183882, acc: 0.296875]\n",
            "38933: [discriminator loss: 0.570965, acc: 0.671875] [adversarial loss: 1.180073, acc: 0.296875]\n",
            "38934: [discriminator loss: 0.626482, acc: 0.625000] [adversarial loss: 0.888377, acc: 0.500000]\n",
            "38935: [discriminator loss: 0.642652, acc: 0.585938] [adversarial loss: 1.945359, acc: 0.062500]\n",
            "38936: [discriminator loss: 0.614442, acc: 0.671875] [adversarial loss: 0.814921, acc: 0.484375]\n",
            "38937: [discriminator loss: 0.595427, acc: 0.710938] [adversarial loss: 1.378890, acc: 0.265625]\n",
            "38938: [discriminator loss: 0.591193, acc: 0.648438] [adversarial loss: 1.010903, acc: 0.296875]\n",
            "38939: [discriminator loss: 0.564638, acc: 0.718750] [adversarial loss: 0.955786, acc: 0.390625]\n",
            "38940: [discriminator loss: 0.595413, acc: 0.687500] [adversarial loss: 1.134275, acc: 0.343750]\n",
            "38941: [discriminator loss: 0.582128, acc: 0.625000] [adversarial loss: 1.348287, acc: 0.125000]\n",
            "38942: [discriminator loss: 0.606317, acc: 0.640625] [adversarial loss: 1.010412, acc: 0.359375]\n",
            "38943: [discriminator loss: 0.495964, acc: 0.757812] [adversarial loss: 1.300142, acc: 0.156250]\n",
            "38944: [discriminator loss: 0.551543, acc: 0.695312] [adversarial loss: 1.087076, acc: 0.296875]\n",
            "38945: [discriminator loss: 0.614787, acc: 0.664062] [adversarial loss: 0.950245, acc: 0.359375]\n",
            "38946: [discriminator loss: 0.549331, acc: 0.703125] [adversarial loss: 1.081925, acc: 0.312500]\n",
            "38947: [discriminator loss: 0.612610, acc: 0.687500] [adversarial loss: 1.056545, acc: 0.250000]\n",
            "38948: [discriminator loss: 0.556191, acc: 0.703125] [adversarial loss: 1.142118, acc: 0.281250]\n",
            "38949: [discriminator loss: 0.571065, acc: 0.726562] [adversarial loss: 1.038334, acc: 0.187500]\n",
            "38950: [discriminator loss: 0.546657, acc: 0.710938] [adversarial loss: 1.212280, acc: 0.250000]\n",
            "38951: [discriminator loss: 0.569494, acc: 0.710938] [adversarial loss: 1.186940, acc: 0.218750]\n",
            "38952: [discriminator loss: 0.622234, acc: 0.648438] [adversarial loss: 1.110612, acc: 0.312500]\n",
            "38953: [discriminator loss: 0.568669, acc: 0.710938] [adversarial loss: 1.341093, acc: 0.125000]\n",
            "38954: [discriminator loss: 0.582300, acc: 0.695312] [adversarial loss: 0.989378, acc: 0.343750]\n",
            "38955: [discriminator loss: 0.614422, acc: 0.617188] [adversarial loss: 1.307222, acc: 0.156250]\n",
            "38956: [discriminator loss: 0.601463, acc: 0.648438] [adversarial loss: 1.068665, acc: 0.375000]\n",
            "38957: [discriminator loss: 0.594179, acc: 0.648438] [adversarial loss: 1.188187, acc: 0.234375]\n",
            "38958: [discriminator loss: 0.549690, acc: 0.703125] [adversarial loss: 0.854809, acc: 0.500000]\n",
            "38959: [discriminator loss: 0.574332, acc: 0.718750] [adversarial loss: 1.143587, acc: 0.250000]\n",
            "38960: [discriminator loss: 0.641298, acc: 0.609375] [adversarial loss: 1.142457, acc: 0.218750]\n",
            "38961: [discriminator loss: 0.503613, acc: 0.765625] [adversarial loss: 0.934164, acc: 0.375000]\n",
            "38962: [discriminator loss: 0.565892, acc: 0.679688] [adversarial loss: 1.191703, acc: 0.250000]\n",
            "38963: [discriminator loss: 0.557918, acc: 0.742188] [adversarial loss: 0.643474, acc: 0.640625]\n",
            "38964: [discriminator loss: 0.557272, acc: 0.718750] [adversarial loss: 1.115688, acc: 0.250000]\n",
            "38965: [discriminator loss: 0.593827, acc: 0.609375] [adversarial loss: 0.952122, acc: 0.437500]\n",
            "38966: [discriminator loss: 0.638702, acc: 0.632812] [adversarial loss: 1.253357, acc: 0.156250]\n",
            "38967: [discriminator loss: 0.534913, acc: 0.750000] [adversarial loss: 1.015863, acc: 0.359375]\n",
            "38968: [discriminator loss: 0.590282, acc: 0.687500] [adversarial loss: 1.091475, acc: 0.375000]\n",
            "38969: [discriminator loss: 0.519494, acc: 0.773438] [adversarial loss: 1.387214, acc: 0.156250]\n",
            "38970: [discriminator loss: 0.532862, acc: 0.703125] [adversarial loss: 0.874841, acc: 0.453125]\n",
            "38971: [discriminator loss: 0.567433, acc: 0.671875] [adversarial loss: 1.162433, acc: 0.250000]\n",
            "38972: [discriminator loss: 0.599676, acc: 0.695312] [adversarial loss: 1.030858, acc: 0.406250]\n",
            "38973: [discriminator loss: 0.604157, acc: 0.742188] [adversarial loss: 1.047292, acc: 0.218750]\n",
            "38974: [discriminator loss: 0.591784, acc: 0.664062] [adversarial loss: 0.898379, acc: 0.406250]\n",
            "38975: [discriminator loss: 0.644253, acc: 0.625000] [adversarial loss: 1.330926, acc: 0.156250]\n",
            "38976: [discriminator loss: 0.586646, acc: 0.679688] [adversarial loss: 0.713844, acc: 0.609375]\n",
            "38977: [discriminator loss: 0.565143, acc: 0.703125] [adversarial loss: 0.996609, acc: 0.328125]\n",
            "38978: [discriminator loss: 0.529531, acc: 0.718750] [adversarial loss: 1.306362, acc: 0.203125]\n",
            "38979: [discriminator loss: 0.594837, acc: 0.664062] [adversarial loss: 1.079326, acc: 0.343750]\n",
            "38980: [discriminator loss: 0.574988, acc: 0.671875] [adversarial loss: 0.925886, acc: 0.437500]\n",
            "38981: [discriminator loss: 0.567254, acc: 0.679688] [adversarial loss: 1.291902, acc: 0.218750]\n",
            "38982: [discriminator loss: 0.636376, acc: 0.648438] [adversarial loss: 1.081650, acc: 0.234375]\n",
            "38983: [discriminator loss: 0.632861, acc: 0.632812] [adversarial loss: 1.049539, acc: 0.265625]\n",
            "38984: [discriminator loss: 0.552476, acc: 0.703125] [adversarial loss: 1.097754, acc: 0.234375]\n",
            "38985: [discriminator loss: 0.595202, acc: 0.695312] [adversarial loss: 1.105061, acc: 0.218750]\n",
            "38986: [discriminator loss: 0.619606, acc: 0.679688] [adversarial loss: 0.871348, acc: 0.453125]\n",
            "38987: [discriminator loss: 0.513039, acc: 0.750000] [adversarial loss: 1.198678, acc: 0.140625]\n",
            "38988: [discriminator loss: 0.577991, acc: 0.703125] [adversarial loss: 0.877983, acc: 0.343750]\n",
            "38989: [discriminator loss: 0.626243, acc: 0.656250] [adversarial loss: 1.373904, acc: 0.140625]\n",
            "38990: [discriminator loss: 0.598204, acc: 0.664062] [adversarial loss: 0.761565, acc: 0.468750]\n",
            "38991: [discriminator loss: 0.611038, acc: 0.656250] [adversarial loss: 1.297810, acc: 0.171875]\n",
            "38992: [discriminator loss: 0.520649, acc: 0.726562] [adversarial loss: 0.905828, acc: 0.437500]\n",
            "38993: [discriminator loss: 0.569906, acc: 0.695312] [adversarial loss: 1.332943, acc: 0.125000]\n",
            "38994: [discriminator loss: 0.580115, acc: 0.703125] [adversarial loss: 1.046780, acc: 0.312500]\n",
            "38995: [discriminator loss: 0.574476, acc: 0.710938] [adversarial loss: 1.026750, acc: 0.250000]\n",
            "38996: [discriminator loss: 0.594757, acc: 0.656250] [adversarial loss: 0.884807, acc: 0.390625]\n",
            "38997: [discriminator loss: 0.572175, acc: 0.710938] [adversarial loss: 1.450451, acc: 0.093750]\n",
            "38998: [discriminator loss: 0.621858, acc: 0.632812] [adversarial loss: 0.908885, acc: 0.468750]\n",
            "38999: [discriminator loss: 0.632124, acc: 0.656250] [adversarial loss: 1.312352, acc: 0.203125]\n",
            "cgan_mnist  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n",
            "39000: [discriminator loss: 0.555415, acc: 0.679688] [adversarial loss: 0.781033, acc: 0.546875]\n",
            "39001: [discriminator loss: 0.634151, acc: 0.679688] [adversarial loss: 1.230313, acc: 0.187500]\n",
            "39002: [discriminator loss: 0.531524, acc: 0.718750] [adversarial loss: 0.876981, acc: 0.421875]\n",
            "39003: [discriminator loss: 0.517168, acc: 0.781250] [adversarial loss: 1.139084, acc: 0.281250]\n",
            "39004: [discriminator loss: 0.600020, acc: 0.742188] [adversarial loss: 1.112398, acc: 0.296875]\n",
            "39005: [discriminator loss: 0.548416, acc: 0.664062] [adversarial loss: 1.205363, acc: 0.312500]\n",
            "39006: [discriminator loss: 0.627726, acc: 0.648438] [adversarial loss: 1.082464, acc: 0.203125]\n",
            "39007: [discriminator loss: 0.497437, acc: 0.773438] [adversarial loss: 1.271467, acc: 0.203125]\n",
            "39008: [discriminator loss: 0.598494, acc: 0.656250] [adversarial loss: 0.798168, acc: 0.562500]\n",
            "39009: [discriminator loss: 0.576426, acc: 0.679688] [adversarial loss: 1.163656, acc: 0.171875]\n",
            "39010: [discriminator loss: 0.630715, acc: 0.656250] [adversarial loss: 0.959125, acc: 0.375000]\n",
            "39011: [discriminator loss: 0.579492, acc: 0.679688] [adversarial loss: 0.894052, acc: 0.406250]\n",
            "39012: [discriminator loss: 0.508298, acc: 0.773438] [adversarial loss: 1.071908, acc: 0.343750]\n",
            "39013: [discriminator loss: 0.583442, acc: 0.726562] [adversarial loss: 1.035634, acc: 0.312500]\n",
            "39014: [discriminator loss: 0.548176, acc: 0.687500] [adversarial loss: 1.156390, acc: 0.203125]\n",
            "39015: [discriminator loss: 0.578383, acc: 0.695312] [adversarial loss: 0.949866, acc: 0.390625]\n",
            "39016: [discriminator loss: 0.551864, acc: 0.726562] [adversarial loss: 1.175862, acc: 0.281250]\n",
            "39017: [discriminator loss: 0.639438, acc: 0.625000] [adversarial loss: 0.830211, acc: 0.468750]\n",
            "39018: [discriminator loss: 0.580050, acc: 0.687500] [adversarial loss: 1.291309, acc: 0.203125]\n",
            "39019: [discriminator loss: 0.593050, acc: 0.648438] [adversarial loss: 0.762079, acc: 0.515625]\n",
            "39020: [discriminator loss: 0.569654, acc: 0.671875] [adversarial loss: 1.103441, acc: 0.343750]\n",
            "39021: [discriminator loss: 0.549696, acc: 0.703125] [adversarial loss: 0.950275, acc: 0.437500]\n",
            "39022: [discriminator loss: 0.615947, acc: 0.656250] [adversarial loss: 1.087386, acc: 0.281250]\n",
            "39023: [discriminator loss: 0.538499, acc: 0.687500] [adversarial loss: 0.896716, acc: 0.390625]\n",
            "39024: [discriminator loss: 0.591820, acc: 0.656250] [adversarial loss: 1.177213, acc: 0.156250]\n",
            "39025: [discriminator loss: 0.546985, acc: 0.734375] [adversarial loss: 1.061124, acc: 0.250000]\n",
            "39026: [discriminator loss: 0.526457, acc: 0.718750] [adversarial loss: 1.016832, acc: 0.265625]\n",
            "39027: [discriminator loss: 0.580990, acc: 0.679688] [adversarial loss: 1.104300, acc: 0.250000]\n",
            "39028: [discriminator loss: 0.538392, acc: 0.718750] [adversarial loss: 0.909610, acc: 0.343750]\n",
            "39029: [discriminator loss: 0.578752, acc: 0.679688] [adversarial loss: 1.135973, acc: 0.296875]\n",
            "39030: [discriminator loss: 0.577485, acc: 0.671875] [adversarial loss: 1.047310, acc: 0.328125]\n",
            "39031: [discriminator loss: 0.497819, acc: 0.750000] [adversarial loss: 1.175469, acc: 0.250000]\n",
            "39032: [discriminator loss: 0.518582, acc: 0.796875] [adversarial loss: 0.961316, acc: 0.390625]\n",
            "39033: [discriminator loss: 0.641143, acc: 0.617188] [adversarial loss: 1.113799, acc: 0.328125]\n",
            "39034: [discriminator loss: 0.582845, acc: 0.718750] [adversarial loss: 1.090057, acc: 0.328125]\n",
            "39035: [discriminator loss: 0.621391, acc: 0.679688] [adversarial loss: 1.102726, acc: 0.250000]\n",
            "39036: [discriminator loss: 0.550326, acc: 0.726562] [adversarial loss: 1.111818, acc: 0.281250]\n",
            "39037: [discriminator loss: 0.626842, acc: 0.640625] [adversarial loss: 1.085656, acc: 0.281250]\n",
            "39038: [discriminator loss: 0.594026, acc: 0.687500] [adversarial loss: 1.253537, acc: 0.187500]\n",
            "39039: [discriminator loss: 0.633911, acc: 0.656250] [adversarial loss: 1.136626, acc: 0.234375]\n",
            "39040: [discriminator loss: 0.679638, acc: 0.593750] [adversarial loss: 1.010237, acc: 0.281250]\n",
            "39041: [discriminator loss: 0.565886, acc: 0.664062] [adversarial loss: 1.087211, acc: 0.281250]\n",
            "39042: [discriminator loss: 0.633178, acc: 0.632812] [adversarial loss: 1.127044, acc: 0.218750]\n",
            "39043: [discriminator loss: 0.581611, acc: 0.703125] [adversarial loss: 0.870463, acc: 0.468750]\n",
            "39044: [discriminator loss: 0.517011, acc: 0.742188] [adversarial loss: 1.239927, acc: 0.171875]\n",
            "39045: [discriminator loss: 0.555077, acc: 0.679688] [adversarial loss: 0.994470, acc: 0.359375]\n",
            "39046: [discriminator loss: 0.636299, acc: 0.593750] [adversarial loss: 1.131634, acc: 0.156250]\n",
            "39047: [discriminator loss: 0.607319, acc: 0.640625] [adversarial loss: 1.098823, acc: 0.203125]\n",
            "39048: [discriminator loss: 0.565527, acc: 0.695312] [adversarial loss: 1.184069, acc: 0.250000]\n",
            "39049: [discriminator loss: 0.573789, acc: 0.687500] [adversarial loss: 1.058471, acc: 0.250000]\n",
            "39050: [discriminator loss: 0.532937, acc: 0.703125] [adversarial loss: 1.056258, acc: 0.265625]\n",
            "39051: [discriminator loss: 0.608813, acc: 0.617188] [adversarial loss: 1.269960, acc: 0.234375]\n",
            "39052: [discriminator loss: 0.588135, acc: 0.671875] [adversarial loss: 1.041466, acc: 0.312500]\n",
            "39053: [discriminator loss: 0.522500, acc: 0.781250] [adversarial loss: 1.169716, acc: 0.265625]\n",
            "39054: [discriminator loss: 0.550818, acc: 0.726562] [adversarial loss: 0.875214, acc: 0.359375]\n",
            "39055: [discriminator loss: 0.609837, acc: 0.664062] [adversarial loss: 1.422442, acc: 0.218750]\n",
            "39056: [discriminator loss: 0.642308, acc: 0.609375] [adversarial loss: 0.918378, acc: 0.453125]\n",
            "39057: [discriminator loss: 0.579842, acc: 0.671875] [adversarial loss: 1.002699, acc: 0.312500]\n",
            "39058: [discriminator loss: 0.657887, acc: 0.640625] [adversarial loss: 0.865130, acc: 0.453125]\n",
            "39059: [discriminator loss: 0.543540, acc: 0.742188] [adversarial loss: 1.337721, acc: 0.156250]\n",
            "39060: [discriminator loss: 0.580156, acc: 0.664062] [adversarial loss: 0.954863, acc: 0.359375]\n",
            "39061: [discriminator loss: 0.643887, acc: 0.656250] [adversarial loss: 1.136499, acc: 0.281250]\n",
            "39062: [discriminator loss: 0.556940, acc: 0.656250] [adversarial loss: 1.104160, acc: 0.312500]\n",
            "39063: [discriminator loss: 0.541072, acc: 0.734375] [adversarial loss: 1.111742, acc: 0.328125]\n",
            "39064: [discriminator loss: 0.602123, acc: 0.687500] [adversarial loss: 0.862532, acc: 0.453125]\n",
            "39065: [discriminator loss: 0.543819, acc: 0.718750] [adversarial loss: 1.381360, acc: 0.156250]\n",
            "39066: [discriminator loss: 0.627303, acc: 0.671875] [adversarial loss: 0.748000, acc: 0.515625]\n",
            "39067: [discriminator loss: 0.614938, acc: 0.656250] [adversarial loss: 1.374538, acc: 0.203125]\n",
            "39068: [discriminator loss: 0.548932, acc: 0.734375] [adversarial loss: 1.105766, acc: 0.265625]\n",
            "39069: [discriminator loss: 0.636915, acc: 0.562500] [adversarial loss: 0.975470, acc: 0.296875]\n",
            "39070: [discriminator loss: 0.577764, acc: 0.687500] [adversarial loss: 1.183864, acc: 0.312500]\n",
            "39071: [discriminator loss: 0.611297, acc: 0.640625] [adversarial loss: 0.981093, acc: 0.343750]\n",
            "39072: [discriminator loss: 0.591439, acc: 0.664062] [adversarial loss: 1.078129, acc: 0.250000]\n",
            "39073: [discriminator loss: 0.523082, acc: 0.757812] [adversarial loss: 1.077147, acc: 0.328125]\n",
            "39074: [discriminator loss: 0.536671, acc: 0.718750] [adversarial loss: 1.066049, acc: 0.296875]\n",
            "39075: [discriminator loss: 0.568232, acc: 0.695312] [adversarial loss: 0.918097, acc: 0.468750]\n",
            "39076: [discriminator loss: 0.540685, acc: 0.789062] [adversarial loss: 1.202836, acc: 0.187500]\n",
            "39077: [discriminator loss: 0.537826, acc: 0.750000] [adversarial loss: 1.076579, acc: 0.234375]\n",
            "39078: [discriminator loss: 0.587294, acc: 0.687500] [adversarial loss: 1.427210, acc: 0.109375]\n",
            "39079: [discriminator loss: 0.589272, acc: 0.695312] [adversarial loss: 0.830605, acc: 0.546875]\n",
            "39080: [discriminator loss: 0.630316, acc: 0.648438] [adversarial loss: 1.462396, acc: 0.156250]\n",
            "39081: [discriminator loss: 0.626074, acc: 0.671875] [adversarial loss: 0.814110, acc: 0.500000]\n",
            "39082: [discriminator loss: 0.651536, acc: 0.648438] [adversarial loss: 1.459453, acc: 0.156250]\n",
            "39083: [discriminator loss: 0.597988, acc: 0.671875] [adversarial loss: 0.943958, acc: 0.390625]\n",
            "39084: [discriminator loss: 0.564038, acc: 0.648438] [adversarial loss: 1.037023, acc: 0.312500]\n",
            "39085: [discriminator loss: 0.612311, acc: 0.656250] [adversarial loss: 1.160231, acc: 0.171875]\n",
            "39086: [discriminator loss: 0.479876, acc: 0.789062] [adversarial loss: 1.164731, acc: 0.234375]\n",
            "39087: [discriminator loss: 0.554576, acc: 0.687500] [adversarial loss: 0.871193, acc: 0.453125]\n",
            "39088: [discriminator loss: 0.571064, acc: 0.718750] [adversarial loss: 1.263778, acc: 0.156250]\n",
            "39089: [discriminator loss: 0.588928, acc: 0.687500] [adversarial loss: 1.066958, acc: 0.296875]\n",
            "39090: [discriminator loss: 0.614485, acc: 0.585938] [adversarial loss: 0.835089, acc: 0.437500]\n",
            "39091: [discriminator loss: 0.520884, acc: 0.687500] [adversarial loss: 1.345490, acc: 0.031250]\n",
            "39092: [discriminator loss: 0.582773, acc: 0.671875] [adversarial loss: 0.915609, acc: 0.375000]\n",
            "39093: [discriminator loss: 0.568473, acc: 0.765625] [adversarial loss: 1.343752, acc: 0.171875]\n",
            "39094: [discriminator loss: 0.608139, acc: 0.625000] [adversarial loss: 0.851138, acc: 0.453125]\n",
            "39095: [discriminator loss: 0.606831, acc: 0.664062] [adversarial loss: 1.356484, acc: 0.187500]\n",
            "39096: [discriminator loss: 0.579879, acc: 0.703125] [adversarial loss: 0.782853, acc: 0.515625]\n",
            "39097: [discriminator loss: 0.626331, acc: 0.648438] [adversarial loss: 1.308863, acc: 0.250000]\n",
            "39098: [discriminator loss: 0.620545, acc: 0.648438] [adversarial loss: 0.896027, acc: 0.343750]\n",
            "39099: [discriminator loss: 0.551792, acc: 0.718750] [adversarial loss: 1.096496, acc: 0.312500]\n",
            "39100: [discriminator loss: 0.595213, acc: 0.664062] [adversarial loss: 0.837348, acc: 0.468750]\n",
            "39101: [discriminator loss: 0.628574, acc: 0.648438] [adversarial loss: 1.108580, acc: 0.296875]\n",
            "39102: [discriminator loss: 0.553786, acc: 0.757812] [adversarial loss: 1.049164, acc: 0.296875]\n",
            "39103: [discriminator loss: 0.559469, acc: 0.734375] [adversarial loss: 1.140800, acc: 0.265625]\n",
            "39104: [discriminator loss: 0.629279, acc: 0.609375] [adversarial loss: 0.933687, acc: 0.390625]\n",
            "39105: [discriminator loss: 0.503930, acc: 0.679688] [adversarial loss: 1.052850, acc: 0.296875]\n",
            "39106: [discriminator loss: 0.571140, acc: 0.656250] [adversarial loss: 1.027200, acc: 0.328125]\n",
            "39107: [discriminator loss: 0.509650, acc: 0.726562] [adversarial loss: 1.160039, acc: 0.250000]\n",
            "39108: [discriminator loss: 0.604086, acc: 0.671875] [adversarial loss: 0.989806, acc: 0.375000]\n",
            "39109: [discriminator loss: 0.624317, acc: 0.625000] [adversarial loss: 1.247212, acc: 0.218750]\n",
            "39110: [discriminator loss: 0.628879, acc: 0.664062] [adversarial loss: 1.098589, acc: 0.375000]\n",
            "39111: [discriminator loss: 0.584013, acc: 0.710938] [adversarial loss: 1.293020, acc: 0.187500]\n",
            "39112: [discriminator loss: 0.574695, acc: 0.710938] [adversarial loss: 0.927246, acc: 0.359375]\n",
            "39113: [discriminator loss: 0.582241, acc: 0.703125] [adversarial loss: 1.153855, acc: 0.328125]\n",
            "39114: [discriminator loss: 0.609266, acc: 0.648438] [adversarial loss: 1.086177, acc: 0.328125]\n",
            "39115: [discriminator loss: 0.599510, acc: 0.632812] [adversarial loss: 1.213127, acc: 0.187500]\n",
            "39116: [discriminator loss: 0.595517, acc: 0.703125] [adversarial loss: 0.823398, acc: 0.500000]\n",
            "39117: [discriminator loss: 0.540085, acc: 0.703125] [adversarial loss: 1.132426, acc: 0.265625]\n",
            "39118: [discriminator loss: 0.544798, acc: 0.718750] [adversarial loss: 0.772769, acc: 0.421875]\n",
            "39119: [discriminator loss: 0.571460, acc: 0.664062] [adversarial loss: 1.455792, acc: 0.171875]\n",
            "39120: [discriminator loss: 0.677021, acc: 0.585938] [adversarial loss: 0.939265, acc: 0.437500]\n",
            "39121: [discriminator loss: 0.576079, acc: 0.710938] [adversarial loss: 1.188919, acc: 0.281250]\n",
            "39122: [discriminator loss: 0.554778, acc: 0.664062] [adversarial loss: 0.911372, acc: 0.375000]\n",
            "39123: [discriminator loss: 0.572102, acc: 0.671875] [adversarial loss: 1.227864, acc: 0.250000]\n",
            "39124: [discriminator loss: 0.577464, acc: 0.687500] [adversarial loss: 0.949105, acc: 0.359375]\n",
            "39125: [discriminator loss: 0.591560, acc: 0.687500] [adversarial loss: 1.110343, acc: 0.296875]\n",
            "39126: [discriminator loss: 0.509309, acc: 0.710938] [adversarial loss: 0.980243, acc: 0.328125]\n",
            "39127: [discriminator loss: 0.578754, acc: 0.703125] [adversarial loss: 1.103871, acc: 0.265625]\n",
            "39128: [discriminator loss: 0.558160, acc: 0.695312] [adversarial loss: 1.086961, acc: 0.250000]\n",
            "39129: [discriminator loss: 0.534266, acc: 0.726562] [adversarial loss: 0.926497, acc: 0.343750]\n",
            "39130: [discriminator loss: 0.636126, acc: 0.648438] [adversarial loss: 1.195061, acc: 0.187500]\n",
            "39131: [discriminator loss: 0.585237, acc: 0.687500] [adversarial loss: 0.837929, acc: 0.515625]\n",
            "39132: [discriminator loss: 0.674742, acc: 0.601562] [adversarial loss: 1.442005, acc: 0.156250]\n",
            "39133: [discriminator loss: 0.572001, acc: 0.718750] [adversarial loss: 0.950581, acc: 0.328125]\n",
            "39134: [discriminator loss: 0.747661, acc: 0.546875] [adversarial loss: 1.125663, acc: 0.265625]\n",
            "39135: [discriminator loss: 0.576560, acc: 0.687500] [adversarial loss: 0.794944, acc: 0.484375]\n",
            "39136: [discriminator loss: 0.516992, acc: 0.757812] [adversarial loss: 1.193485, acc: 0.234375]\n",
            "39137: [discriminator loss: 0.579596, acc: 0.656250] [adversarial loss: 1.034391, acc: 0.281250]\n",
            "39138: [discriminator loss: 0.585145, acc: 0.710938] [adversarial loss: 0.994983, acc: 0.328125]\n",
            "39139: [discriminator loss: 0.595190, acc: 0.679688] [adversarial loss: 0.958113, acc: 0.390625]\n",
            "39140: [discriminator loss: 0.519639, acc: 0.765625] [adversarial loss: 0.810323, acc: 0.500000]\n",
            "39141: [discriminator loss: 0.575531, acc: 0.718750] [adversarial loss: 1.164804, acc: 0.218750]\n",
            "39142: [discriminator loss: 0.600357, acc: 0.695312] [adversarial loss: 0.775704, acc: 0.531250]\n",
            "39143: [discriminator loss: 0.569552, acc: 0.695312] [adversarial loss: 1.294108, acc: 0.171875]\n",
            "39144: [discriminator loss: 0.628234, acc: 0.648438] [adversarial loss: 0.915006, acc: 0.359375]\n",
            "39145: [discriminator loss: 0.563973, acc: 0.742188] [adversarial loss: 1.202024, acc: 0.218750]\n",
            "39146: [discriminator loss: 0.611028, acc: 0.632812] [adversarial loss: 0.873574, acc: 0.437500]\n",
            "39147: [discriminator loss: 0.584346, acc: 0.671875] [adversarial loss: 1.236663, acc: 0.218750]\n",
            "39148: [discriminator loss: 0.618312, acc: 0.679688] [adversarial loss: 0.779453, acc: 0.562500]\n",
            "39149: [discriminator loss: 0.627387, acc: 0.617188] [adversarial loss: 1.131897, acc: 0.234375]\n",
            "39150: [discriminator loss: 0.625108, acc: 0.632812] [adversarial loss: 1.109479, acc: 0.218750]\n",
            "39151: [discriminator loss: 0.611213, acc: 0.625000] [adversarial loss: 1.029526, acc: 0.328125]\n",
            "39152: [discriminator loss: 0.598328, acc: 0.687500] [adversarial loss: 0.975884, acc: 0.359375]\n",
            "39153: [discriminator loss: 0.645384, acc: 0.625000] [adversarial loss: 1.145455, acc: 0.218750]\n",
            "39154: [discriminator loss: 0.544140, acc: 0.742188] [adversarial loss: 1.102896, acc: 0.281250]\n",
            "39155: [discriminator loss: 0.594356, acc: 0.656250] [adversarial loss: 1.052995, acc: 0.312500]\n",
            "39156: [discriminator loss: 0.584801, acc: 0.664062] [adversarial loss: 1.041058, acc: 0.312500]\n",
            "39157: [discriminator loss: 0.576111, acc: 0.742188] [adversarial loss: 1.229321, acc: 0.203125]\n",
            "39158: [discriminator loss: 0.648844, acc: 0.609375] [adversarial loss: 0.711379, acc: 0.593750]\n",
            "39159: [discriminator loss: 0.611013, acc: 0.671875] [adversarial loss: 1.275259, acc: 0.281250]\n",
            "39160: [discriminator loss: 0.589532, acc: 0.703125] [adversarial loss: 0.923237, acc: 0.390625]\n",
            "39161: [discriminator loss: 0.605587, acc: 0.632812] [adversarial loss: 1.237643, acc: 0.203125]\n",
            "39162: [discriminator loss: 0.607966, acc: 0.679688] [adversarial loss: 0.978689, acc: 0.359375]\n",
            "39163: [discriminator loss: 0.630641, acc: 0.640625] [adversarial loss: 1.069837, acc: 0.296875]\n",
            "39164: [discriminator loss: 0.587551, acc: 0.679688] [adversarial loss: 0.974930, acc: 0.390625]\n",
            "39165: [discriminator loss: 0.587901, acc: 0.648438] [adversarial loss: 1.122645, acc: 0.281250]\n",
            "39166: [discriminator loss: 0.627660, acc: 0.656250] [adversarial loss: 1.178775, acc: 0.296875]\n",
            "39167: [discriminator loss: 0.549169, acc: 0.710938] [adversarial loss: 1.156579, acc: 0.187500]\n",
            "39168: [discriminator loss: 0.663427, acc: 0.671875] [adversarial loss: 0.949043, acc: 0.453125]\n",
            "39169: [discriminator loss: 0.532900, acc: 0.789062] [adversarial loss: 1.074266, acc: 0.296875]\n",
            "39170: [discriminator loss: 0.524760, acc: 0.765625] [adversarial loss: 1.124505, acc: 0.312500]\n",
            "39171: [discriminator loss: 0.558395, acc: 0.703125] [adversarial loss: 0.813769, acc: 0.437500]\n",
            "39172: [discriminator loss: 0.561742, acc: 0.750000] [adversarial loss: 1.207307, acc: 0.218750]\n",
            "39173: [discriminator loss: 0.644915, acc: 0.632812] [adversarial loss: 1.111446, acc: 0.281250]\n",
            "39174: [discriminator loss: 0.550912, acc: 0.710938] [adversarial loss: 1.221201, acc: 0.234375]\n",
            "39175: [discriminator loss: 0.594901, acc: 0.671875] [adversarial loss: 1.012025, acc: 0.312500]\n",
            "39176: [discriminator loss: 0.550270, acc: 0.695312] [adversarial loss: 1.267569, acc: 0.203125]\n",
            "39177: [discriminator loss: 0.586640, acc: 0.687500] [adversarial loss: 0.943936, acc: 0.343750]\n",
            "39178: [discriminator loss: 0.609712, acc: 0.656250] [adversarial loss: 1.109888, acc: 0.250000]\n",
            "39179: [discriminator loss: 0.524647, acc: 0.734375] [adversarial loss: 1.123239, acc: 0.250000]\n",
            "39180: [discriminator loss: 0.622479, acc: 0.695312] [adversarial loss: 1.236847, acc: 0.156250]\n",
            "39181: [discriminator loss: 0.560323, acc: 0.718750] [adversarial loss: 1.149004, acc: 0.250000]\n",
            "39182: [discriminator loss: 0.567233, acc: 0.664062] [adversarial loss: 0.867684, acc: 0.453125]\n",
            "39183: [discriminator loss: 0.591307, acc: 0.687500] [adversarial loss: 1.224926, acc: 0.156250]\n",
            "39184: [discriminator loss: 0.607662, acc: 0.656250] [adversarial loss: 0.911615, acc: 0.359375]\n",
            "39185: [discriminator loss: 0.628000, acc: 0.625000] [adversarial loss: 1.225570, acc: 0.156250]\n",
            "39186: [discriminator loss: 0.575842, acc: 0.671875] [adversarial loss: 0.658086, acc: 0.640625]\n",
            "39187: [discriminator loss: 0.617342, acc: 0.687500] [adversarial loss: 1.415215, acc: 0.125000]\n",
            "39188: [discriminator loss: 0.660254, acc: 0.601562] [adversarial loss: 0.881950, acc: 0.421875]\n",
            "39189: [discriminator loss: 0.658615, acc: 0.601562] [adversarial loss: 1.010657, acc: 0.296875]\n",
            "39190: [discriminator loss: 0.625602, acc: 0.648438] [adversarial loss: 0.889706, acc: 0.390625]\n",
            "39191: [discriminator loss: 0.609914, acc: 0.679688] [adversarial loss: 1.020332, acc: 0.218750]\n",
            "39192: [discriminator loss: 0.537663, acc: 0.734375] [adversarial loss: 1.151105, acc: 0.281250]\n",
            "39193: [discriminator loss: 0.615355, acc: 0.656250] [adversarial loss: 0.900999, acc: 0.390625]\n",
            "39194: [discriminator loss: 0.574698, acc: 0.679688] [adversarial loss: 1.156502, acc: 0.187500]\n",
            "39195: [discriminator loss: 0.557701, acc: 0.710938] [adversarial loss: 0.916728, acc: 0.421875]\n",
            "39196: [discriminator loss: 0.576401, acc: 0.687500] [adversarial loss: 0.978842, acc: 0.343750]\n",
            "39197: [discriminator loss: 0.554536, acc: 0.742188] [adversarial loss: 1.113225, acc: 0.265625]\n",
            "39198: [discriminator loss: 0.602795, acc: 0.695312] [adversarial loss: 1.071901, acc: 0.234375]\n",
            "39199: [discriminator loss: 0.535792, acc: 0.742188] [adversarial loss: 0.995933, acc: 0.390625]\n",
            "39200: [discriminator loss: 0.579174, acc: 0.671875] [adversarial loss: 1.173645, acc: 0.281250]\n",
            "39201: [discriminator loss: 0.557450, acc: 0.656250] [adversarial loss: 1.063369, acc: 0.359375]\n",
            "39202: [discriminator loss: 0.599926, acc: 0.648438] [adversarial loss: 0.986372, acc: 0.296875]\n",
            "39203: [discriminator loss: 0.637606, acc: 0.632812] [adversarial loss: 1.215182, acc: 0.281250]\n",
            "39204: [discriminator loss: 0.587034, acc: 0.671875] [adversarial loss: 1.058238, acc: 0.312500]\n",
            "39205: [discriminator loss: 0.571802, acc: 0.671875] [adversarial loss: 1.237918, acc: 0.218750]\n",
            "39206: [discriminator loss: 0.596660, acc: 0.687500] [adversarial loss: 0.932165, acc: 0.328125]\n",
            "39207: [discriminator loss: 0.527908, acc: 0.765625] [adversarial loss: 1.074205, acc: 0.281250]\n",
            "39208: [discriminator loss: 0.592664, acc: 0.671875] [adversarial loss: 0.874246, acc: 0.468750]\n",
            "39209: [discriminator loss: 0.593955, acc: 0.687500] [adversarial loss: 1.227062, acc: 0.218750]\n",
            "39210: [discriminator loss: 0.585910, acc: 0.664062] [adversarial loss: 0.997932, acc: 0.343750]\n",
            "39211: [discriminator loss: 0.577378, acc: 0.695312] [adversarial loss: 1.065348, acc: 0.281250]\n",
            "39212: [discriminator loss: 0.600535, acc: 0.679688] [adversarial loss: 1.157995, acc: 0.187500]\n",
            "39213: [discriminator loss: 0.593685, acc: 0.664062] [adversarial loss: 1.113315, acc: 0.203125]\n",
            "39214: [discriminator loss: 0.610516, acc: 0.687500] [adversarial loss: 1.060043, acc: 0.312500]\n",
            "39215: [discriminator loss: 0.660708, acc: 0.632812] [adversarial loss: 1.031949, acc: 0.312500]\n",
            "39216: [discriminator loss: 0.551714, acc: 0.695312] [adversarial loss: 0.895633, acc: 0.390625]\n",
            "39217: [discriminator loss: 0.587411, acc: 0.679688] [adversarial loss: 1.274960, acc: 0.171875]\n",
            "39218: [discriminator loss: 0.627775, acc: 0.648438] [adversarial loss: 0.914153, acc: 0.453125]\n",
            "39219: [discriminator loss: 0.564330, acc: 0.687500] [adversarial loss: 1.279927, acc: 0.203125]\n",
            "39220: [discriminator loss: 0.608625, acc: 0.679688] [adversarial loss: 1.075721, acc: 0.328125]\n",
            "39221: [discriminator loss: 0.614066, acc: 0.664062] [adversarial loss: 1.058974, acc: 0.234375]\n",
            "39222: [discriminator loss: 0.544297, acc: 0.726562] [adversarial loss: 1.021471, acc: 0.296875]\n",
            "39223: [discriminator loss: 0.612905, acc: 0.648438] [adversarial loss: 1.202689, acc: 0.203125]\n",
            "39224: [discriminator loss: 0.580187, acc: 0.625000] [adversarial loss: 1.050262, acc: 0.343750]\n",
            "39225: [discriminator loss: 0.552096, acc: 0.703125] [adversarial loss: 1.269687, acc: 0.187500]\n",
            "39226: [discriminator loss: 0.527827, acc: 0.703125] [adversarial loss: 0.957891, acc: 0.281250]\n",
            "39227: [discriminator loss: 0.537069, acc: 0.703125] [adversarial loss: 1.147705, acc: 0.312500]\n",
            "39228: [discriminator loss: 0.553870, acc: 0.726562] [adversarial loss: 0.881215, acc: 0.375000]\n",
            "39229: [discriminator loss: 0.508926, acc: 0.750000] [adversarial loss: 1.051741, acc: 0.328125]\n",
            "39230: [discriminator loss: 0.533576, acc: 0.726562] [adversarial loss: 1.018646, acc: 0.421875]\n",
            "39231: [discriminator loss: 0.562577, acc: 0.710938] [adversarial loss: 0.771799, acc: 0.515625]\n",
            "39232: [discriminator loss: 0.629503, acc: 0.703125] [adversarial loss: 1.444990, acc: 0.156250]\n",
            "39233: [discriminator loss: 0.682471, acc: 0.617188] [adversarial loss: 0.768313, acc: 0.484375]\n",
            "39234: [discriminator loss: 0.607910, acc: 0.687500] [adversarial loss: 1.339930, acc: 0.218750]\n",
            "39235: [discriminator loss: 0.615083, acc: 0.664062] [adversarial loss: 0.939927, acc: 0.390625]\n",
            "39236: [discriminator loss: 0.607810, acc: 0.679688] [adversarial loss: 1.076544, acc: 0.296875]\n",
            "39237: [discriminator loss: 0.573230, acc: 0.671875] [adversarial loss: 1.007759, acc: 0.281250]\n",
            "39238: [discriminator loss: 0.577382, acc: 0.726562] [adversarial loss: 1.164675, acc: 0.265625]\n",
            "39239: [discriminator loss: 0.645174, acc: 0.625000] [adversarial loss: 0.898131, acc: 0.468750]\n",
            "39240: [discriminator loss: 0.584456, acc: 0.640625] [adversarial loss: 1.342636, acc: 0.140625]\n",
            "39241: [discriminator loss: 0.556684, acc: 0.726562] [adversarial loss: 1.054736, acc: 0.281250]\n",
            "39242: [discriminator loss: 0.572476, acc: 0.664062] [adversarial loss: 1.341905, acc: 0.109375]\n",
            "39243: [discriminator loss: 0.597124, acc: 0.671875] [adversarial loss: 1.022381, acc: 0.265625]\n",
            "39244: [discriminator loss: 0.577281, acc: 0.640625] [adversarial loss: 1.136951, acc: 0.281250]\n",
            "39245: [discriminator loss: 0.616297, acc: 0.679688] [adversarial loss: 1.013240, acc: 0.343750]\n",
            "39246: [discriminator loss: 0.602033, acc: 0.695312] [adversarial loss: 0.924045, acc: 0.406250]\n",
            "39247: [discriminator loss: 0.640543, acc: 0.601562] [adversarial loss: 1.103788, acc: 0.296875]\n",
            "39248: [discriminator loss: 0.567742, acc: 0.742188] [adversarial loss: 1.044962, acc: 0.312500]\n",
            "39249: [discriminator loss: 0.602419, acc: 0.640625] [adversarial loss: 0.952538, acc: 0.359375]\n",
            "39250: [discriminator loss: 0.553443, acc: 0.742188] [adversarial loss: 1.188610, acc: 0.234375]\n",
            "39251: [discriminator loss: 0.588865, acc: 0.703125] [adversarial loss: 1.114416, acc: 0.234375]\n",
            "39252: [discriminator loss: 0.624886, acc: 0.570312] [adversarial loss: 1.127795, acc: 0.281250]\n",
            "39253: [discriminator loss: 0.599294, acc: 0.679688] [adversarial loss: 1.205354, acc: 0.156250]\n",
            "39254: [discriminator loss: 0.531520, acc: 0.773438] [adversarial loss: 0.875613, acc: 0.453125]\n",
            "39255: [discriminator loss: 0.584914, acc: 0.648438] [adversarial loss: 1.229961, acc: 0.156250]\n",
            "39256: [discriminator loss: 0.568533, acc: 0.679688] [adversarial loss: 0.768664, acc: 0.531250]\n",
            "39257: [discriminator loss: 0.577153, acc: 0.695312] [adversarial loss: 1.148049, acc: 0.250000]\n",
            "39258: [discriminator loss: 0.636927, acc: 0.617188] [adversarial loss: 0.828113, acc: 0.578125]\n",
            "39259: [discriminator loss: 0.572653, acc: 0.687500] [adversarial loss: 0.998936, acc: 0.406250]\n",
            "39260: [discriminator loss: 0.611835, acc: 0.703125] [adversarial loss: 1.142303, acc: 0.156250]\n",
            "39261: [discriminator loss: 0.623182, acc: 0.632812] [adversarial loss: 1.143196, acc: 0.234375]\n",
            "39262: [discriminator loss: 0.545811, acc: 0.710938] [adversarial loss: 1.043680, acc: 0.343750]\n",
            "39263: [discriminator loss: 0.571662, acc: 0.695312] [adversarial loss: 0.966619, acc: 0.328125]\n",
            "39264: [discriminator loss: 0.562925, acc: 0.726562] [adversarial loss: 0.989670, acc: 0.296875]\n",
            "39265: [discriminator loss: 0.542623, acc: 0.679688] [adversarial loss: 0.806958, acc: 0.484375]\n",
            "39266: [discriminator loss: 0.616852, acc: 0.703125] [adversarial loss: 1.206945, acc: 0.187500]\n",
            "39267: [discriminator loss: 0.575776, acc: 0.703125] [adversarial loss: 0.918422, acc: 0.406250]\n",
            "39268: [discriminator loss: 0.633348, acc: 0.632812] [adversarial loss: 1.047221, acc: 0.281250]\n",
            "39269: [discriminator loss: 0.554161, acc: 0.703125] [adversarial loss: 0.870249, acc: 0.500000]\n",
            "39270: [discriminator loss: 0.512201, acc: 0.742188] [adversarial loss: 1.132914, acc: 0.203125]\n",
            "39271: [discriminator loss: 0.638970, acc: 0.578125] [adversarial loss: 0.849983, acc: 0.468750]\n",
            "39272: [discriminator loss: 0.569215, acc: 0.703125] [adversarial loss: 1.547501, acc: 0.031250]\n",
            "39273: [discriminator loss: 0.636947, acc: 0.664062] [adversarial loss: 0.802644, acc: 0.453125]\n",
            "39274: [discriminator loss: 0.589747, acc: 0.679688] [adversarial loss: 1.116241, acc: 0.218750]\n",
            "39275: [discriminator loss: 0.591096, acc: 0.687500] [adversarial loss: 1.280266, acc: 0.140625]\n",
            "39276: [discriminator loss: 0.587552, acc: 0.640625] [adversarial loss: 0.931190, acc: 0.375000]\n",
            "39277: [discriminator loss: 0.543665, acc: 0.734375] [adversarial loss: 0.892342, acc: 0.468750]\n",
            "39278: [discriminator loss: 0.663691, acc: 0.578125] [adversarial loss: 1.010794, acc: 0.328125]\n",
            "39279: [discriminator loss: 0.550735, acc: 0.718750] [adversarial loss: 0.774901, acc: 0.500000]\n",
            "39280: [discriminator loss: 0.684004, acc: 0.625000] [adversarial loss: 1.172996, acc: 0.281250]\n",
            "39281: [discriminator loss: 0.622336, acc: 0.656250] [adversarial loss: 0.959188, acc: 0.453125]\n",
            "39282: [discriminator loss: 0.633250, acc: 0.625000] [adversarial loss: 1.041467, acc: 0.281250]\n",
            "39283: [discriminator loss: 0.592466, acc: 0.664062] [adversarial loss: 1.055333, acc: 0.312500]\n",
            "39284: [discriminator loss: 0.490605, acc: 0.781250] [adversarial loss: 1.296171, acc: 0.218750]\n",
            "39285: [discriminator loss: 0.614776, acc: 0.640625] [adversarial loss: 0.986759, acc: 0.390625]\n",
            "39286: [discriminator loss: 0.562490, acc: 0.734375] [adversarial loss: 0.995946, acc: 0.281250]\n",
            "39287: [discriminator loss: 0.613540, acc: 0.632812] [adversarial loss: 1.001900, acc: 0.328125]\n",
            "39288: [discriminator loss: 0.621178, acc: 0.710938] [adversarial loss: 1.219124, acc: 0.171875]\n",
            "39289: [discriminator loss: 0.576850, acc: 0.687500] [adversarial loss: 0.895444, acc: 0.421875]\n",
            "39290: [discriminator loss: 0.547223, acc: 0.718750] [adversarial loss: 1.187444, acc: 0.265625]\n",
            "39291: [discriminator loss: 0.528479, acc: 0.757812] [adversarial loss: 0.915474, acc: 0.328125]\n",
            "39292: [discriminator loss: 0.642377, acc: 0.632812] [adversarial loss: 1.278600, acc: 0.203125]\n",
            "39293: [discriminator loss: 0.576891, acc: 0.687500] [adversarial loss: 1.042240, acc: 0.343750]\n",
            "39294: [discriminator loss: 0.606919, acc: 0.648438] [adversarial loss: 1.118576, acc: 0.203125]\n",
            "39295: [discriminator loss: 0.593295, acc: 0.664062] [adversarial loss: 1.054556, acc: 0.437500]\n",
            "39296: [discriminator loss: 0.555243, acc: 0.671875] [adversarial loss: 1.327555, acc: 0.140625]\n",
            "39297: [discriminator loss: 0.551393, acc: 0.726562] [adversarial loss: 0.985403, acc: 0.312500]\n",
            "39298: [discriminator loss: 0.608300, acc: 0.617188] [adversarial loss: 1.023631, acc: 0.375000]\n",
            "39299: [discriminator loss: 0.596297, acc: 0.695312] [adversarial loss: 1.023099, acc: 0.281250]\n",
            "39300: [discriminator loss: 0.580054, acc: 0.679688] [adversarial loss: 0.847274, acc: 0.484375]\n",
            "39301: [discriminator loss: 0.592950, acc: 0.687500] [adversarial loss: 1.297311, acc: 0.203125]\n",
            "39302: [discriminator loss: 0.627896, acc: 0.617188] [adversarial loss: 0.990448, acc: 0.359375]\n",
            "39303: [discriminator loss: 0.544940, acc: 0.671875] [adversarial loss: 1.162356, acc: 0.265625]\n",
            "39304: [discriminator loss: 0.550165, acc: 0.703125] [adversarial loss: 1.077151, acc: 0.234375]\n",
            "39305: [discriminator loss: 0.549562, acc: 0.757812] [adversarial loss: 0.970983, acc: 0.421875]\n",
            "39306: [discriminator loss: 0.549448, acc: 0.687500] [adversarial loss: 1.106416, acc: 0.265625]\n",
            "39307: [discriminator loss: 0.586517, acc: 0.687500] [adversarial loss: 1.115030, acc: 0.218750]\n",
            "39308: [discriminator loss: 0.577297, acc: 0.679688] [adversarial loss: 1.219803, acc: 0.234375]\n",
            "39309: [discriminator loss: 0.587054, acc: 0.687500] [adversarial loss: 1.154716, acc: 0.203125]\n",
            "39310: [discriminator loss: 0.558240, acc: 0.718750] [adversarial loss: 1.171925, acc: 0.296875]\n",
            "39311: [discriminator loss: 0.559187, acc: 0.726562] [adversarial loss: 1.292817, acc: 0.187500]\n",
            "39312: [discriminator loss: 0.607261, acc: 0.625000] [adversarial loss: 1.189770, acc: 0.265625]\n",
            "39313: [discriminator loss: 0.589573, acc: 0.687500] [adversarial loss: 1.274102, acc: 0.187500]\n",
            "39314: [discriminator loss: 0.528469, acc: 0.726562] [adversarial loss: 1.181041, acc: 0.281250]\n",
            "39315: [discriminator loss: 0.569086, acc: 0.679688] [adversarial loss: 1.097167, acc: 0.312500]\n",
            "39316: [discriminator loss: 0.545225, acc: 0.734375] [adversarial loss: 0.844949, acc: 0.515625]\n",
            "39317: [discriminator loss: 0.635919, acc: 0.632812] [adversarial loss: 1.407558, acc: 0.078125]\n",
            "39318: [discriminator loss: 0.634343, acc: 0.664062] [adversarial loss: 0.847113, acc: 0.468750]\n",
            "39319: [discriminator loss: 0.608292, acc: 0.609375] [adversarial loss: 1.068442, acc: 0.343750]\n",
            "39320: [discriminator loss: 0.535454, acc: 0.781250] [adversarial loss: 0.925608, acc: 0.437500]\n",
            "39321: [discriminator loss: 0.528609, acc: 0.734375] [adversarial loss: 1.464216, acc: 0.140625]\n",
            "39322: [discriminator loss: 0.608196, acc: 0.671875] [adversarial loss: 0.826807, acc: 0.500000]\n",
            "39323: [discriminator loss: 0.590594, acc: 0.671875] [adversarial loss: 1.152811, acc: 0.281250]\n",
            "39324: [discriminator loss: 0.534552, acc: 0.726562] [adversarial loss: 1.093920, acc: 0.359375]\n",
            "39325: [discriminator loss: 0.626453, acc: 0.664062] [adversarial loss: 1.673577, acc: 0.109375]\n",
            "39326: [discriminator loss: 0.599269, acc: 0.671875] [adversarial loss: 0.771465, acc: 0.500000]\n",
            "39327: [discriminator loss: 0.575458, acc: 0.703125] [adversarial loss: 1.258884, acc: 0.265625]\n",
            "39328: [discriminator loss: 0.610339, acc: 0.679688] [adversarial loss: 0.890975, acc: 0.406250]\n",
            "39329: [discriminator loss: 0.569190, acc: 0.718750] [adversarial loss: 1.366827, acc: 0.250000]\n",
            "39330: [discriminator loss: 0.665696, acc: 0.632812] [adversarial loss: 1.014462, acc: 0.390625]\n",
            "39331: [discriminator loss: 0.583074, acc: 0.718750] [adversarial loss: 0.965005, acc: 0.359375]\n",
            "39332: [discriminator loss: 0.600158, acc: 0.765625] [adversarial loss: 1.237238, acc: 0.265625]\n",
            "39333: [discriminator loss: 0.580627, acc: 0.679688] [adversarial loss: 0.948870, acc: 0.437500]\n",
            "39334: [discriminator loss: 0.627534, acc: 0.640625] [adversarial loss: 1.261694, acc: 0.218750]\n",
            "39335: [discriminator loss: 0.660954, acc: 0.625000] [adversarial loss: 0.776710, acc: 0.515625]\n",
            "39336: [discriminator loss: 0.506428, acc: 0.726562] [adversarial loss: 1.357592, acc: 0.171875]\n",
            "39337: [discriminator loss: 0.593761, acc: 0.648438] [adversarial loss: 0.886145, acc: 0.328125]\n",
            "39338: [discriminator loss: 0.558670, acc: 0.726562] [adversarial loss: 1.052079, acc: 0.312500]\n",
            "39339: [discriminator loss: 0.568657, acc: 0.695312] [adversarial loss: 0.852170, acc: 0.453125]\n",
            "39340: [discriminator loss: 0.538342, acc: 0.781250] [adversarial loss: 1.003493, acc: 0.265625]\n",
            "39341: [discriminator loss: 0.522561, acc: 0.765625] [adversarial loss: 1.029469, acc: 0.359375]\n",
            "39342: [discriminator loss: 0.576376, acc: 0.679688] [adversarial loss: 0.926905, acc: 0.375000]\n",
            "39343: [discriminator loss: 0.544311, acc: 0.710938] [adversarial loss: 1.140914, acc: 0.265625]\n",
            "39344: [discriminator loss: 0.532077, acc: 0.757812] [adversarial loss: 0.969578, acc: 0.312500]\n",
            "39345: [discriminator loss: 0.605487, acc: 0.671875] [adversarial loss: 1.115793, acc: 0.187500]\n",
            "39346: [discriminator loss: 0.531921, acc: 0.726562] [adversarial loss: 0.859309, acc: 0.484375]\n",
            "39347: [discriminator loss: 0.563233, acc: 0.734375] [adversarial loss: 1.364308, acc: 0.171875]\n",
            "39348: [discriminator loss: 0.608030, acc: 0.687500] [adversarial loss: 1.235624, acc: 0.218750]\n",
            "39349: [discriminator loss: 0.548871, acc: 0.734375] [adversarial loss: 1.153235, acc: 0.250000]\n",
            "39350: [discriminator loss: 0.551515, acc: 0.734375] [adversarial loss: 1.201050, acc: 0.265625]\n",
            "39351: [discriminator loss: 0.548729, acc: 0.703125] [adversarial loss: 0.965219, acc: 0.437500]\n",
            "39352: [discriminator loss: 0.595047, acc: 0.656250] [adversarial loss: 0.998333, acc: 0.375000]\n",
            "39353: [discriminator loss: 0.558130, acc: 0.703125] [adversarial loss: 0.919461, acc: 0.406250]\n",
            "39354: [discriminator loss: 0.579934, acc: 0.656250] [adversarial loss: 1.632740, acc: 0.062500]\n",
            "39355: [discriminator loss: 0.680302, acc: 0.601562] [adversarial loss: 0.712332, acc: 0.578125]\n",
            "39356: [discriminator loss: 0.526137, acc: 0.742188] [adversarial loss: 1.170969, acc: 0.281250]\n",
            "39357: [discriminator loss: 0.578194, acc: 0.648438] [adversarial loss: 0.892107, acc: 0.437500]\n",
            "39358: [discriminator loss: 0.556987, acc: 0.695312] [adversarial loss: 1.095579, acc: 0.265625]\n",
            "39359: [discriminator loss: 0.635943, acc: 0.632812] [adversarial loss: 1.147401, acc: 0.343750]\n",
            "39360: [discriminator loss: 0.507768, acc: 0.765625] [adversarial loss: 1.012670, acc: 0.343750]\n",
            "39361: [discriminator loss: 0.529524, acc: 0.750000] [adversarial loss: 1.212008, acc: 0.312500]\n",
            "39362: [discriminator loss: 0.535153, acc: 0.703125] [adversarial loss: 1.103229, acc: 0.390625]\n",
            "39363: [discriminator loss: 0.596013, acc: 0.648438] [adversarial loss: 1.035475, acc: 0.312500]\n",
            "39364: [discriminator loss: 0.609793, acc: 0.687500] [adversarial loss: 1.302749, acc: 0.171875]\n",
            "39365: [discriminator loss: 0.530862, acc: 0.750000] [adversarial loss: 1.072508, acc: 0.359375]\n",
            "39366: [discriminator loss: 0.593416, acc: 0.664062] [adversarial loss: 1.221256, acc: 0.187500]\n",
            "39367: [discriminator loss: 0.562765, acc: 0.703125] [adversarial loss: 0.948365, acc: 0.437500]\n",
            "39368: [discriminator loss: 0.614329, acc: 0.601562] [adversarial loss: 1.053032, acc: 0.343750]\n",
            "39369: [discriminator loss: 0.531828, acc: 0.757812] [adversarial loss: 1.046667, acc: 0.359375]\n",
            "39370: [discriminator loss: 0.602045, acc: 0.679688] [adversarial loss: 1.100135, acc: 0.328125]\n",
            "39371: [discriminator loss: 0.651422, acc: 0.632812] [adversarial loss: 1.103339, acc: 0.250000]\n",
            "39372: [discriminator loss: 0.628758, acc: 0.687500] [adversarial loss: 0.895573, acc: 0.406250]\n",
            "39373: [discriminator loss: 0.555977, acc: 0.710938] [adversarial loss: 1.194283, acc: 0.203125]\n",
            "39374: [discriminator loss: 0.569159, acc: 0.726562] [adversarial loss: 1.211291, acc: 0.281250]\n",
            "39375: [discriminator loss: 0.593653, acc: 0.671875] [adversarial loss: 0.750482, acc: 0.468750]\n",
            "39376: [discriminator loss: 0.637780, acc: 0.679688] [adversarial loss: 1.509438, acc: 0.078125]\n",
            "39377: [discriminator loss: 0.572193, acc: 0.640625] [adversarial loss: 0.949725, acc: 0.390625]\n",
            "39378: [discriminator loss: 0.603967, acc: 0.710938] [adversarial loss: 1.303008, acc: 0.234375]\n",
            "39379: [discriminator loss: 0.600452, acc: 0.664062] [adversarial loss: 0.775080, acc: 0.562500]\n",
            "39380: [discriminator loss: 0.608883, acc: 0.703125] [adversarial loss: 1.008122, acc: 0.390625]\n",
            "39381: [discriminator loss: 0.563412, acc: 0.703125] [adversarial loss: 1.107167, acc: 0.265625]\n",
            "39382: [discriminator loss: 0.596299, acc: 0.664062] [adversarial loss: 1.006418, acc: 0.375000]\n",
            "39383: [discriminator loss: 0.583708, acc: 0.742188] [adversarial loss: 0.971799, acc: 0.312500]\n",
            "39384: [discriminator loss: 0.559726, acc: 0.710938] [adversarial loss: 1.036021, acc: 0.250000]\n",
            "39385: [discriminator loss: 0.540175, acc: 0.742188] [adversarial loss: 1.099070, acc: 0.281250]\n",
            "39386: [discriminator loss: 0.603124, acc: 0.703125] [adversarial loss: 1.210384, acc: 0.250000]\n",
            "39387: [discriminator loss: 0.540898, acc: 0.726562] [adversarial loss: 1.088546, acc: 0.296875]\n",
            "39388: [discriminator loss: 0.574946, acc: 0.703125] [adversarial loss: 1.085960, acc: 0.296875]\n",
            "39389: [discriminator loss: 0.550942, acc: 0.703125] [adversarial loss: 1.134268, acc: 0.328125]\n",
            "39390: [discriminator loss: 0.592859, acc: 0.695312] [adversarial loss: 1.059913, acc: 0.328125]\n",
            "39391: [discriminator loss: 0.609267, acc: 0.640625] [adversarial loss: 0.928476, acc: 0.453125]\n",
            "39392: [discriminator loss: 0.530401, acc: 0.710938] [adversarial loss: 1.131897, acc: 0.281250]\n",
            "39393: [discriminator loss: 0.548165, acc: 0.726562] [adversarial loss: 1.048566, acc: 0.328125]\n",
            "39394: [discriminator loss: 0.603611, acc: 0.664062] [adversarial loss: 1.104048, acc: 0.281250]\n",
            "39395: [discriminator loss: 0.544194, acc: 0.742188] [adversarial loss: 1.424384, acc: 0.203125]\n",
            "39396: [discriminator loss: 0.633698, acc: 0.593750] [adversarial loss: 0.766687, acc: 0.531250]\n",
            "39397: [discriminator loss: 0.588082, acc: 0.679688] [adversarial loss: 1.377308, acc: 0.109375]\n",
            "39398: [discriminator loss: 0.596030, acc: 0.671875] [adversarial loss: 0.979705, acc: 0.312500]\n",
            "39399: [discriminator loss: 0.564001, acc: 0.734375] [adversarial loss: 1.382235, acc: 0.093750]\n",
            "39400: [discriminator loss: 0.553247, acc: 0.664062] [adversarial loss: 1.004168, acc: 0.343750]\n",
            "39401: [discriminator loss: 0.585257, acc: 0.703125] [adversarial loss: 1.201062, acc: 0.218750]\n",
            "39402: [discriminator loss: 0.538571, acc: 0.750000] [adversarial loss: 1.004521, acc: 0.265625]\n",
            "39403: [discriminator loss: 0.574514, acc: 0.687500] [adversarial loss: 1.040730, acc: 0.281250]\n",
            "39404: [discriminator loss: 0.541800, acc: 0.750000] [adversarial loss: 1.078887, acc: 0.343750]\n",
            "39405: [discriminator loss: 0.617000, acc: 0.640625] [adversarial loss: 1.102051, acc: 0.218750]\n",
            "39406: [discriminator loss: 0.558599, acc: 0.703125] [adversarial loss: 0.859930, acc: 0.406250]\n",
            "39407: [discriminator loss: 0.563414, acc: 0.710938] [adversarial loss: 0.937950, acc: 0.390625]\n",
            "39408: [discriminator loss: 0.552468, acc: 0.710938] [adversarial loss: 1.034495, acc: 0.375000]\n",
            "39409: [discriminator loss: 0.560742, acc: 0.703125] [adversarial loss: 1.056780, acc: 0.343750]\n",
            "39410: [discriminator loss: 0.546411, acc: 0.695312] [adversarial loss: 1.161332, acc: 0.234375]\n",
            "39411: [discriminator loss: 0.556048, acc: 0.718750] [adversarial loss: 0.858190, acc: 0.406250]\n",
            "39412: [discriminator loss: 0.611448, acc: 0.671875] [adversarial loss: 1.227888, acc: 0.156250]\n",
            "39413: [discriminator loss: 0.579053, acc: 0.671875] [adversarial loss: 1.047680, acc: 0.312500]\n",
            "39414: [discriminator loss: 0.595177, acc: 0.671875] [adversarial loss: 1.052035, acc: 0.328125]\n",
            "39415: [discriminator loss: 0.535038, acc: 0.734375] [adversarial loss: 1.106394, acc: 0.281250]\n",
            "39416: [discriminator loss: 0.574630, acc: 0.687500] [adversarial loss: 1.066716, acc: 0.281250]\n",
            "39417: [discriminator loss: 0.601928, acc: 0.695312] [adversarial loss: 1.195036, acc: 0.265625]\n",
            "39418: [discriminator loss: 0.622060, acc: 0.632812] [adversarial loss: 1.170854, acc: 0.265625]\n",
            "39419: [discriminator loss: 0.548789, acc: 0.726562] [adversarial loss: 0.770437, acc: 0.562500]\n",
            "39420: [discriminator loss: 0.531686, acc: 0.726562] [adversarial loss: 1.289795, acc: 0.171875]\n",
            "39421: [discriminator loss: 0.625998, acc: 0.632812] [adversarial loss: 0.690142, acc: 0.593750]\n",
            "39422: [discriminator loss: 0.534995, acc: 0.679688] [adversarial loss: 1.335369, acc: 0.156250]\n",
            "39423: [discriminator loss: 0.579263, acc: 0.703125] [adversarial loss: 0.816022, acc: 0.500000]\n",
            "39424: [discriminator loss: 0.565884, acc: 0.726562] [adversarial loss: 1.267706, acc: 0.171875]\n",
            "39425: [discriminator loss: 0.636587, acc: 0.656250] [adversarial loss: 0.976687, acc: 0.359375]\n",
            "39426: [discriminator loss: 0.627722, acc: 0.625000] [adversarial loss: 1.446478, acc: 0.078125]\n",
            "39427: [discriminator loss: 0.645358, acc: 0.664062] [adversarial loss: 0.848849, acc: 0.468750]\n",
            "39428: [discriminator loss: 0.662817, acc: 0.617188] [adversarial loss: 1.255031, acc: 0.265625]\n",
            "39429: [discriminator loss: 0.623840, acc: 0.617188] [adversarial loss: 1.053698, acc: 0.296875]\n",
            "39430: [discriminator loss: 0.571418, acc: 0.734375] [adversarial loss: 0.928211, acc: 0.375000]\n",
            "39431: [discriminator loss: 0.561004, acc: 0.718750] [adversarial loss: 1.142147, acc: 0.203125]\n",
            "39432: [discriminator loss: 0.550331, acc: 0.734375] [adversarial loss: 0.788950, acc: 0.468750]\n",
            "39433: [discriminator loss: 0.558393, acc: 0.734375] [adversarial loss: 1.208210, acc: 0.234375]\n",
            "39434: [discriminator loss: 0.655130, acc: 0.632812] [adversarial loss: 1.017647, acc: 0.359375]\n",
            "39435: [discriminator loss: 0.595704, acc: 0.664062] [adversarial loss: 1.276310, acc: 0.156250]\n",
            "39436: [discriminator loss: 0.522453, acc: 0.742188] [adversarial loss: 1.041679, acc: 0.421875]\n",
            "39437: [discriminator loss: 0.583492, acc: 0.609375] [adversarial loss: 1.239974, acc: 0.218750]\n",
            "39438: [discriminator loss: 0.665654, acc: 0.617188] [adversarial loss: 0.887385, acc: 0.406250]\n",
            "39439: [discriminator loss: 0.529427, acc: 0.687500] [adversarial loss: 1.297936, acc: 0.171875]\n",
            "39440: [discriminator loss: 0.566439, acc: 0.687500] [adversarial loss: 1.100650, acc: 0.250000]\n",
            "39441: [discriminator loss: 0.602958, acc: 0.695312] [adversarial loss: 1.116482, acc: 0.234375]\n",
            "39442: [discriminator loss: 0.570867, acc: 0.726562] [adversarial loss: 1.118106, acc: 0.265625]\n",
            "39443: [discriminator loss: 0.575545, acc: 0.695312] [adversarial loss: 0.852840, acc: 0.437500]\n",
            "39444: [discriminator loss: 0.523639, acc: 0.757812] [adversarial loss: 1.415598, acc: 0.187500]\n",
            "39445: [discriminator loss: 0.623392, acc: 0.632812] [adversarial loss: 0.855705, acc: 0.484375]\n",
            "39446: [discriminator loss: 0.618501, acc: 0.648438] [adversarial loss: 1.141899, acc: 0.250000]\n",
            "39447: [discriminator loss: 0.568837, acc: 0.679688] [adversarial loss: 1.037803, acc: 0.375000]\n",
            "39448: [discriminator loss: 0.596143, acc: 0.679688] [adversarial loss: 1.096532, acc: 0.328125]\n",
            "39449: [discriminator loss: 0.647342, acc: 0.609375] [adversarial loss: 0.875145, acc: 0.484375]\n",
            "39450: [discriminator loss: 0.600568, acc: 0.648438] [adversarial loss: 0.806747, acc: 0.500000]\n",
            "39451: [discriminator loss: 0.561151, acc: 0.695312] [adversarial loss: 1.251073, acc: 0.203125]\n",
            "39452: [discriminator loss: 0.584650, acc: 0.695312] [adversarial loss: 1.109419, acc: 0.218750]\n",
            "39453: [discriminator loss: 0.587106, acc: 0.632812] [adversarial loss: 1.339742, acc: 0.156250]\n",
            "39454: [discriminator loss: 0.574169, acc: 0.656250] [adversarial loss: 0.984357, acc: 0.281250]\n",
            "39455: [discriminator loss: 0.622764, acc: 0.695312] [adversarial loss: 1.051397, acc: 0.281250]\n",
            "39456: [discriminator loss: 0.643390, acc: 0.625000] [adversarial loss: 1.042842, acc: 0.343750]\n",
            "39457: [discriminator loss: 0.507667, acc: 0.781250] [adversarial loss: 1.077367, acc: 0.312500]\n",
            "39458: [discriminator loss: 0.616473, acc: 0.609375] [adversarial loss: 1.104078, acc: 0.296875]\n",
            "39459: [discriminator loss: 0.541923, acc: 0.726562] [adversarial loss: 1.174121, acc: 0.281250]\n",
            "39460: [discriminator loss: 0.591298, acc: 0.703125] [adversarial loss: 1.173659, acc: 0.265625]\n",
            "39461: [discriminator loss: 0.573504, acc: 0.656250] [adversarial loss: 1.015707, acc: 0.468750]\n",
            "39462: [discriminator loss: 0.576673, acc: 0.656250] [adversarial loss: 1.137157, acc: 0.281250]\n",
            "39463: [discriminator loss: 0.566135, acc: 0.648438] [adversarial loss: 1.511210, acc: 0.187500]\n",
            "39464: [discriminator loss: 0.626981, acc: 0.601562] [adversarial loss: 0.946626, acc: 0.453125]\n",
            "39465: [discriminator loss: 0.547137, acc: 0.718750] [adversarial loss: 1.089705, acc: 0.328125]\n",
            "39466: [discriminator loss: 0.579743, acc: 0.710938] [adversarial loss: 0.957784, acc: 0.390625]\n",
            "39467: [discriminator loss: 0.549174, acc: 0.710938] [adversarial loss: 1.198292, acc: 0.156250]\n",
            "39468: [discriminator loss: 0.530484, acc: 0.710938] [adversarial loss: 1.198848, acc: 0.250000]\n",
            "39469: [discriminator loss: 0.496683, acc: 0.765625] [adversarial loss: 0.909496, acc: 0.515625]\n",
            "39470: [discriminator loss: 0.506523, acc: 0.773438] [adversarial loss: 1.189512, acc: 0.265625]\n",
            "39471: [discriminator loss: 0.530486, acc: 0.734375] [adversarial loss: 0.979202, acc: 0.468750]\n",
            "39472: [discriminator loss: 0.614831, acc: 0.664062] [adversarial loss: 1.254086, acc: 0.187500]\n",
            "39473: [discriminator loss: 0.577825, acc: 0.671875] [adversarial loss: 0.773802, acc: 0.531250]\n",
            "39474: [discriminator loss: 0.597097, acc: 0.640625] [adversarial loss: 1.398404, acc: 0.140625]\n",
            "39475: [discriminator loss: 0.650110, acc: 0.664062] [adversarial loss: 0.693431, acc: 0.593750]\n",
            "39476: [discriminator loss: 0.569208, acc: 0.718750] [adversarial loss: 0.976871, acc: 0.343750]\n",
            "39477: [discriminator loss: 0.599334, acc: 0.687500] [adversarial loss: 1.125460, acc: 0.203125]\n",
            "39478: [discriminator loss: 0.610300, acc: 0.617188] [adversarial loss: 1.102476, acc: 0.296875]\n",
            "39479: [discriminator loss: 0.584974, acc: 0.695312] [adversarial loss: 1.033303, acc: 0.390625]\n",
            "39480: [discriminator loss: 0.517975, acc: 0.757812] [adversarial loss: 0.892141, acc: 0.359375]\n",
            "39481: [discriminator loss: 0.548477, acc: 0.710938] [adversarial loss: 1.246579, acc: 0.234375]\n",
            "39482: [discriminator loss: 0.667482, acc: 0.570312] [adversarial loss: 1.063501, acc: 0.265625]\n",
            "39483: [discriminator loss: 0.567327, acc: 0.718750] [adversarial loss: 1.299670, acc: 0.187500]\n",
            "39484: [discriminator loss: 0.565616, acc: 0.718750] [adversarial loss: 1.092155, acc: 0.281250]\n",
            "39485: [discriminator loss: 0.493905, acc: 0.726562] [adversarial loss: 1.103812, acc: 0.281250]\n",
            "39486: [discriminator loss: 0.569238, acc: 0.710938] [adversarial loss: 1.051955, acc: 0.328125]\n",
            "39487: [discriminator loss: 0.579309, acc: 0.625000] [adversarial loss: 0.981726, acc: 0.296875]\n",
            "39488: [discriminator loss: 0.560041, acc: 0.703125] [adversarial loss: 1.273187, acc: 0.140625]\n",
            "39489: [discriminator loss: 0.596672, acc: 0.710938] [adversarial loss: 0.948821, acc: 0.421875]\n",
            "39490: [discriminator loss: 0.571379, acc: 0.726562] [adversarial loss: 1.156734, acc: 0.281250]\n",
            "39491: [discriminator loss: 0.569806, acc: 0.695312] [adversarial loss: 0.729550, acc: 0.562500]\n",
            "39492: [discriminator loss: 0.582857, acc: 0.695312] [adversarial loss: 1.378503, acc: 0.140625]\n",
            "39493: [discriminator loss: 0.593724, acc: 0.648438] [adversarial loss: 0.823624, acc: 0.500000]\n",
            "39494: [discriminator loss: 0.561446, acc: 0.718750] [adversarial loss: 1.303705, acc: 0.234375]\n",
            "39495: [discriminator loss: 0.594982, acc: 0.671875] [adversarial loss: 0.916065, acc: 0.343750]\n",
            "39496: [discriminator loss: 0.615498, acc: 0.671875] [adversarial loss: 1.419291, acc: 0.187500]\n",
            "39497: [discriminator loss: 0.528980, acc: 0.742188] [adversarial loss: 0.903055, acc: 0.390625]\n",
            "39498: [discriminator loss: 0.595658, acc: 0.632812] [adversarial loss: 1.344081, acc: 0.250000]\n",
            "39499: [discriminator loss: 0.496737, acc: 0.726562] [adversarial loss: 0.844600, acc: 0.437500]\n",
            "39500: [discriminator loss: 0.578512, acc: 0.703125] [adversarial loss: 1.199357, acc: 0.203125]\n",
            "39501: [discriminator loss: 0.552992, acc: 0.687500] [adversarial loss: 1.007683, acc: 0.375000]\n",
            "39502: [discriminator loss: 0.608565, acc: 0.632812] [adversarial loss: 1.069762, acc: 0.265625]\n",
            "39503: [discriminator loss: 0.537725, acc: 0.734375] [adversarial loss: 1.123668, acc: 0.312500]\n",
            "39504: [discriminator loss: 0.590053, acc: 0.695312] [adversarial loss: 0.888463, acc: 0.468750]\n",
            "39505: [discriminator loss: 0.639586, acc: 0.617188] [adversarial loss: 1.213249, acc: 0.250000]\n",
            "39506: [discriminator loss: 0.556959, acc: 0.664062] [adversarial loss: 0.883717, acc: 0.578125]\n",
            "39507: [discriminator loss: 0.582370, acc: 0.671875] [adversarial loss: 1.027369, acc: 0.359375]\n",
            "39508: [discriminator loss: 0.554025, acc: 0.742188] [adversarial loss: 1.177823, acc: 0.234375]\n",
            "39509: [discriminator loss: 0.611178, acc: 0.632812] [adversarial loss: 1.186105, acc: 0.218750]\n",
            "39510: [discriminator loss: 0.605992, acc: 0.648438] [adversarial loss: 0.895856, acc: 0.453125]\n",
            "39511: [discriminator loss: 0.626006, acc: 0.664062] [adversarial loss: 1.199968, acc: 0.156250]\n",
            "39512: [discriminator loss: 0.565103, acc: 0.718750] [adversarial loss: 0.803776, acc: 0.500000]\n",
            "39513: [discriminator loss: 0.576454, acc: 0.695312] [adversarial loss: 1.199897, acc: 0.250000]\n",
            "39514: [discriminator loss: 0.611792, acc: 0.679688] [adversarial loss: 0.951311, acc: 0.453125]\n",
            "39515: [discriminator loss: 0.586811, acc: 0.695312] [adversarial loss: 0.964616, acc: 0.375000]\n",
            "39516: [discriminator loss: 0.591643, acc: 0.679688] [adversarial loss: 1.167831, acc: 0.281250]\n",
            "39517: [discriminator loss: 0.611011, acc: 0.671875] [adversarial loss: 1.249640, acc: 0.218750]\n",
            "39518: [discriminator loss: 0.562935, acc: 0.664062] [adversarial loss: 1.230446, acc: 0.187500]\n",
            "39519: [discriminator loss: 0.611892, acc: 0.687500] [adversarial loss: 1.075711, acc: 0.296875]\n",
            "39520: [discriminator loss: 0.635325, acc: 0.609375] [adversarial loss: 0.855958, acc: 0.484375]\n",
            "39521: [discriminator loss: 0.548457, acc: 0.734375] [adversarial loss: 1.269786, acc: 0.187500]\n",
            "39522: [discriminator loss: 0.588724, acc: 0.687500] [adversarial loss: 1.002848, acc: 0.390625]\n",
            "39523: [discriminator loss: 0.602145, acc: 0.679688] [adversarial loss: 1.348411, acc: 0.109375]\n",
            "39524: [discriminator loss: 0.580602, acc: 0.679688] [adversarial loss: 0.976949, acc: 0.375000]\n",
            "39525: [discriminator loss: 0.582774, acc: 0.695312] [adversarial loss: 1.121834, acc: 0.281250]\n",
            "39526: [discriminator loss: 0.511331, acc: 0.796875] [adversarial loss: 0.698360, acc: 0.546875]\n",
            "39527: [discriminator loss: 0.600026, acc: 0.671875] [adversarial loss: 1.320647, acc: 0.140625]\n",
            "39528: [discriminator loss: 0.591380, acc: 0.695312] [adversarial loss: 0.904579, acc: 0.453125]\n",
            "39529: [discriminator loss: 0.585963, acc: 0.609375] [adversarial loss: 1.414299, acc: 0.140625]\n",
            "39530: [discriminator loss: 0.552006, acc: 0.781250] [adversarial loss: 1.004528, acc: 0.359375]\n",
            "39531: [discriminator loss: 0.580388, acc: 0.664062] [adversarial loss: 1.237687, acc: 0.250000]\n",
            "39532: [discriminator loss: 0.523644, acc: 0.742188] [adversarial loss: 1.023816, acc: 0.328125]\n",
            "39533: [discriminator loss: 0.598819, acc: 0.648438] [adversarial loss: 1.250248, acc: 0.171875]\n",
            "39534: [discriminator loss: 0.524487, acc: 0.710938] [adversarial loss: 1.124297, acc: 0.234375]\n",
            "39535: [discriminator loss: 0.613715, acc: 0.679688] [adversarial loss: 1.203439, acc: 0.281250]\n",
            "39536: [discriminator loss: 0.616632, acc: 0.671875] [adversarial loss: 1.050539, acc: 0.328125]\n",
            "39537: [discriminator loss: 0.589188, acc: 0.648438] [adversarial loss: 1.204038, acc: 0.203125]\n",
            "39538: [discriminator loss: 0.555726, acc: 0.718750] [adversarial loss: 1.228928, acc: 0.218750]\n",
            "39539: [discriminator loss: 0.605573, acc: 0.656250] [adversarial loss: 0.998073, acc: 0.312500]\n",
            "39540: [discriminator loss: 0.521145, acc: 0.765625] [adversarial loss: 0.961167, acc: 0.375000]\n",
            "39541: [discriminator loss: 0.602668, acc: 0.679688] [adversarial loss: 1.119971, acc: 0.203125]\n",
            "39542: [discriminator loss: 0.579077, acc: 0.734375] [adversarial loss: 1.005606, acc: 0.281250]\n",
            "39543: [discriminator loss: 0.569247, acc: 0.671875] [adversarial loss: 1.050308, acc: 0.375000]\n",
            "39544: [discriminator loss: 0.518406, acc: 0.726562] [adversarial loss: 1.145522, acc: 0.265625]\n",
            "39545: [discriminator loss: 0.568444, acc: 0.718750] [adversarial loss: 1.043749, acc: 0.343750]\n",
            "39546: [discriminator loss: 0.574683, acc: 0.695312] [adversarial loss: 0.917860, acc: 0.343750]\n",
            "39547: [discriminator loss: 0.624578, acc: 0.648438] [adversarial loss: 1.316134, acc: 0.156250]\n",
            "39548: [discriminator loss: 0.639837, acc: 0.640625] [adversarial loss: 0.954719, acc: 0.406250]\n",
            "39549: [discriminator loss: 0.535881, acc: 0.757812] [adversarial loss: 1.152766, acc: 0.296875]\n",
            "39550: [discriminator loss: 0.582707, acc: 0.687500] [adversarial loss: 1.016808, acc: 0.359375]\n",
            "39551: [discriminator loss: 0.585305, acc: 0.679688] [adversarial loss: 0.971444, acc: 0.375000]\n",
            "39552: [discriminator loss: 0.564000, acc: 0.710938] [adversarial loss: 1.012482, acc: 0.375000]\n",
            "39553: [discriminator loss: 0.610637, acc: 0.664062] [adversarial loss: 1.034829, acc: 0.312500]\n",
            "39554: [discriminator loss: 0.546414, acc: 0.664062] [adversarial loss: 1.003735, acc: 0.437500]\n",
            "39555: [discriminator loss: 0.570645, acc: 0.695312] [adversarial loss: 1.251911, acc: 0.156250]\n",
            "39556: [discriminator loss: 0.592103, acc: 0.726562] [adversarial loss: 1.009819, acc: 0.359375]\n",
            "39557: [discriminator loss: 0.621529, acc: 0.656250] [adversarial loss: 1.419625, acc: 0.156250]\n",
            "39558: [discriminator loss: 0.655501, acc: 0.625000] [adversarial loss: 0.755805, acc: 0.609375]\n",
            "39559: [discriminator loss: 0.648822, acc: 0.617188] [adversarial loss: 1.336635, acc: 0.171875]\n",
            "39560: [discriminator loss: 0.626034, acc: 0.656250] [adversarial loss: 0.822302, acc: 0.453125]\n",
            "39561: [discriminator loss: 0.607773, acc: 0.640625] [adversarial loss: 1.011799, acc: 0.250000]\n",
            "39562: [discriminator loss: 0.557017, acc: 0.757812] [adversarial loss: 1.275990, acc: 0.187500]\n",
            "39563: [discriminator loss: 0.586360, acc: 0.640625] [adversarial loss: 0.799821, acc: 0.515625]\n",
            "39564: [discriminator loss: 0.581536, acc: 0.671875] [adversarial loss: 1.417490, acc: 0.125000]\n",
            "39565: [discriminator loss: 0.562903, acc: 0.703125] [adversarial loss: 0.870086, acc: 0.468750]\n",
            "39566: [discriminator loss: 0.580351, acc: 0.687500] [adversarial loss: 1.281523, acc: 0.156250]\n",
            "39567: [discriminator loss: 0.566913, acc: 0.703125] [adversarial loss: 0.918642, acc: 0.390625]\n",
            "39568: [discriminator loss: 0.578401, acc: 0.687500] [adversarial loss: 1.099170, acc: 0.296875]\n",
            "39569: [discriminator loss: 0.571477, acc: 0.742188] [adversarial loss: 0.791248, acc: 0.453125]\n",
            "39570: [discriminator loss: 0.631788, acc: 0.601562] [adversarial loss: 1.120082, acc: 0.218750]\n",
            "39571: [discriminator loss: 0.578270, acc: 0.664062] [adversarial loss: 0.980897, acc: 0.359375]\n",
            "39572: [discriminator loss: 0.591800, acc: 0.679688] [adversarial loss: 1.036126, acc: 0.265625]\n",
            "39573: [discriminator loss: 0.633216, acc: 0.593750] [adversarial loss: 1.165444, acc: 0.296875]\n",
            "39574: [discriminator loss: 0.531793, acc: 0.710938] [adversarial loss: 1.058861, acc: 0.359375]\n",
            "39575: [discriminator loss: 0.580801, acc: 0.703125] [adversarial loss: 1.047480, acc: 0.406250]\n",
            "39576: [discriminator loss: 0.564501, acc: 0.718750] [adversarial loss: 1.136786, acc: 0.265625]\n",
            "39577: [discriminator loss: 0.545046, acc: 0.734375] [adversarial loss: 0.965011, acc: 0.375000]\n",
            "39578: [discriminator loss: 0.566632, acc: 0.703125] [adversarial loss: 1.121315, acc: 0.234375]\n",
            "39579: [discriminator loss: 0.584719, acc: 0.703125] [adversarial loss: 1.024292, acc: 0.421875]\n",
            "39580: [discriminator loss: 0.614679, acc: 0.617188] [adversarial loss: 0.980983, acc: 0.406250]\n",
            "39581: [discriminator loss: 0.602545, acc: 0.640625] [adversarial loss: 1.105409, acc: 0.234375]\n",
            "39582: [discriminator loss: 0.614664, acc: 0.656250] [adversarial loss: 0.920326, acc: 0.406250]\n",
            "39583: [discriminator loss: 0.613954, acc: 0.609375] [adversarial loss: 1.151499, acc: 0.234375]\n",
            "39584: [discriminator loss: 0.557945, acc: 0.679688] [adversarial loss: 0.958197, acc: 0.406250]\n",
            "39585: [discriminator loss: 0.568729, acc: 0.703125] [adversarial loss: 1.003061, acc: 0.281250]\n",
            "39586: [discriminator loss: 0.600166, acc: 0.625000] [adversarial loss: 1.145571, acc: 0.296875]\n",
            "39587: [discriminator loss: 0.518290, acc: 0.734375] [adversarial loss: 1.066556, acc: 0.265625]\n",
            "39588: [discriminator loss: 0.575955, acc: 0.617188] [adversarial loss: 1.102201, acc: 0.343750]\n",
            "39589: [discriminator loss: 0.563137, acc: 0.695312] [adversarial loss: 0.802686, acc: 0.500000]\n",
            "39590: [discriminator loss: 0.653343, acc: 0.632812] [adversarial loss: 1.691527, acc: 0.031250]\n",
            "39591: [discriminator loss: 0.603371, acc: 0.679688] [adversarial loss: 0.859313, acc: 0.421875]\n",
            "39592: [discriminator loss: 0.567233, acc: 0.640625] [adversarial loss: 1.238925, acc: 0.187500]\n",
            "39593: [discriminator loss: 0.543021, acc: 0.718750] [adversarial loss: 1.009348, acc: 0.343750]\n",
            "39594: [discriminator loss: 0.547256, acc: 0.734375] [adversarial loss: 1.097392, acc: 0.281250]\n",
            "39595: [discriminator loss: 0.564096, acc: 0.726562] [adversarial loss: 1.010316, acc: 0.281250]\n",
            "39596: [discriminator loss: 0.532827, acc: 0.726562] [adversarial loss: 1.125811, acc: 0.218750]\n",
            "39597: [discriminator loss: 0.547000, acc: 0.726562] [adversarial loss: 1.179967, acc: 0.171875]\n",
            "39598: [discriminator loss: 0.497470, acc: 0.765625] [adversarial loss: 1.014925, acc: 0.343750]\n",
            "39599: [discriminator loss: 0.542755, acc: 0.726562] [adversarial loss: 1.033672, acc: 0.359375]\n",
            "39600: [discriminator loss: 0.556447, acc: 0.718750] [adversarial loss: 1.107229, acc: 0.218750]\n",
            "39601: [discriminator loss: 0.617460, acc: 0.671875] [adversarial loss: 1.288830, acc: 0.171875]\n",
            "39602: [discriminator loss: 0.578897, acc: 0.710938] [adversarial loss: 1.246852, acc: 0.171875]\n",
            "39603: [discriminator loss: 0.592179, acc: 0.679688] [adversarial loss: 1.243350, acc: 0.156250]\n",
            "39604: [discriminator loss: 0.528370, acc: 0.750000] [adversarial loss: 1.059737, acc: 0.265625]\n",
            "39605: [discriminator loss: 0.561060, acc: 0.710938] [adversarial loss: 1.060430, acc: 0.281250]\n",
            "39606: [discriminator loss: 0.605845, acc: 0.664062] [adversarial loss: 1.314245, acc: 0.125000]\n",
            "39607: [discriminator loss: 0.630779, acc: 0.632812] [adversarial loss: 0.944511, acc: 0.312500]\n",
            "39608: [discriminator loss: 0.588166, acc: 0.648438] [adversarial loss: 1.172734, acc: 0.218750]\n",
            "39609: [discriminator loss: 0.611934, acc: 0.648438] [adversarial loss: 0.818894, acc: 0.562500]\n",
            "39610: [discriminator loss: 0.600320, acc: 0.695312] [adversarial loss: 1.159687, acc: 0.171875]\n",
            "39611: [discriminator loss: 0.600002, acc: 0.687500] [adversarial loss: 0.888413, acc: 0.453125]\n",
            "39612: [discriminator loss: 0.624408, acc: 0.632812] [adversarial loss: 1.146895, acc: 0.203125]\n",
            "39613: [discriminator loss: 0.569137, acc: 0.679688] [adversarial loss: 1.060123, acc: 0.218750]\n",
            "39614: [discriminator loss: 0.592317, acc: 0.703125] [adversarial loss: 1.113806, acc: 0.265625]\n",
            "39615: [discriminator loss: 0.564828, acc: 0.671875] [adversarial loss: 1.135851, acc: 0.265625]\n",
            "39616: [discriminator loss: 0.603710, acc: 0.679688] [adversarial loss: 0.918142, acc: 0.375000]\n",
            "39617: [discriminator loss: 0.508023, acc: 0.726562] [adversarial loss: 1.334593, acc: 0.187500]\n",
            "39618: [discriminator loss: 0.614777, acc: 0.632812] [adversarial loss: 0.962985, acc: 0.421875]\n",
            "39619: [discriminator loss: 0.611654, acc: 0.671875] [adversarial loss: 1.184499, acc: 0.203125]\n",
            "39620: [discriminator loss: 0.658536, acc: 0.609375] [adversarial loss: 0.934688, acc: 0.328125]\n",
            "39621: [discriminator loss: 0.653299, acc: 0.632812] [adversarial loss: 1.416388, acc: 0.140625]\n",
            "39622: [discriminator loss: 0.567667, acc: 0.695312] [adversarial loss: 0.875607, acc: 0.421875]\n",
            "39623: [discriminator loss: 0.635138, acc: 0.617188] [adversarial loss: 1.243128, acc: 0.218750]\n",
            "39624: [discriminator loss: 0.597880, acc: 0.625000] [adversarial loss: 1.209465, acc: 0.250000]\n",
            "39625: [discriminator loss: 0.528418, acc: 0.750000] [adversarial loss: 0.975967, acc: 0.312500]\n",
            "39626: [discriminator loss: 0.640420, acc: 0.593750] [adversarial loss: 0.948662, acc: 0.359375]\n",
            "39627: [discriminator loss: 0.594595, acc: 0.640625] [adversarial loss: 0.825253, acc: 0.421875]\n",
            "39628: [discriminator loss: 0.516360, acc: 0.773438] [adversarial loss: 0.875451, acc: 0.375000]\n",
            "39629: [discriminator loss: 0.594029, acc: 0.656250] [adversarial loss: 0.902229, acc: 0.406250]\n",
            "39630: [discriminator loss: 0.589625, acc: 0.710938] [adversarial loss: 1.355944, acc: 0.140625]\n",
            "39631: [discriminator loss: 0.566115, acc: 0.679688] [adversarial loss: 0.838930, acc: 0.484375]\n",
            "39632: [discriminator loss: 0.598025, acc: 0.656250] [adversarial loss: 1.450768, acc: 0.187500]\n",
            "39633: [discriminator loss: 0.669032, acc: 0.585938] [adversarial loss: 0.872145, acc: 0.406250]\n",
            "39634: [discriminator loss: 0.588052, acc: 0.687500] [adversarial loss: 1.315034, acc: 0.125000]\n",
            "39635: [discriminator loss: 0.599501, acc: 0.640625] [adversarial loss: 0.885318, acc: 0.468750]\n",
            "39636: [discriminator loss: 0.551608, acc: 0.750000] [adversarial loss: 1.035119, acc: 0.312500]\n",
            "39637: [discriminator loss: 0.570172, acc: 0.718750] [adversarial loss: 1.033878, acc: 0.328125]\n",
            "39638: [discriminator loss: 0.525649, acc: 0.750000] [adversarial loss: 1.043920, acc: 0.406250]\n",
            "39639: [discriminator loss: 0.575359, acc: 0.726562] [adversarial loss: 1.232224, acc: 0.203125]\n",
            "39640: [discriminator loss: 0.701476, acc: 0.625000] [adversarial loss: 0.845121, acc: 0.453125]\n",
            "39641: [discriminator loss: 0.512782, acc: 0.804688] [adversarial loss: 1.196159, acc: 0.281250]\n",
            "39642: [discriminator loss: 0.558407, acc: 0.695312] [adversarial loss: 0.899585, acc: 0.453125]\n",
            "39643: [discriminator loss: 0.593153, acc: 0.664062] [adversarial loss: 1.305421, acc: 0.234375]\n",
            "39644: [discriminator loss: 0.583578, acc: 0.695312] [adversarial loss: 0.747010, acc: 0.562500]\n",
            "39645: [discriminator loss: 0.624257, acc: 0.679688] [adversarial loss: 1.393550, acc: 0.140625]\n",
            "39646: [discriminator loss: 0.671956, acc: 0.617188] [adversarial loss: 1.207119, acc: 0.187500]\n",
            "39647: [discriminator loss: 0.594350, acc: 0.625000] [adversarial loss: 0.873428, acc: 0.468750]\n",
            "39648: [discriminator loss: 0.627028, acc: 0.625000] [adversarial loss: 1.336640, acc: 0.125000]\n",
            "39649: [discriminator loss: 0.583382, acc: 0.726562] [adversarial loss: 0.991437, acc: 0.343750]\n",
            "39650: [discriminator loss: 0.612950, acc: 0.710938] [adversarial loss: 1.121204, acc: 0.234375]\n",
            "39651: [discriminator loss: 0.525865, acc: 0.742188] [adversarial loss: 1.062525, acc: 0.234375]\n",
            "39652: [discriminator loss: 0.536269, acc: 0.734375] [adversarial loss: 0.982466, acc: 0.421875]\n",
            "39653: [discriminator loss: 0.555034, acc: 0.742188] [adversarial loss: 1.182687, acc: 0.234375]\n",
            "39654: [discriminator loss: 0.576573, acc: 0.664062] [adversarial loss: 1.243621, acc: 0.203125]\n",
            "39655: [discriminator loss: 0.589505, acc: 0.687500] [adversarial loss: 0.861479, acc: 0.484375]\n",
            "39656: [discriminator loss: 0.589673, acc: 0.648438] [adversarial loss: 0.996566, acc: 0.359375]\n",
            "39657: [discriminator loss: 0.661071, acc: 0.625000] [adversarial loss: 0.971622, acc: 0.328125]\n",
            "39658: [discriminator loss: 0.606634, acc: 0.687500] [adversarial loss: 1.165479, acc: 0.281250]\n",
            "39659: [discriminator loss: 0.585150, acc: 0.703125] [adversarial loss: 1.271885, acc: 0.156250]\n",
            "39660: [discriminator loss: 0.593957, acc: 0.656250] [adversarial loss: 0.792395, acc: 0.375000]\n",
            "39661: [discriminator loss: 0.621009, acc: 0.671875] [adversarial loss: 1.386340, acc: 0.109375]\n",
            "39662: [discriminator loss: 0.568770, acc: 0.687500] [adversarial loss: 0.934239, acc: 0.343750]\n",
            "39663: [discriminator loss: 0.596846, acc: 0.695312] [adversarial loss: 1.528729, acc: 0.062500]\n",
            "39664: [discriminator loss: 0.521612, acc: 0.734375] [adversarial loss: 1.128352, acc: 0.359375]\n",
            "39665: [discriminator loss: 0.603143, acc: 0.609375] [adversarial loss: 1.324059, acc: 0.218750]\n",
            "39666: [discriminator loss: 0.565606, acc: 0.703125] [adversarial loss: 0.940336, acc: 0.531250]\n",
            "39667: [discriminator loss: 0.597052, acc: 0.648438] [adversarial loss: 1.357102, acc: 0.156250]\n",
            "39668: [discriminator loss: 0.533498, acc: 0.718750] [adversarial loss: 0.812887, acc: 0.484375]\n",
            "39669: [discriminator loss: 0.703510, acc: 0.562500] [adversarial loss: 1.093700, acc: 0.312500]\n",
            "39670: [discriminator loss: 0.627701, acc: 0.625000] [adversarial loss: 0.987084, acc: 0.375000]\n",
            "39671: [discriminator loss: 0.547599, acc: 0.710938] [adversarial loss: 1.168389, acc: 0.203125]\n",
            "39672: [discriminator loss: 0.528568, acc: 0.718750] [adversarial loss: 0.895670, acc: 0.406250]\n",
            "39673: [discriminator loss: 0.554223, acc: 0.734375] [adversarial loss: 0.955929, acc: 0.312500]\n",
            "39674: [discriminator loss: 0.615486, acc: 0.664062] [adversarial loss: 1.058612, acc: 0.359375]\n",
            "39675: [discriminator loss: 0.612297, acc: 0.695312] [adversarial loss: 0.905569, acc: 0.375000]\n",
            "39676: [discriminator loss: 0.586080, acc: 0.703125] [adversarial loss: 1.077725, acc: 0.265625]\n",
            "39677: [discriminator loss: 0.553452, acc: 0.687500] [adversarial loss: 0.958926, acc: 0.343750]\n",
            "39678: [discriminator loss: 0.617837, acc: 0.632812] [adversarial loss: 1.006933, acc: 0.359375]\n",
            "39679: [discriminator loss: 0.552417, acc: 0.695312] [adversarial loss: 1.246779, acc: 0.250000]\n",
            "39680: [discriminator loss: 0.584778, acc: 0.679688] [adversarial loss: 1.107570, acc: 0.296875]\n",
            "39681: [discriminator loss: 0.520338, acc: 0.742188] [adversarial loss: 1.106210, acc: 0.265625]\n",
            "39682: [discriminator loss: 0.608852, acc: 0.664062] [adversarial loss: 0.975567, acc: 0.359375]\n",
            "39683: [discriminator loss: 0.593824, acc: 0.687500] [adversarial loss: 1.244424, acc: 0.281250]\n",
            "39684: [discriminator loss: 0.603080, acc: 0.625000] [adversarial loss: 1.084652, acc: 0.250000]\n",
            "39685: [discriminator loss: 0.510946, acc: 0.750000] [adversarial loss: 0.976049, acc: 0.343750]\n",
            "39686: [discriminator loss: 0.573293, acc: 0.703125] [adversarial loss: 1.257476, acc: 0.265625]\n",
            "39687: [discriminator loss: 0.603657, acc: 0.656250] [adversarial loss: 1.147688, acc: 0.187500]\n",
            "39688: [discriminator loss: 0.561729, acc: 0.710938] [adversarial loss: 1.280205, acc: 0.234375]\n",
            "39689: [discriminator loss: 0.563156, acc: 0.726562] [adversarial loss: 0.763364, acc: 0.578125]\n",
            "39690: [discriminator loss: 0.536296, acc: 0.703125] [adversarial loss: 1.140212, acc: 0.250000]\n",
            "39691: [discriminator loss: 0.548219, acc: 0.710938] [adversarial loss: 1.155219, acc: 0.296875]\n",
            "39692: [discriminator loss: 0.591676, acc: 0.640625] [adversarial loss: 1.025198, acc: 0.343750]\n",
            "39693: [discriminator loss: 0.579316, acc: 0.695312] [adversarial loss: 1.182398, acc: 0.296875]\n",
            "39694: [discriminator loss: 0.551867, acc: 0.734375] [adversarial loss: 0.744293, acc: 0.515625]\n",
            "39695: [discriminator loss: 0.573118, acc: 0.710938] [adversarial loss: 1.229359, acc: 0.171875]\n",
            "39696: [discriminator loss: 0.584634, acc: 0.671875] [adversarial loss: 0.761459, acc: 0.578125]\n",
            "39697: [discriminator loss: 0.629868, acc: 0.640625] [adversarial loss: 1.176082, acc: 0.218750]\n",
            "39698: [discriminator loss: 0.662844, acc: 0.570312] [adversarial loss: 0.839813, acc: 0.500000]\n",
            "39699: [discriminator loss: 0.587489, acc: 0.710938] [adversarial loss: 1.349082, acc: 0.125000]\n",
            "39700: [discriminator loss: 0.615464, acc: 0.632812] [adversarial loss: 0.889884, acc: 0.421875]\n",
            "39701: [discriminator loss: 0.569633, acc: 0.703125] [adversarial loss: 1.131398, acc: 0.265625]\n",
            "39702: [discriminator loss: 0.600221, acc: 0.664062] [adversarial loss: 1.049821, acc: 0.359375]\n",
            "39703: [discriminator loss: 0.612462, acc: 0.617188] [adversarial loss: 1.036849, acc: 0.296875]\n",
            "39704: [discriminator loss: 0.629607, acc: 0.617188] [adversarial loss: 1.100951, acc: 0.281250]\n",
            "39705: [discriminator loss: 0.623431, acc: 0.601562] [adversarial loss: 1.100252, acc: 0.265625]\n",
            "39706: [discriminator loss: 0.524748, acc: 0.734375] [adversarial loss: 1.174564, acc: 0.234375]\n",
            "39707: [discriminator loss: 0.521664, acc: 0.734375] [adversarial loss: 0.952339, acc: 0.390625]\n",
            "39708: [discriminator loss: 0.536672, acc: 0.734375] [adversarial loss: 1.119803, acc: 0.250000]\n",
            "39709: [discriminator loss: 0.559697, acc: 0.718750] [adversarial loss: 1.221509, acc: 0.218750]\n",
            "39710: [discriminator loss: 0.550692, acc: 0.703125] [adversarial loss: 0.980632, acc: 0.343750]\n",
            "39711: [discriminator loss: 0.565013, acc: 0.703125] [adversarial loss: 1.203417, acc: 0.218750]\n",
            "39712: [discriminator loss: 0.597752, acc: 0.671875] [adversarial loss: 0.812428, acc: 0.515625]\n",
            "39713: [discriminator loss: 0.641112, acc: 0.625000] [adversarial loss: 1.272480, acc: 0.203125]\n",
            "39714: [discriminator loss: 0.569010, acc: 0.695312] [adversarial loss: 1.105965, acc: 0.296875]\n",
            "39715: [discriminator loss: 0.519341, acc: 0.726562] [adversarial loss: 1.043365, acc: 0.375000]\n",
            "39716: [discriminator loss: 0.627949, acc: 0.679688] [adversarial loss: 1.242811, acc: 0.218750]\n",
            "39717: [discriminator loss: 0.542952, acc: 0.687500] [adversarial loss: 0.886112, acc: 0.359375]\n",
            "39718: [discriminator loss: 0.626212, acc: 0.664062] [adversarial loss: 1.412571, acc: 0.171875]\n",
            "39719: [discriminator loss: 0.592214, acc: 0.656250] [adversarial loss: 0.884977, acc: 0.406250]\n",
            "39720: [discriminator loss: 0.649438, acc: 0.664062] [adversarial loss: 1.259498, acc: 0.187500]\n",
            "39721: [discriminator loss: 0.573319, acc: 0.695312] [adversarial loss: 0.986206, acc: 0.343750]\n",
            "39722: [discriminator loss: 0.561576, acc: 0.710938] [adversarial loss: 1.148639, acc: 0.187500]\n",
            "39723: [discriminator loss: 0.555136, acc: 0.726562] [adversarial loss: 1.263932, acc: 0.156250]\n",
            "39724: [discriminator loss: 0.535890, acc: 0.734375] [adversarial loss: 0.983202, acc: 0.375000]\n",
            "39725: [discriminator loss: 0.590516, acc: 0.687500] [adversarial loss: 1.181627, acc: 0.281250]\n",
            "39726: [discriminator loss: 0.603863, acc: 0.664062] [adversarial loss: 0.682763, acc: 0.546875]\n",
            "39727: [discriminator loss: 0.612993, acc: 0.679688] [adversarial loss: 1.402889, acc: 0.109375]\n",
            "39728: [discriminator loss: 0.623260, acc: 0.664062] [adversarial loss: 0.813681, acc: 0.546875]\n",
            "39729: [discriminator loss: 0.611625, acc: 0.718750] [adversarial loss: 1.280549, acc: 0.281250]\n",
            "39730: [discriminator loss: 0.613325, acc: 0.664062] [adversarial loss: 1.040079, acc: 0.312500]\n",
            "39731: [discriminator loss: 0.640700, acc: 0.601562] [adversarial loss: 0.977055, acc: 0.328125]\n",
            "39732: [discriminator loss: 0.593054, acc: 0.687500] [adversarial loss: 1.141946, acc: 0.281250]\n",
            "39733: [discriminator loss: 0.566630, acc: 0.679688] [adversarial loss: 0.986928, acc: 0.375000]\n",
            "39734: [discriminator loss: 0.495225, acc: 0.718750] [adversarial loss: 1.082597, acc: 0.265625]\n",
            "39735: [discriminator loss: 0.583391, acc: 0.679688] [adversarial loss: 1.014921, acc: 0.328125]\n",
            "39736: [discriminator loss: 0.551276, acc: 0.734375] [adversarial loss: 1.074299, acc: 0.328125]\n",
            "39737: [discriminator loss: 0.555465, acc: 0.742188] [adversarial loss: 1.295580, acc: 0.250000]\n",
            "39738: [discriminator loss: 0.558422, acc: 0.710938] [adversarial loss: 1.148836, acc: 0.296875]\n",
            "39739: [discriminator loss: 0.614661, acc: 0.632812] [adversarial loss: 0.931567, acc: 0.390625]\n",
            "39740: [discriminator loss: 0.529758, acc: 0.765625] [adversarial loss: 1.123109, acc: 0.281250]\n",
            "39741: [discriminator loss: 0.572492, acc: 0.718750] [adversarial loss: 0.984648, acc: 0.375000]\n",
            "39742: [discriminator loss: 0.571089, acc: 0.664062] [adversarial loss: 1.061777, acc: 0.296875]\n",
            "39743: [discriminator loss: 0.535113, acc: 0.757812] [adversarial loss: 1.032359, acc: 0.359375]\n",
            "39744: [discriminator loss: 0.576022, acc: 0.703125] [adversarial loss: 1.128801, acc: 0.265625]\n",
            "39745: [discriminator loss: 0.548920, acc: 0.703125] [adversarial loss: 1.040728, acc: 0.281250]\n",
            "39746: [discriminator loss: 0.562148, acc: 0.734375] [adversarial loss: 1.069507, acc: 0.218750]\n",
            "39747: [discriminator loss: 0.569257, acc: 0.687500] [adversarial loss: 1.076669, acc: 0.375000]\n",
            "39748: [discriminator loss: 0.581601, acc: 0.718750] [adversarial loss: 1.330560, acc: 0.156250]\n",
            "39749: [discriminator loss: 0.600729, acc: 0.632812] [adversarial loss: 1.152590, acc: 0.265625]\n",
            "39750: [discriminator loss: 0.565817, acc: 0.734375] [adversarial loss: 1.110616, acc: 0.234375]\n",
            "39751: [discriminator loss: 0.586933, acc: 0.664062] [adversarial loss: 0.975652, acc: 0.406250]\n",
            "39752: [discriminator loss: 0.586727, acc: 0.687500] [adversarial loss: 1.189108, acc: 0.250000]\n",
            "39753: [discriminator loss: 0.538623, acc: 0.742188] [adversarial loss: 1.185729, acc: 0.312500]\n",
            "39754: [discriminator loss: 0.558609, acc: 0.687500] [adversarial loss: 1.123677, acc: 0.250000]\n",
            "39755: [discriminator loss: 0.529370, acc: 0.765625] [adversarial loss: 0.915186, acc: 0.453125]\n",
            "39756: [discriminator loss: 0.525394, acc: 0.734375] [adversarial loss: 1.254540, acc: 0.187500]\n",
            "39757: [discriminator loss: 0.571342, acc: 0.687500] [adversarial loss: 1.233798, acc: 0.218750]\n",
            "39758: [discriminator loss: 0.646880, acc: 0.648438] [adversarial loss: 0.951719, acc: 0.390625]\n",
            "39759: [discriminator loss: 0.543666, acc: 0.703125] [adversarial loss: 1.091260, acc: 0.281250]\n",
            "39760: [discriminator loss: 0.542190, acc: 0.718750] [adversarial loss: 1.144123, acc: 0.187500]\n",
            "39761: [discriminator loss: 0.580823, acc: 0.671875] [adversarial loss: 1.118677, acc: 0.250000]\n",
            "39762: [discriminator loss: 0.517926, acc: 0.757812] [adversarial loss: 1.121582, acc: 0.218750]\n",
            "39763: [discriminator loss: 0.546782, acc: 0.726562] [adversarial loss: 1.028974, acc: 0.296875]\n",
            "39764: [discriminator loss: 0.612903, acc: 0.679688] [adversarial loss: 1.138741, acc: 0.234375]\n",
            "39765: [discriminator loss: 0.602696, acc: 0.710938] [adversarial loss: 1.214008, acc: 0.218750]\n",
            "39766: [discriminator loss: 0.553148, acc: 0.750000] [adversarial loss: 0.897547, acc: 0.453125]\n",
            "39767: [discriminator loss: 0.606851, acc: 0.679688] [adversarial loss: 1.346011, acc: 0.093750]\n",
            "39768: [discriminator loss: 0.612014, acc: 0.671875] [adversarial loss: 0.861103, acc: 0.390625]\n",
            "39769: [discriminator loss: 0.628548, acc: 0.632812] [adversarial loss: 1.105423, acc: 0.187500]\n",
            "39770: [discriminator loss: 0.595358, acc: 0.671875] [adversarial loss: 0.919543, acc: 0.390625]\n",
            "39771: [discriminator loss: 0.600506, acc: 0.664062] [adversarial loss: 1.298252, acc: 0.125000]\n",
            "39772: [discriminator loss: 0.563021, acc: 0.695312] [adversarial loss: 1.019951, acc: 0.359375]\n",
            "39773: [discriminator loss: 0.649447, acc: 0.625000] [adversarial loss: 1.163289, acc: 0.296875]\n",
            "39774: [discriminator loss: 0.482043, acc: 0.765625] [adversarial loss: 1.378174, acc: 0.187500]\n",
            "39775: [discriminator loss: 0.598010, acc: 0.687500] [adversarial loss: 0.961911, acc: 0.421875]\n",
            "39776: [discriminator loss: 0.538371, acc: 0.687500] [adversarial loss: 1.099972, acc: 0.171875]\n",
            "39777: [discriminator loss: 0.610201, acc: 0.648438] [adversarial loss: 1.158369, acc: 0.234375]\n",
            "39778: [discriminator loss: 0.516904, acc: 0.726562] [adversarial loss: 1.002321, acc: 0.343750]\n",
            "39779: [discriminator loss: 0.558339, acc: 0.726562] [adversarial loss: 1.307174, acc: 0.218750]\n",
            "39780: [discriminator loss: 0.581782, acc: 0.664062] [adversarial loss: 0.841279, acc: 0.468750]\n",
            "39781: [discriminator loss: 0.619039, acc: 0.640625] [adversarial loss: 1.089921, acc: 0.296875]\n",
            "39782: [discriminator loss: 0.578320, acc: 0.703125] [adversarial loss: 0.995693, acc: 0.421875]\n",
            "39783: [discriminator loss: 0.555702, acc: 0.734375] [adversarial loss: 1.215387, acc: 0.250000]\n",
            "39784: [discriminator loss: 0.522621, acc: 0.703125] [adversarial loss: 1.024724, acc: 0.375000]\n",
            "39785: [discriminator loss: 0.601874, acc: 0.679688] [adversarial loss: 1.447904, acc: 0.125000]\n",
            "39786: [discriminator loss: 0.633092, acc: 0.625000] [adversarial loss: 0.738056, acc: 0.546875]\n",
            "39787: [discriminator loss: 0.584342, acc: 0.695312] [adversarial loss: 1.238093, acc: 0.171875]\n",
            "39788: [discriminator loss: 0.627711, acc: 0.625000] [adversarial loss: 1.007441, acc: 0.343750]\n",
            "39789: [discriminator loss: 0.604987, acc: 0.609375] [adversarial loss: 1.169648, acc: 0.203125]\n",
            "39790: [discriminator loss: 0.611503, acc: 0.671875] [adversarial loss: 0.992577, acc: 0.343750]\n",
            "39791: [discriminator loss: 0.558012, acc: 0.718750] [adversarial loss: 1.006763, acc: 0.390625]\n",
            "39792: [discriminator loss: 0.612647, acc: 0.679688] [adversarial loss: 1.214988, acc: 0.265625]\n",
            "39793: [discriminator loss: 0.591964, acc: 0.664062] [adversarial loss: 1.043530, acc: 0.328125]\n",
            "39794: [discriminator loss: 0.584170, acc: 0.640625] [adversarial loss: 1.069731, acc: 0.296875]\n",
            "39795: [discriminator loss: 0.624521, acc: 0.648438] [adversarial loss: 1.138065, acc: 0.250000]\n",
            "39796: [discriminator loss: 0.604647, acc: 0.656250] [adversarial loss: 0.882314, acc: 0.437500]\n",
            "39797: [discriminator loss: 0.610282, acc: 0.671875] [adversarial loss: 1.169058, acc: 0.156250]\n",
            "39798: [discriminator loss: 0.562043, acc: 0.703125] [adversarial loss: 0.882837, acc: 0.375000]\n",
            "39799: [discriminator loss: 0.608089, acc: 0.687500] [adversarial loss: 1.285122, acc: 0.250000]\n",
            "39800: [discriminator loss: 0.538031, acc: 0.773438] [adversarial loss: 1.035959, acc: 0.234375]\n",
            "39801: [discriminator loss: 0.567007, acc: 0.757812] [adversarial loss: 1.086746, acc: 0.281250]\n",
            "39802: [discriminator loss: 0.558946, acc: 0.734375] [adversarial loss: 0.969565, acc: 0.390625]\n",
            "39803: [discriminator loss: 0.566056, acc: 0.703125] [adversarial loss: 1.097192, acc: 0.312500]\n",
            "39804: [discriminator loss: 0.595032, acc: 0.656250] [adversarial loss: 1.118755, acc: 0.171875]\n",
            "39805: [discriminator loss: 0.530409, acc: 0.710938] [adversarial loss: 0.936110, acc: 0.437500]\n",
            "39806: [discriminator loss: 0.577062, acc: 0.695312] [adversarial loss: 1.233030, acc: 0.171875]\n",
            "39807: [discriminator loss: 0.620111, acc: 0.656250] [adversarial loss: 0.808948, acc: 0.468750]\n",
            "39808: [discriminator loss: 0.580856, acc: 0.718750] [adversarial loss: 1.593937, acc: 0.078125]\n",
            "39809: [discriminator loss: 0.602420, acc: 0.640625] [adversarial loss: 1.142568, acc: 0.296875]\n",
            "39810: [discriminator loss: 0.608409, acc: 0.671875] [adversarial loss: 1.249749, acc: 0.265625]\n",
            "39811: [discriminator loss: 0.584455, acc: 0.671875] [adversarial loss: 1.099188, acc: 0.281250]\n",
            "39812: [discriminator loss: 0.561743, acc: 0.703125] [adversarial loss: 0.987066, acc: 0.296875]\n",
            "39813: [discriminator loss: 0.523401, acc: 0.726562] [adversarial loss: 1.030066, acc: 0.343750]\n",
            "39814: [discriminator loss: 0.542581, acc: 0.750000] [adversarial loss: 0.982846, acc: 0.359375]\n",
            "39815: [discriminator loss: 0.522368, acc: 0.734375] [adversarial loss: 0.988156, acc: 0.390625]\n",
            "39816: [discriminator loss: 0.562854, acc: 0.734375] [adversarial loss: 0.983284, acc: 0.390625]\n",
            "39817: [discriminator loss: 0.615429, acc: 0.632812] [adversarial loss: 1.086805, acc: 0.250000]\n",
            "39818: [discriminator loss: 0.569261, acc: 0.703125] [adversarial loss: 0.943611, acc: 0.406250]\n",
            "39819: [discriminator loss: 0.623972, acc: 0.648438] [adversarial loss: 1.181691, acc: 0.250000]\n",
            "39820: [discriminator loss: 0.595897, acc: 0.671875] [adversarial loss: 1.091985, acc: 0.296875]\n",
            "39821: [discriminator loss: 0.562264, acc: 0.703125] [adversarial loss: 1.013186, acc: 0.343750]\n",
            "39822: [discriminator loss: 0.556764, acc: 0.734375] [adversarial loss: 1.226652, acc: 0.250000]\n",
            "39823: [discriminator loss: 0.557734, acc: 0.703125] [adversarial loss: 1.208570, acc: 0.156250]\n",
            "39824: [discriminator loss: 0.546203, acc: 0.734375] [adversarial loss: 0.840603, acc: 0.484375]\n",
            "39825: [discriminator loss: 0.534646, acc: 0.726562] [adversarial loss: 1.192294, acc: 0.312500]\n",
            "39826: [discriminator loss: 0.570572, acc: 0.671875] [adversarial loss: 0.748083, acc: 0.515625]\n",
            "39827: [discriminator loss: 0.564682, acc: 0.726562] [adversarial loss: 1.421583, acc: 0.093750]\n",
            "39828: [discriminator loss: 0.607227, acc: 0.687500] [adversarial loss: 0.882624, acc: 0.437500]\n",
            "39829: [discriminator loss: 0.639446, acc: 0.656250] [adversarial loss: 0.962823, acc: 0.437500]\n",
            "39830: [discriminator loss: 0.600241, acc: 0.710938] [adversarial loss: 1.477548, acc: 0.109375]\n",
            "39831: [discriminator loss: 0.635358, acc: 0.664062] [adversarial loss: 0.762366, acc: 0.500000]\n",
            "39832: [discriminator loss: 0.587510, acc: 0.679688] [adversarial loss: 1.249138, acc: 0.265625]\n",
            "39833: [discriminator loss: 0.579042, acc: 0.656250] [adversarial loss: 0.879616, acc: 0.515625]\n",
            "39834: [discriminator loss: 0.613872, acc: 0.679688] [adversarial loss: 1.128846, acc: 0.218750]\n",
            "39835: [discriminator loss: 0.623086, acc: 0.656250] [adversarial loss: 0.863977, acc: 0.375000]\n",
            "39836: [discriminator loss: 0.624778, acc: 0.632812] [adversarial loss: 1.002544, acc: 0.359375]\n",
            "39837: [discriminator loss: 0.613038, acc: 0.648438] [adversarial loss: 1.101493, acc: 0.250000]\n",
            "39838: [discriminator loss: 0.592510, acc: 0.664062] [adversarial loss: 1.142845, acc: 0.203125]\n",
            "39839: [discriminator loss: 0.558009, acc: 0.703125] [adversarial loss: 0.871231, acc: 0.437500]\n",
            "39840: [discriminator loss: 0.585634, acc: 0.687500] [adversarial loss: 1.215806, acc: 0.203125]\n",
            "39841: [discriminator loss: 0.653446, acc: 0.640625] [adversarial loss: 0.917264, acc: 0.390625]\n",
            "39842: [discriminator loss: 0.617298, acc: 0.671875] [adversarial loss: 1.169744, acc: 0.234375]\n",
            "39843: [discriminator loss: 0.548970, acc: 0.718750] [adversarial loss: 0.752438, acc: 0.531250]\n",
            "39844: [discriminator loss: 0.566819, acc: 0.734375] [adversarial loss: 1.262903, acc: 0.156250]\n",
            "39845: [discriminator loss: 0.561125, acc: 0.718750] [adversarial loss: 1.040148, acc: 0.343750]\n",
            "39846: [discriminator loss: 0.549307, acc: 0.750000] [adversarial loss: 1.143117, acc: 0.234375]\n",
            "39847: [discriminator loss: 0.557536, acc: 0.695312] [adversarial loss: 0.930122, acc: 0.375000]\n",
            "39848: [discriminator loss: 0.560380, acc: 0.734375] [adversarial loss: 1.458174, acc: 0.218750]\n",
            "39849: [discriminator loss: 0.490394, acc: 0.742188] [adversarial loss: 0.960282, acc: 0.453125]\n",
            "39850: [discriminator loss: 0.538072, acc: 0.757812] [adversarial loss: 1.138570, acc: 0.328125]\n",
            "39851: [discriminator loss: 0.572381, acc: 0.710938] [adversarial loss: 1.234041, acc: 0.296875]\n",
            "39852: [discriminator loss: 0.612027, acc: 0.632812] [adversarial loss: 1.278907, acc: 0.218750]\n",
            "39853: [discriminator loss: 0.596590, acc: 0.640625] [adversarial loss: 0.855232, acc: 0.406250]\n",
            "39854: [discriminator loss: 0.667408, acc: 0.656250] [adversarial loss: 1.348743, acc: 0.171875]\n",
            "39855: [discriminator loss: 0.601841, acc: 0.625000] [adversarial loss: 0.800472, acc: 0.531250]\n",
            "39856: [discriminator loss: 0.554833, acc: 0.710938] [adversarial loss: 1.136286, acc: 0.187500]\n",
            "39857: [discriminator loss: 0.531025, acc: 0.734375] [adversarial loss: 0.906939, acc: 0.406250]\n",
            "39858: [discriminator loss: 0.581155, acc: 0.695312] [adversarial loss: 1.107385, acc: 0.281250]\n",
            "39859: [discriminator loss: 0.558256, acc: 0.695312] [adversarial loss: 1.169692, acc: 0.203125]\n",
            "39860: [discriminator loss: 0.526118, acc: 0.726562] [adversarial loss: 0.886022, acc: 0.328125]\n",
            "39861: [discriminator loss: 0.579219, acc: 0.656250] [adversarial loss: 1.262706, acc: 0.234375]\n",
            "39862: [discriminator loss: 0.592397, acc: 0.656250] [adversarial loss: 0.769591, acc: 0.484375]\n",
            "39863: [discriminator loss: 0.637216, acc: 0.656250] [adversarial loss: 1.259920, acc: 0.140625]\n",
            "39864: [discriminator loss: 0.594276, acc: 0.695312] [adversarial loss: 0.920667, acc: 0.468750]\n",
            "39865: [discriminator loss: 0.535720, acc: 0.679688] [adversarial loss: 1.157710, acc: 0.265625]\n",
            "39866: [discriminator loss: 0.560043, acc: 0.718750] [adversarial loss: 1.050081, acc: 0.437500]\n",
            "39867: [discriminator loss: 0.629730, acc: 0.679688] [adversarial loss: 1.355243, acc: 0.171875]\n",
            "39868: [discriminator loss: 0.562963, acc: 0.718750] [adversarial loss: 0.869883, acc: 0.421875]\n",
            "39869: [discriminator loss: 0.606547, acc: 0.703125] [adversarial loss: 1.107330, acc: 0.265625]\n",
            "39870: [discriminator loss: 0.576908, acc: 0.648438] [adversarial loss: 1.103229, acc: 0.312500]\n",
            "39871: [discriminator loss: 0.545289, acc: 0.734375] [adversarial loss: 0.919575, acc: 0.390625]\n",
            "39872: [discriminator loss: 0.556549, acc: 0.679688] [adversarial loss: 1.343044, acc: 0.171875]\n",
            "39873: [discriminator loss: 0.627432, acc: 0.625000] [adversarial loss: 0.919130, acc: 0.328125]\n",
            "39874: [discriminator loss: 0.561550, acc: 0.710938] [adversarial loss: 1.185757, acc: 0.234375]\n",
            "39875: [discriminator loss: 0.572842, acc: 0.671875] [adversarial loss: 1.097256, acc: 0.312500]\n",
            "39876: [discriminator loss: 0.606279, acc: 0.710938] [adversarial loss: 1.036726, acc: 0.328125]\n",
            "39877: [discriminator loss: 0.576045, acc: 0.671875] [adversarial loss: 1.251634, acc: 0.234375]\n",
            "39878: [discriminator loss: 0.589390, acc: 0.726562] [adversarial loss: 0.977364, acc: 0.359375]\n",
            "39879: [discriminator loss: 0.544034, acc: 0.734375] [adversarial loss: 1.077992, acc: 0.312500]\n",
            "39880: [discriminator loss: 0.632269, acc: 0.656250] [adversarial loss: 1.385780, acc: 0.171875]\n",
            "39881: [discriminator loss: 0.509151, acc: 0.742188] [adversarial loss: 0.885009, acc: 0.468750]\n",
            "39882: [discriminator loss: 0.623392, acc: 0.617188] [adversarial loss: 1.312914, acc: 0.125000]\n",
            "39883: [discriminator loss: 0.549226, acc: 0.726562] [adversarial loss: 0.869531, acc: 0.562500]\n",
            "39884: [discriminator loss: 0.630599, acc: 0.671875] [adversarial loss: 1.298865, acc: 0.234375]\n",
            "39885: [discriminator loss: 0.637616, acc: 0.656250] [adversarial loss: 0.970995, acc: 0.281250]\n",
            "39886: [discriminator loss: 0.582141, acc: 0.695312] [adversarial loss: 1.218109, acc: 0.281250]\n",
            "39887: [discriminator loss: 0.618365, acc: 0.656250] [adversarial loss: 1.163320, acc: 0.203125]\n",
            "39888: [discriminator loss: 0.566717, acc: 0.687500] [adversarial loss: 0.993982, acc: 0.359375]\n",
            "39889: [discriminator loss: 0.533823, acc: 0.718750] [adversarial loss: 1.296746, acc: 0.187500]\n",
            "39890: [discriminator loss: 0.575846, acc: 0.687500] [adversarial loss: 0.920669, acc: 0.468750]\n",
            "39891: [discriminator loss: 0.557294, acc: 0.679688] [adversarial loss: 1.009731, acc: 0.343750]\n",
            "39892: [discriminator loss: 0.561157, acc: 0.703125] [adversarial loss: 1.202679, acc: 0.171875]\n",
            "39893: [discriminator loss: 0.531157, acc: 0.710938] [adversarial loss: 1.004498, acc: 0.359375]\n",
            "39894: [discriminator loss: 0.560112, acc: 0.726562] [adversarial loss: 1.146836, acc: 0.265625]\n",
            "39895: [discriminator loss: 0.638139, acc: 0.687500] [adversarial loss: 0.943763, acc: 0.343750]\n",
            "39896: [discriminator loss: 0.644203, acc: 0.617188] [adversarial loss: 1.276101, acc: 0.218750]\n",
            "39897: [discriminator loss: 0.606960, acc: 0.601562] [adversarial loss: 0.847321, acc: 0.437500]\n",
            "39898: [discriminator loss: 0.573346, acc: 0.664062] [adversarial loss: 1.393683, acc: 0.156250]\n",
            "39899: [discriminator loss: 0.596859, acc: 0.710938] [adversarial loss: 1.027571, acc: 0.312500]\n",
            "39900: [discriminator loss: 0.531712, acc: 0.718750] [adversarial loss: 1.359537, acc: 0.156250]\n",
            "39901: [discriminator loss: 0.612868, acc: 0.656250] [adversarial loss: 0.901184, acc: 0.437500]\n",
            "39902: [discriminator loss: 0.568664, acc: 0.687500] [adversarial loss: 1.051541, acc: 0.390625]\n",
            "39903: [discriminator loss: 0.561084, acc: 0.703125] [adversarial loss: 1.215430, acc: 0.187500]\n",
            "39904: [discriminator loss: 0.596485, acc: 0.710938] [adversarial loss: 1.086721, acc: 0.312500]\n",
            "39905: [discriminator loss: 0.591105, acc: 0.695312] [adversarial loss: 1.082149, acc: 0.281250]\n",
            "39906: [discriminator loss: 0.558692, acc: 0.703125] [adversarial loss: 0.948660, acc: 0.468750]\n",
            "39907: [discriminator loss: 0.634880, acc: 0.664062] [adversarial loss: 1.098665, acc: 0.328125]\n",
            "39908: [discriminator loss: 0.569387, acc: 0.671875] [adversarial loss: 1.051060, acc: 0.281250]\n",
            "39909: [discriminator loss: 0.547810, acc: 0.710938] [adversarial loss: 1.123951, acc: 0.281250]\n",
            "39910: [discriminator loss: 0.590033, acc: 0.703125] [adversarial loss: 1.074277, acc: 0.328125]\n",
            "39911: [discriminator loss: 0.523938, acc: 0.750000] [adversarial loss: 1.061809, acc: 0.250000]\n",
            "39912: [discriminator loss: 0.546337, acc: 0.718750] [adversarial loss: 0.938650, acc: 0.390625]\n",
            "39913: [discriminator loss: 0.631630, acc: 0.648438] [adversarial loss: 1.359515, acc: 0.156250]\n",
            "39914: [discriminator loss: 0.620321, acc: 0.625000] [adversarial loss: 0.839406, acc: 0.484375]\n",
            "39915: [discriminator loss: 0.578396, acc: 0.640625] [adversarial loss: 0.993901, acc: 0.328125]\n",
            "39916: [discriminator loss: 0.565390, acc: 0.687500] [adversarial loss: 0.964704, acc: 0.375000]\n",
            "39917: [discriminator loss: 0.563280, acc: 0.742188] [adversarial loss: 1.228964, acc: 0.156250]\n",
            "39918: [discriminator loss: 0.559827, acc: 0.710938] [adversarial loss: 0.840653, acc: 0.468750]\n",
            "39919: [discriminator loss: 0.615795, acc: 0.640625] [adversarial loss: 1.229672, acc: 0.187500]\n",
            "39920: [discriminator loss: 0.573674, acc: 0.671875] [adversarial loss: 1.166936, acc: 0.296875]\n",
            "39921: [discriminator loss: 0.562257, acc: 0.664062] [adversarial loss: 1.102344, acc: 0.312500]\n",
            "39922: [discriminator loss: 0.557218, acc: 0.710938] [adversarial loss: 1.189813, acc: 0.296875]\n",
            "39923: [discriminator loss: 0.618423, acc: 0.617188] [adversarial loss: 1.036182, acc: 0.343750]\n",
            "39924: [discriminator loss: 0.559581, acc: 0.710938] [adversarial loss: 1.047261, acc: 0.281250]\n",
            "39925: [discriminator loss: 0.535996, acc: 0.734375] [adversarial loss: 0.954438, acc: 0.375000]\n",
            "39926: [discriminator loss: 0.513370, acc: 0.742188] [adversarial loss: 1.296679, acc: 0.218750]\n",
            "39927: [discriminator loss: 0.606884, acc: 0.664062] [adversarial loss: 0.909790, acc: 0.421875]\n",
            "39928: [discriminator loss: 0.559005, acc: 0.703125] [adversarial loss: 1.457018, acc: 0.187500]\n",
            "39929: [discriminator loss: 0.649394, acc: 0.648438] [adversarial loss: 0.880530, acc: 0.390625]\n",
            "39930: [discriminator loss: 0.593964, acc: 0.664062] [adversarial loss: 1.136019, acc: 0.265625]\n",
            "39931: [discriminator loss: 0.575979, acc: 0.695312] [adversarial loss: 0.949057, acc: 0.406250]\n",
            "39932: [discriminator loss: 0.577016, acc: 0.648438] [adversarial loss: 1.216304, acc: 0.234375]\n",
            "39933: [discriminator loss: 0.600782, acc: 0.664062] [adversarial loss: 0.861858, acc: 0.578125]\n",
            "39934: [discriminator loss: 0.611471, acc: 0.656250] [adversarial loss: 1.084958, acc: 0.343750]\n",
            "39935: [discriminator loss: 0.608217, acc: 0.656250] [adversarial loss: 1.091714, acc: 0.328125]\n",
            "39936: [discriminator loss: 0.579529, acc: 0.710938] [adversarial loss: 1.405020, acc: 0.140625]\n",
            "39937: [discriminator loss: 0.599473, acc: 0.703125] [adversarial loss: 0.968055, acc: 0.390625]\n",
            "39938: [discriminator loss: 0.618132, acc: 0.656250] [adversarial loss: 1.280328, acc: 0.187500]\n",
            "39939: [discriminator loss: 0.600879, acc: 0.687500] [adversarial loss: 0.958152, acc: 0.328125]\n",
            "39940: [discriminator loss: 0.556733, acc: 0.718750] [adversarial loss: 0.951768, acc: 0.375000]\n",
            "39941: [discriminator loss: 0.557376, acc: 0.742188] [adversarial loss: 1.100012, acc: 0.296875]\n",
            "39942: [discriminator loss: 0.560259, acc: 0.671875] [adversarial loss: 0.905446, acc: 0.421875]\n",
            "39943: [discriminator loss: 0.603504, acc: 0.687500] [adversarial loss: 0.983427, acc: 0.312500]\n",
            "39944: [discriminator loss: 0.543615, acc: 0.750000] [adversarial loss: 1.098293, acc: 0.250000]\n",
            "39945: [discriminator loss: 0.565225, acc: 0.710938] [adversarial loss: 1.017707, acc: 0.375000]\n",
            "39946: [discriminator loss: 0.539189, acc: 0.734375] [adversarial loss: 1.210605, acc: 0.187500]\n",
            "39947: [discriminator loss: 0.565305, acc: 0.695312] [adversarial loss: 0.867773, acc: 0.421875]\n",
            "39948: [discriminator loss: 0.606032, acc: 0.640625] [adversarial loss: 1.370861, acc: 0.187500]\n",
            "39949: [discriminator loss: 0.588571, acc: 0.664062] [adversarial loss: 1.058218, acc: 0.312500]\n",
            "39950: [discriminator loss: 0.613136, acc: 0.664062] [adversarial loss: 1.265002, acc: 0.234375]\n",
            "39951: [discriminator loss: 0.586262, acc: 0.632812] [adversarial loss: 0.989938, acc: 0.359375]\n",
            "39952: [discriminator loss: 0.581228, acc: 0.632812] [adversarial loss: 1.124948, acc: 0.359375]\n",
            "39953: [discriminator loss: 0.551452, acc: 0.695312] [adversarial loss: 1.073163, acc: 0.250000]\n",
            "39954: [discriminator loss: 0.530039, acc: 0.765625] [adversarial loss: 1.233669, acc: 0.250000]\n",
            "39955: [discriminator loss: 0.535732, acc: 0.703125] [adversarial loss: 1.230941, acc: 0.187500]\n",
            "39956: [discriminator loss: 0.521671, acc: 0.703125] [adversarial loss: 1.004700, acc: 0.390625]\n",
            "39957: [discriminator loss: 0.582753, acc: 0.703125] [adversarial loss: 1.450570, acc: 0.125000]\n",
            "39958: [discriminator loss: 0.604013, acc: 0.679688] [adversarial loss: 1.241882, acc: 0.312500]\n",
            "39959: [discriminator loss: 0.573223, acc: 0.687500] [adversarial loss: 1.192986, acc: 0.234375]\n",
            "39960: [discriminator loss: 0.599116, acc: 0.664062] [adversarial loss: 1.169596, acc: 0.359375]\n",
            "39961: [discriminator loss: 0.636448, acc: 0.617188] [adversarial loss: 0.900956, acc: 0.484375]\n",
            "39962: [discriminator loss: 0.678241, acc: 0.593750] [adversarial loss: 1.313685, acc: 0.187500]\n",
            "39963: [discriminator loss: 0.559389, acc: 0.679688] [adversarial loss: 0.938877, acc: 0.453125]\n",
            "39964: [discriminator loss: 0.585017, acc: 0.656250] [adversarial loss: 1.227370, acc: 0.218750]\n",
            "39965: [discriminator loss: 0.550720, acc: 0.710938] [adversarial loss: 0.899296, acc: 0.375000]\n",
            "39966: [discriminator loss: 0.608077, acc: 0.648438] [adversarial loss: 1.412625, acc: 0.078125]\n",
            "39967: [discriminator loss: 0.573048, acc: 0.710938] [adversarial loss: 0.991714, acc: 0.343750]\n",
            "39968: [discriminator loss: 0.575572, acc: 0.656250] [adversarial loss: 1.287058, acc: 0.218750]\n",
            "39969: [discriminator loss: 0.632053, acc: 0.687500] [adversarial loss: 0.967544, acc: 0.453125]\n",
            "39970: [discriminator loss: 0.539329, acc: 0.734375] [adversarial loss: 1.073492, acc: 0.375000]\n",
            "39971: [discriminator loss: 0.588896, acc: 0.640625] [adversarial loss: 1.315362, acc: 0.140625]\n",
            "39972: [discriminator loss: 0.563861, acc: 0.742188] [adversarial loss: 0.942162, acc: 0.343750]\n",
            "39973: [discriminator loss: 0.546500, acc: 0.718750] [adversarial loss: 1.034548, acc: 0.234375]\n",
            "39974: [discriminator loss: 0.555028, acc: 0.750000] [adversarial loss: 1.116514, acc: 0.265625]\n",
            "39975: [discriminator loss: 0.553164, acc: 0.703125] [adversarial loss: 0.951470, acc: 0.375000]\n",
            "39976: [discriminator loss: 0.565218, acc: 0.695312] [adversarial loss: 1.112798, acc: 0.281250]\n",
            "39977: [discriminator loss: 0.557622, acc: 0.726562] [adversarial loss: 0.894724, acc: 0.468750]\n",
            "39978: [discriminator loss: 0.558724, acc: 0.726562] [adversarial loss: 1.014277, acc: 0.312500]\n",
            "39979: [discriminator loss: 0.606497, acc: 0.703125] [adversarial loss: 1.302583, acc: 0.203125]\n",
            "39980: [discriminator loss: 0.562134, acc: 0.687500] [adversarial loss: 1.120946, acc: 0.281250]\n",
            "39981: [discriminator loss: 0.535228, acc: 0.789062] [adversarial loss: 1.016251, acc: 0.281250]\n",
            "39982: [discriminator loss: 0.575676, acc: 0.757812] [adversarial loss: 1.148452, acc: 0.203125]\n",
            "39983: [discriminator loss: 0.625679, acc: 0.640625] [adversarial loss: 0.807547, acc: 0.453125]\n",
            "39984: [discriminator loss: 0.563769, acc: 0.695312] [adversarial loss: 1.243913, acc: 0.187500]\n",
            "39985: [discriminator loss: 0.649990, acc: 0.617188] [adversarial loss: 1.160818, acc: 0.265625]\n",
            "39986: [discriminator loss: 0.554606, acc: 0.703125] [adversarial loss: 0.881056, acc: 0.375000]\n",
            "39987: [discriminator loss: 0.568280, acc: 0.710938] [adversarial loss: 1.182491, acc: 0.218750]\n",
            "39988: [discriminator loss: 0.524268, acc: 0.734375] [adversarial loss: 1.044981, acc: 0.250000]\n",
            "39989: [discriminator loss: 0.525249, acc: 0.734375] [adversarial loss: 0.925823, acc: 0.328125]\n",
            "39990: [discriminator loss: 0.580918, acc: 0.679688] [adversarial loss: 1.004007, acc: 0.328125]\n",
            "39991: [discriminator loss: 0.570563, acc: 0.710938] [adversarial loss: 0.842485, acc: 0.468750]\n",
            "39992: [discriminator loss: 0.538513, acc: 0.750000] [adversarial loss: 0.982166, acc: 0.375000]\n",
            "39993: [discriminator loss: 0.619564, acc: 0.578125] [adversarial loss: 1.052214, acc: 0.343750]\n",
            "39994: [discriminator loss: 0.609522, acc: 0.648438] [adversarial loss: 1.178784, acc: 0.250000]\n",
            "39995: [discriminator loss: 0.616173, acc: 0.671875] [adversarial loss: 0.909564, acc: 0.359375]\n",
            "39996: [discriminator loss: 0.557490, acc: 0.679688] [adversarial loss: 1.341499, acc: 0.187500]\n",
            "39997: [discriminator loss: 0.597132, acc: 0.679688] [adversarial loss: 0.850774, acc: 0.453125]\n",
            "39998: [discriminator loss: 0.637145, acc: 0.671875] [adversarial loss: 1.323778, acc: 0.218750]\n",
            "39999: [discriminator loss: 0.590132, acc: 0.640625] [adversarial loss: 1.082646, acc: 0.343750]\n",
            "cgan_mnist  labels for generated images:  [0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "YK7M6E2iR4ie",
        "outputId": "0484c03d-d844-4d2f-d8f7-bfafa40b4782"
      },
      "source": [
        "from PIL import Image\r\n",
        "Image.open('/content/cgan_mnist/01000.png')\r\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=216x216 at 0x7F598E1C5A20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "vyIXdFsLR66-",
        "outputId": "ed8dcaf0-0d5b-495c-de38-01465bcca76b"
      },
      "source": [
        "Image.open('/content/cgan_mnist/21000.png')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=216x216 at 0x7F598E597240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}